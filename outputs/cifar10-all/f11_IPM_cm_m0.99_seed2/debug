ParallelTrainer(aggregator=Coordinate-wise median, max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.4202 top1= 10.8750
[E 1B10 |   8800/50000 ( 18%) ] Loss: 2.3039 top1= 12.0000
[E 1B20 |  16800/50000 ( 34%) ] Loss: 2.3134 top1= 14.2500
[E 1B30 |  24800/50000 ( 50%) ] Loss: 2.1966 top1= 22.3750
[E 1B40 |  32800/50000 ( 66%) ] Loss: 2.0851 top1= 24.3750
[E 1B50 |  40800/50000 ( 82%) ] Loss: 2.2669 top1= 17.2500
[E 1B60 |  48800/50000 ( 98%) ] Loss: 2.0910 top1= 23.8750
[E 1B70 |  56800/50000 (114%) ] Loss: 2.0049 top1= 21.0000
[E 1B80 |  64800/50000 (130%) ] Loss: 1.9440 top1= 25.6250
[E 1B90 |  72800/50000 (146%) ] Loss: 1.9432 top1= 25.0000
[E 1B100|  80800/50000 (162%) ] Loss: 1.9852 top1= 19.8750
[E 1B110|  88800/50000 (178%) ] Loss: 1.9930 top1= 24.6250

=> Eval Loss=1.9097 top1= 27.9647

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 1.9150 top1= 28.8750
[E 2B10 |   8800/50000 ( 18%) ] Loss: 1.9386 top1= 25.1250
[E 2B20 |  16800/50000 ( 34%) ] Loss: 1.8872 top1= 30.2500
[E 2B30 |  24800/50000 ( 50%) ] Loss: 1.8760 top1= 29.3750
[E 2B40 |  32800/50000 ( 66%) ] Loss: 1.8437 top1= 29.1250
[E 2B50 |  40800/50000 ( 82%) ] Loss: 1.9958 top1= 24.5000
[E 2B60 |  48800/50000 ( 98%) ] Loss: 1.9307 top1= 31.1250
[E 2B70 |  56800/50000 (114%) ] Loss: 1.8158 top1= 32.3750
[E 2B80 |  64800/50000 (130%) ] Loss: 1.8805 top1= 30.3750
[E 2B90 |  72800/50000 (146%) ] Loss: 1.7164 top1= 38.2500
[E 2B100|  80800/50000 (162%) ] Loss: 1.7603 top1= 33.3750
[E 2B110|  88800/50000 (178%) ] Loss: 1.8045 top1= 32.0000

=> Eval Loss=1.6842 top1= 35.4567

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 1.7528 top1= 34.1250
[E 3B10 |   8800/50000 ( 18%) ] Loss: 1.7593 top1= 33.7500
[E 3B20 |  16800/50000 ( 34%) ] Loss: 1.7993 top1= 32.6250
[E 3B30 |  24800/50000 ( 50%) ] Loss: 1.7828 top1= 30.1250
[E 3B40 |  32800/50000 ( 66%) ] Loss: 1.7705 top1= 34.1250
[E 3B50 |  40800/50000 ( 82%) ] Loss: 1.7838 top1= 31.2500
[E 3B60 |  48800/50000 ( 98%) ] Loss: 1.7209 top1= 33.6250
[E 3B70 |  56800/50000 (114%) ] Loss: 1.7596 top1= 34.6250
[E 3B80 |  64800/50000 (130%) ] Loss: 1.6966 top1= 36.0000
[E 3B90 |  72800/50000 (146%) ] Loss: 1.7348 top1= 35.2500
[E 3B100|  80800/50000 (162%) ] Loss: 1.6825 top1= 38.0000
[E 3B110|  88800/50000 (178%) ] Loss: 1.6684 top1= 39.2500

=> Eval Loss=1.6042 top1= 39.2328

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 1.6738 top1= 38.8750
[E 4B10 |   8800/50000 ( 18%) ] Loss: 1.7596 top1= 34.3750
[E 4B20 |  16800/50000 ( 34%) ] Loss: 1.7015 top1= 36.5000
[E 4B30 |  24800/50000 ( 50%) ] Loss: 1.7413 top1= 33.3750
[E 4B40 |  32800/50000 ( 66%) ] Loss: 1.6435 top1= 36.6250
[E 4B50 |  40800/50000 ( 82%) ] Loss: 1.6017 top1= 39.5000
[E 4B60 |  48800/50000 ( 98%) ] Loss: 1.6493 top1= 35.3750
[E 4B70 |  56800/50000 (114%) ] Loss: 1.7164 top1= 40.5000
[E 4B80 |  64800/50000 (130%) ] Loss: 1.6397 top1= 42.7500
[E 4B90 |  72800/50000 (146%) ] Loss: 1.6637 top1= 38.1250
[E 4B100|  80800/50000 (162%) ] Loss: 1.6123 top1= 39.7500
[E 4B110|  88800/50000 (178%) ] Loss: 1.6518 top1= 37.8750

=> Eval Loss=1.5555 top1= 40.7552

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 1.5997 top1= 39.0000
[E 5B10 |   8800/50000 ( 18%) ] Loss: 1.6363 top1= 40.7500
[E 5B20 |  16800/50000 ( 34%) ] Loss: 1.6669 top1= 36.8750
[E 5B30 |  24800/50000 ( 50%) ] Loss: 1.6226 top1= 39.6250
[E 5B40 |  32800/50000 ( 66%) ] Loss: 1.6493 top1= 41.6250
[E 5B50 |  40800/50000 ( 82%) ] Loss: 1.6087 top1= 40.2500
[E 5B60 |  48800/50000 ( 98%) ] Loss: 1.5693 top1= 37.3750
[E 5B70 |  56800/50000 (114%) ] Loss: 1.5656 top1= 40.3750
[E 5B80 |  64800/50000 (130%) ] Loss: 1.5248 top1= 42.5000
[E 5B90 |  72800/50000 (146%) ] Loss: 1.6003 top1= 40.2500
[E 5B100|  80800/50000 (162%) ] Loss: 1.5677 top1= 42.7500
[E 5B110|  88800/50000 (178%) ] Loss: 1.5931 top1= 41.5000

=> Eval Loss=1.5066 top1= 44.6915

Train epoch 6
[E 6B0  |    800/50000 (  2%) ] Loss: 1.6057 top1= 39.5000
[E 6B10 |   8800/50000 ( 18%) ] Loss: 1.5331 top1= 47.5000
[E 6B20 |  16800/50000 ( 34%) ] Loss: 1.5216 top1= 41.3750
[E 6B30 |  24800/50000 ( 50%) ] Loss: 1.5227 top1= 41.3750
[E 6B40 |  32800/50000 ( 66%) ] Loss: 1.5157 top1= 44.5000
[E 6B50 |  40800/50000 ( 82%) ] Loss: 1.6004 top1= 39.7500
[E 6B60 |  48800/50000 ( 98%) ] Loss: 1.5045 top1= 43.0000
[E 6B70 |  56800/50000 (114%) ] Loss: 1.4303 top1= 44.8750
[E 6B80 |  64800/50000 (130%) ] Loss: 1.6155 top1= 41.7500
[E 6B90 |  72800/50000 (146%) ] Loss: 1.5037 top1= 43.1250
[E 6B100|  80800/50000 (162%) ] Loss: 1.5470 top1= 43.8750
[E 6B110|  88800/50000 (178%) ] Loss: 1.4781 top1= 46.0000

=> Eval Loss=1.4273 top1= 47.7063

Train epoch 7
[E 7B0  |    800/50000 (  2%) ] Loss: 1.5062 top1= 42.3750
[E 7B10 |   8800/50000 ( 18%) ] Loss: 1.4815 top1= 45.8750
[E 7B20 |  16800/50000 ( 34%) ] Loss: 1.4990 top1= 41.1250
[E 7B30 |  24800/50000 ( 50%) ] Loss: 1.4072 top1= 46.7500
[E 7B40 |  32800/50000 ( 66%) ] Loss: 1.4294 top1= 49.3750
[E 7B50 |  40800/50000 ( 82%) ] Loss: 1.5270 top1= 44.1250
[E 7B60 |  48800/50000 ( 98%) ] Loss: 1.3834 top1= 48.7500
[E 7B70 |  56800/50000 (114%) ] Loss: 1.4499 top1= 44.1250
[E 7B80 |  64800/50000 (130%) ] Loss: 1.4424 top1= 45.2500
[E 7B90 |  72800/50000 (146%) ] Loss: 1.4610 top1= 43.2500
[E 7B100|  80800/50000 (162%) ] Loss: 1.4749 top1= 46.6250
[E 7B110|  88800/50000 (178%) ] Loss: 1.4387 top1= 42.6250

=> Eval Loss=1.3687 top1= 49.1486

Train epoch 8
[E 8B0  |    800/50000 (  2%) ] Loss: 1.5063 top1= 46.1250
[E 8B10 |   8800/50000 ( 18%) ] Loss: 1.4029 top1= 48.5000
[E 8B20 |  16800/50000 ( 34%) ] Loss: 1.5984 top1= 43.6250
[E 8B30 |  24800/50000 ( 50%) ] Loss: 1.4076 top1= 50.2500
[E 8B40 |  32800/50000 ( 66%) ] Loss: 1.4050 top1= 49.0000
[E 8B50 |  40800/50000 ( 82%) ] Loss: 1.3200 top1= 49.6250
[E 8B60 |  48800/50000 ( 98%) ] Loss: 1.3322 top1= 49.7500
[E 8B70 |  56800/50000 (114%) ] Loss: 1.3501 top1= 52.2500
[E 8B80 |  64800/50000 (130%) ] Loss: 1.3456 top1= 50.5000
[E 8B90 |  72800/50000 (146%) ] Loss: 1.4730 top1= 43.8750
[E 8B100|  80800/50000 (162%) ] Loss: 1.4488 top1= 49.3750
[E 8B110|  88800/50000 (178%) ] Loss: 1.3556 top1= 53.3750

=> Eval Loss=1.2831 top1= 53.3654

Train epoch 9
[E 9B0  |    800/50000 (  2%) ] Loss: 1.2972 top1= 50.6250
[E 9B10 |   8800/50000 ( 18%) ] Loss: 1.3871 top1= 53.8750
[E 9B20 |  16800/50000 ( 34%) ] Loss: 1.2811 top1= 55.8750
[E 9B30 |  24800/50000 ( 50%) ] Loss: 1.3593 top1= 52.0000
[E 9B40 |  32800/50000 ( 66%) ] Loss: 1.3927 top1= 52.1250
[E 9B50 |  40800/50000 ( 82%) ] Loss: 1.3526 top1= 52.2500
[E 9B60 |  48800/50000 ( 98%) ] Loss: 1.4300 top1= 49.7500
[E 9B70 |  56800/50000 (114%) ] Loss: 1.3574 top1= 49.3750
[E 9B80 |  64800/50000 (130%) ] Loss: 1.4696 top1= 46.6250
[E 9B90 |  72800/50000 (146%) ] Loss: 1.3617 top1= 53.1250
[E 9B100|  80800/50000 (162%) ] Loss: 1.3005 top1= 53.5000
[E 9B110|  88800/50000 (178%) ] Loss: 1.4010 top1= 48.7500

=> Eval Loss=1.3093 top1= 52.8846

Train epoch 10
[E10B0  |    800/50000 (  2%) ] Loss: 1.2771 top1= 54.3750
[E10B10 |   8800/50000 ( 18%) ] Loss: 1.3606 top1= 52.5000
[E10B20 |  16800/50000 ( 34%) ] Loss: 1.4179 top1= 50.3750
[E10B30 |  24800/50000 ( 50%) ] Loss: 1.3551 top1= 47.2500
[E10B40 |  32800/50000 ( 66%) ] Loss: 1.3756 top1= 46.8750
[E10B50 |  40800/50000 ( 82%) ] Loss: 1.2110 top1= 54.0000
[E10B60 |  48800/50000 ( 98%) ] Loss: 1.2953 top1= 54.3750
[E10B70 |  56800/50000 (114%) ] Loss: 1.2491 top1= 55.5000
[E10B80 |  64800/50000 (130%) ] Loss: 1.3744 top1= 53.0000
[E10B90 |  72800/50000 (146%) ] Loss: 1.3083 top1= 53.7500
[E10B100|  80800/50000 (162%) ] Loss: 1.3176 top1= 50.7500
[E10B110|  88800/50000 (178%) ] Loss: 1.3238 top1= 55.3750

=> Eval Loss=1.2702 top1= 54.0865

Train epoch 11
[E11B0  |    800/50000 (  2%) ] Loss: 1.3252 top1= 53.7500
[E11B10 |   8800/50000 ( 18%) ] Loss: 1.2232 top1= 55.6250
[E11B20 |  16800/50000 ( 34%) ] Loss: 1.3640 top1= 53.1250
[E11B30 |  24800/50000 ( 50%) ] Loss: 1.3142 top1= 52.6250
[E11B40 |  32800/50000 ( 66%) ] Loss: 1.2446 top1= 54.6250
[E11B50 |  40800/50000 ( 82%) ] Loss: 1.2713 top1= 55.5000
[E11B60 |  48800/50000 ( 98%) ] Loss: 1.2075 top1= 57.2500
[E11B70 |  56800/50000 (114%) ] Loss: 1.3781 top1= 52.3750
[E11B80 |  64800/50000 (130%) ] Loss: 1.2562 top1= 54.6250
[E11B90 |  72800/50000 (146%) ] Loss: 1.2657 top1= 54.8750
[E11B100|  80800/50000 (162%) ] Loss: 1.3030 top1= 52.2500
[E11B110|  88800/50000 (178%) ] Loss: 1.2479 top1= 58.1250

=> Eval Loss=1.2210 top1= 56.0196

Train epoch 12
[E12B0  |    800/50000 (  2%) ] Loss: 1.2888 top1= 55.2500
[E12B10 |   8800/50000 ( 18%) ] Loss: 1.3903 top1= 50.3750
[E12B20 |  16800/50000 ( 34%) ] Loss: 1.3148 top1= 53.7500
[E12B30 |  24800/50000 ( 50%) ] Loss: 1.3086 top1= 54.7500
[E12B40 |  32800/50000 ( 66%) ] Loss: 1.2670 top1= 53.1250
[E12B50 |  40800/50000 ( 82%) ] Loss: 1.2459 top1= 56.3750
[E12B60 |  48800/50000 ( 98%) ] Loss: 1.3410 top1= 51.8750
[E12B70 |  56800/50000 (114%) ] Loss: 1.2953 top1= 50.2500
[E12B80 |  64800/50000 (130%) ] Loss: 1.2806 top1= 53.5000
[E12B90 |  72800/50000 (146%) ] Loss: 1.3356 top1= 55.1250
[E12B100|  80800/50000 (162%) ] Loss: 1.2599 top1= 53.6250
[E12B110|  88800/50000 (178%) ] Loss: 1.1926 top1= 57.2500

=> Eval Loss=1.1835 top1= 57.2015

Train epoch 13
[E13B0  |    800/50000 (  2%) ] Loss: 1.1051 top1= 59.2500
[E13B10 |   8800/50000 ( 18%) ] Loss: 1.2897 top1= 53.6250
[E13B20 |  16800/50000 ( 34%) ] Loss: 1.1514 top1= 58.7500
[E13B30 |  24800/50000 ( 50%) ] Loss: 1.3409 top1= 51.5000
[E13B40 |  32800/50000 ( 66%) ] Loss: 1.2947 top1= 54.7500
[E13B50 |  40800/50000 ( 82%) ] Loss: 1.2418 top1= 54.2500
[E13B60 |  48800/50000 ( 98%) ] Loss: 1.2667 top1= 54.2500
[E13B70 |  56800/50000 (114%) ] Loss: 1.2951 top1= 52.7500
[E13B80 |  64800/50000 (130%) ] Loss: 1.1412 top1= 58.8750
[E13B90 |  72800/50000 (146%) ] Loss: 1.2989 top1= 56.6250
[E13B100|  80800/50000 (162%) ] Loss: 1.3173 top1= 51.8750
[E13B110|  88800/50000 (178%) ] Loss: 1.3007 top1= 52.7500

=> Eval Loss=1.1707 top1= 58.5737

Train epoch 14
[E14B0  |    800/50000 (  2%) ] Loss: 1.2159 top1= 54.8750
[E14B10 |   8800/50000 ( 18%) ] Loss: 1.2720 top1= 56.3750
[E14B20 |  16800/50000 ( 34%) ] Loss: 1.2234 top1= 56.0000
[E14B30 |  24800/50000 ( 50%) ] Loss: 1.2282 top1= 56.3750
[E14B40 |  32800/50000 ( 66%) ] Loss: 1.2552 top1= 55.1250
[E14B50 |  40800/50000 ( 82%) ] Loss: 1.1086 top1= 60.8750
[E14B60 |  48800/50000 ( 98%) ] Loss: 1.2532 top1= 52.6250
[E14B70 |  56800/50000 (114%) ] Loss: 1.1097 top1= 58.8750
[E14B80 |  64800/50000 (130%) ] Loss: 1.1601 top1= 59.5000
[E14B90 |  72800/50000 (146%) ] Loss: 1.1621 top1= 55.3750
[E14B100|  80800/50000 (162%) ] Loss: 1.1570 top1= 60.1250
[E14B110|  88800/50000 (178%) ] Loss: 1.2455 top1= 56.5000

=> Eval Loss=1.1464 top1= 58.6138

Train epoch 15
[E15B0  |    800/50000 (  2%) ] Loss: 1.1492 top1= 58.2500
[E15B10 |   8800/50000 ( 18%) ] Loss: 1.2121 top1= 56.5000
[E15B20 |  16800/50000 ( 34%) ] Loss: 1.1902 top1= 58.1250
[E15B30 |  24800/50000 ( 50%) ] Loss: 1.1211 top1= 59.7500
[E15B40 |  32800/50000 ( 66%) ] Loss: 1.1501 top1= 53.1250
[E15B50 |  40800/50000 ( 82%) ] Loss: 1.2145 top1= 56.3750
[E15B60 |  48800/50000 ( 98%) ] Loss: 1.2028 top1= 58.6250
[E15B70 |  56800/50000 (114%) ] Loss: 1.1842 top1= 57.2500
[E15B80 |  64800/50000 (130%) ] Loss: 1.1687 top1= 56.8750
[E15B90 |  72800/50000 (146%) ] Loss: 1.1575 top1= 60.3750
[E15B100|  80800/50000 (162%) ] Loss: 1.1831 top1= 59.0000
[E15B110|  88800/50000 (178%) ] Loss: 1.1133 top1= 57.6250

=> Eval Loss=1.1240 top1= 58.8141

Train epoch 16
[E16B0  |    800/50000 (  2%) ] Loss: 1.1090 top1= 59.8750
[E16B10 |   8800/50000 ( 18%) ] Loss: 1.2490 top1= 56.3750
[E16B20 |  16800/50000 ( 34%) ] Loss: 1.0967 top1= 60.6250
[E16B30 |  24800/50000 ( 50%) ] Loss: 1.2330 top1= 54.5000
[E16B40 |  32800/50000 ( 66%) ] Loss: 1.1526 top1= 56.7500
[E16B50 |  40800/50000 ( 82%) ] Loss: 1.1294 top1= 58.2500
[E16B60 |  48800/50000 ( 98%) ] Loss: 1.1280 top1= 58.7500
[E16B70 |  56800/50000 (114%) ] Loss: 1.1240 top1= 58.3750
[E16B80 |  64800/50000 (130%) ] Loss: 1.0825 top1= 60.6250
[E16B90 |  72800/50000 (146%) ] Loss: 1.1894 top1= 56.7500
[E16B100|  80800/50000 (162%) ] Loss: 1.1804 top1= 57.0000
[E16B110|  88800/50000 (178%) ] Loss: 1.1413 top1= 57.2500

=> Eval Loss=1.1386 top1= 59.3550

Train epoch 17
[E17B0  |    800/50000 (  2%) ] Loss: 1.2031 top1= 58.2500
[E17B10 |   8800/50000 ( 18%) ] Loss: 1.0775 top1= 61.3750
[E17B20 |  16800/50000 ( 34%) ] Loss: 1.1560 top1= 59.3750
[E17B30 |  24800/50000 ( 50%) ] Loss: 1.1042 top1= 58.5000
[E17B40 |  32800/50000 ( 66%) ] Loss: 1.1630 top1= 59.3750
[E17B50 |  40800/50000 ( 82%) ] Loss: 1.1043 top1= 60.5000
[E17B60 |  48800/50000 ( 98%) ] Loss: 1.1781 top1= 57.6250
[E17B70 |  56800/50000 (114%) ] Loss: 1.1797 top1= 58.5000
[E17B80 |  64800/50000 (130%) ] Loss: 1.1426 top1= 59.8750
[E17B90 |  72800/50000 (146%) ] Loss: 1.0963 top1= 62.1250
[E17B100|  80800/50000 (162%) ] Loss: 1.1276 top1= 60.3750
[E17B110|  88800/50000 (178%) ] Loss: 1.0734 top1= 61.1250

=> Eval Loss=1.0900 top1= 60.6070

Train epoch 18
[E18B0  |    800/50000 (  2%) ] Loss: 1.1700 top1= 59.7500
[E18B10 |   8800/50000 ( 18%) ] Loss: 1.1781 top1= 58.2500
[E18B20 |  16800/50000 ( 34%) ] Loss: 1.0668 top1= 62.6250
[E18B30 |  24800/50000 ( 50%) ] Loss: 1.1161 top1= 58.0000
[E18B40 |  32800/50000 ( 66%) ] Loss: 1.0946 top1= 61.3750
[E18B50 |  40800/50000 ( 82%) ] Loss: 1.0869 top1= 61.7500
[E18B60 |  48800/50000 ( 98%) ] Loss: 1.1601 top1= 58.7500
[E18B70 |  56800/50000 (114%) ] Loss: 1.1443 top1= 60.1250
[E18B80 |  64800/50000 (130%) ] Loss: 1.1224 top1= 62.0000
[E18B90 |  72800/50000 (146%) ] Loss: 1.1767 top1= 56.2500
[E18B100|  80800/50000 (162%) ] Loss: 1.0603 top1= 65.6250
[E18B110|  88800/50000 (178%) ] Loss: 1.1467 top1= 58.0000

=> Eval Loss=1.0614 top1= 61.7488

Train epoch 19
[E19B0  |    800/50000 (  2%) ] Loss: 1.0249 top1= 62.7500
[E19B10 |   8800/50000 ( 18%) ] Loss: 1.0107 top1= 63.6250
[E19B20 |  16800/50000 ( 34%) ] Loss: 1.0457 top1= 62.6250
[E19B30 |  24800/50000 ( 50%) ] Loss: 1.0462 top1= 63.8750
[E19B40 |  32800/50000 ( 66%) ] Loss: 1.0772 top1= 63.3750
[E19B50 |  40800/50000 ( 82%) ] Loss: 1.0903 top1= 59.3750
[E19B60 |  48800/50000 ( 98%) ] Loss: 1.1243 top1= 58.6250
[E19B70 |  56800/50000 (114%) ] Loss: 1.1540 top1= 58.8750
[E19B80 |  64800/50000 (130%) ] Loss: 1.1456 top1= 56.1250
[E19B90 |  72800/50000 (146%) ] Loss: 1.1694 top1= 60.6250
[E19B100|  80800/50000 (162%) ] Loss: 1.1387 top1= 58.1250
[E19B110|  88800/50000 (178%) ] Loss: 1.1016 top1= 59.8750

=> Eval Loss=1.0567 top1= 61.6787

Train epoch 20
[E20B0  |    800/50000 (  2%) ] Loss: 1.0712 top1= 60.8750
[E20B10 |   8800/50000 ( 18%) ] Loss: 1.0683 top1= 59.2500
[E20B20 |  16800/50000 ( 34%) ] Loss: 1.0507 top1= 65.1250
[E20B30 |  24800/50000 ( 50%) ] Loss: 1.1727 top1= 55.3750
[E20B40 |  32800/50000 ( 66%) ] Loss: 1.0727 top1= 61.3750
[E20B50 |  40800/50000 ( 82%) ] Loss: 1.0615 top1= 58.8750
[E20B60 |  48800/50000 ( 98%) ] Loss: 1.0771 top1= 59.8750
[E20B70 |  56800/50000 (114%) ] Loss: 1.0831 top1= 62.1250
[E20B80 |  64800/50000 (130%) ] Loss: 1.1109 top1= 61.6250
[E20B90 |  72800/50000 (146%) ] Loss: 1.0576 top1= 61.8750
[E20B100|  80800/50000 (162%) ] Loss: 1.1636 top1= 59.0000
[E20B110|  88800/50000 (178%) ] Loss: 1.0852 top1= 62.5000

=> Eval Loss=1.0376 top1= 63.1210

Train epoch 21
[E21B0  |    800/50000 (  2%) ] Loss: 1.0696 top1= 61.0000
[E21B10 |   8800/50000 ( 18%) ] Loss: 1.0222 top1= 61.5000
[E21B20 |  16800/50000 ( 34%) ] Loss: 1.0899 top1= 59.8750
[E21B30 |  24800/50000 ( 50%) ] Loss: 1.1550 top1= 59.1250
[E21B40 |  32800/50000 ( 66%) ] Loss: 1.1265 top1= 61.1250
[E21B50 |  40800/50000 ( 82%) ] Loss: 1.0546 top1= 59.2500
[E21B60 |  48800/50000 ( 98%) ] Loss: 1.1305 top1= 59.5000
[E21B70 |  56800/50000 (114%) ] Loss: 1.1216 top1= 60.5000
[E21B80 |  64800/50000 (130%) ] Loss: 1.1502 top1= 59.3750
[E21B90 |  72800/50000 (146%) ] Loss: 1.0661 top1= 58.3750
[E21B100|  80800/50000 (162%) ] Loss: 1.1051 top1= 61.7500
[E21B110|  88800/50000 (178%) ] Loss: 1.0833 top1= 62.0000

=> Eval Loss=1.0377 top1= 62.9808

Train epoch 22
[E22B0  |    800/50000 (  2%) ] Loss: 1.0982 top1= 60.2500
[E22B10 |   8800/50000 ( 18%) ] Loss: 1.0531 top1= 63.7500
[E22B20 |  16800/50000 ( 34%) ] Loss: 1.2231 top1= 55.0000
[E22B30 |  24800/50000 ( 50%) ] Loss: 1.0594 top1= 63.2500
[E22B40 |  32800/50000 ( 66%) ] Loss: 1.0687 top1= 62.0000
[E22B50 |  40800/50000 ( 82%) ] Loss: 1.0548 top1= 63.7500
[E22B60 |  48800/50000 ( 98%) ] Loss: 1.1077 top1= 60.6250
[E22B70 |  56800/50000 (114%) ] Loss: 0.9224 top1= 69.5000
[E22B80 |  64800/50000 (130%) ] Loss: 1.0714 top1= 60.0000
[E22B90 |  72800/50000 (146%) ] Loss: 1.1026 top1= 60.7500
[E22B100|  80800/50000 (162%) ] Loss: 0.9937 top1= 64.2500
[E22B110|  88800/50000 (178%) ] Loss: 1.0055 top1= 65.2500

=> Eval Loss=1.0036 top1= 64.3029

Train epoch 23
[E23B0  |    800/50000 (  2%) ] Loss: 1.0354 top1= 60.8750
[E23B10 |   8800/50000 ( 18%) ] Loss: 1.1931 top1= 58.1250
[E23B20 |  16800/50000 ( 34%) ] Loss: 1.0365 top1= 61.8750
[E23B30 |  24800/50000 ( 50%) ] Loss: 1.0732 top1= 63.8750
[E23B40 |  32800/50000 ( 66%) ] Loss: 1.0532 top1= 63.6250
[E23B50 |  40800/50000 ( 82%) ] Loss: 1.0520 top1= 62.2500
[E23B60 |  48800/50000 ( 98%) ] Loss: 1.0861 top1= 59.7500
[E23B70 |  56800/50000 (114%) ] Loss: 0.9616 top1= 64.5000
[E23B80 |  64800/50000 (130%) ] Loss: 1.0227 top1= 62.0000
[E23B90 |  72800/50000 (146%) ] Loss: 1.0459 top1= 64.0000
[E23B100|  80800/50000 (162%) ] Loss: 1.0918 top1= 61.1250
[E23B110|  88800/50000 (178%) ] Loss: 1.0256 top1= 64.0000

=> Eval Loss=1.0195 top1= 64.5032

Train epoch 24
[E24B0  |    800/50000 (  2%) ] Loss: 1.0488 top1= 63.6250
[E24B10 |   8800/50000 ( 18%) ] Loss: 1.0725 top1= 60.8750
[E24B20 |  16800/50000 ( 34%) ] Loss: 1.0757 top1= 58.6250
[E24B30 |  24800/50000 ( 50%) ] Loss: 1.0923 top1= 63.1250
[E24B40 |  32800/50000 ( 66%) ] Loss: 1.0912 top1= 61.5000
[E24B50 |  40800/50000 ( 82%) ] Loss: 0.9975 top1= 64.2500
[E24B60 |  48800/50000 ( 98%) ] Loss: 0.9647 top1= 65.7500
[E24B70 |  56800/50000 (114%) ] Loss: 1.0303 top1= 63.5000
[E24B80 |  64800/50000 (130%) ] Loss: 1.0743 top1= 59.7500
[E24B90 |  72800/50000 (146%) ] Loss: 0.9574 top1= 64.7500
[E24B100|  80800/50000 (162%) ] Loss: 1.1309 top1= 60.5000
[E24B110|  88800/50000 (178%) ] Loss: 1.0203 top1= 62.6250

=> Eval Loss=1.0125 top1= 64.3229

Train epoch 25
[E25B0  |    800/50000 (  2%) ] Loss: 1.0202 top1= 63.5000
[E25B10 |   8800/50000 ( 18%) ] Loss: 1.1522 top1= 58.2500
[E25B20 |  16800/50000 ( 34%) ] Loss: 1.1512 top1= 59.2500
[E25B30 |  24800/50000 ( 50%) ] Loss: 1.0727 top1= 60.0000
[E25B40 |  32800/50000 ( 66%) ] Loss: 1.0539 top1= 62.7500
[E25B50 |  40800/50000 ( 82%) ] Loss: 1.0639 top1= 59.5000
[E25B60 |  48800/50000 ( 98%) ] Loss: 1.0148 top1= 64.5000
[E25B70 |  56800/50000 (114%) ] Loss: 1.0567 top1= 64.6250
[E25B80 |  64800/50000 (130%) ] Loss: 1.0615 top1= 61.7500
[E25B90 |  72800/50000 (146%) ] Loss: 1.0590 top1= 65.5000
[E25B100|  80800/50000 (162%) ] Loss: 1.1139 top1= 60.1250
[E25B110|  88800/50000 (178%) ] Loss: 1.1408 top1= 60.1250

=> Eval Loss=1.0420 top1= 63.1911

Train epoch 26
[E26B0  |    800/50000 (  2%) ] Loss: 0.9298 top1= 66.1250
[E26B10 |   8800/50000 ( 18%) ] Loss: 1.1190 top1= 59.1250
[E26B20 |  16800/50000 ( 34%) ] Loss: 1.1196 top1= 61.5000
[E26B30 |  24800/50000 ( 50%) ] Loss: 1.0957 top1= 57.8750
[E26B40 |  32800/50000 ( 66%) ] Loss: 0.9980 top1= 61.7500
[E26B50 |  40800/50000 ( 82%) ] Loss: 1.0530 top1= 64.2500
[E26B60 |  48800/50000 ( 98%) ] Loss: 1.0589 top1= 60.5000
[E26B70 |  56800/50000 (114%) ] Loss: 1.0227 top1= 64.1250
[E26B80 |  64800/50000 (130%) ] Loss: 1.0915 top1= 63.6250
[E26B90 |  72800/50000 (146%) ] Loss: 1.1484 top1= 59.5000
[E26B100|  80800/50000 (162%) ] Loss: 0.9923 top1= 64.2500
[E26B110|  88800/50000 (178%) ] Loss: 1.0743 top1= 60.1250

=> Eval Loss=1.0360 top1= 63.0008

Train epoch 27
[E27B0  |    800/50000 (  2%) ] Loss: 0.9662 top1= 64.0000
[E27B10 |   8800/50000 ( 18%) ] Loss: 1.0695 top1= 61.7500
[E27B20 |  16800/50000 ( 34%) ] Loss: 1.0610 top1= 59.7500
[E27B30 |  24800/50000 ( 50%) ] Loss: 0.9133 top1= 66.5000
[E27B40 |  32800/50000 ( 66%) ] Loss: 0.9947 top1= 62.0000
[E27B50 |  40800/50000 ( 82%) ] Loss: 1.0575 top1= 59.5000
[E27B60 |  48800/50000 ( 98%) ] Loss: 1.0928 top1= 61.5000
[E27B70 |  56800/50000 (114%) ] Loss: 1.0817 top1= 62.3750
[E27B80 |  64800/50000 (130%) ] Loss: 1.0502 top1= 61.8750
[E27B90 |  72800/50000 (146%) ] Loss: 1.0048 top1= 65.7500
[E27B100|  80800/50000 (162%) ] Loss: 1.0256 top1= 62.0000
[E27B110|  88800/50000 (178%) ] Loss: 1.0483 top1= 61.0000

=> Eval Loss=0.9887 top1= 64.7636

Train epoch 28
[E28B0  |    800/50000 (  2%) ] Loss: 0.9853 top1= 63.5000
[E28B10 |   8800/50000 ( 18%) ] Loss: 1.0037 top1= 65.3750
[E28B20 |  16800/50000 ( 34%) ] Loss: 1.0348 top1= 64.5000
[E28B30 |  24800/50000 ( 50%) ] Loss: 1.0307 top1= 66.1250
[E28B40 |  32800/50000 ( 66%) ] Loss: 1.0536 top1= 62.1250
[E28B50 |  40800/50000 ( 82%) ] Loss: 1.0069 top1= 64.0000
[E28B60 |  48800/50000 ( 98%) ] Loss: 1.0662 top1= 64.7500
[E28B70 |  56800/50000 (114%) ] Loss: 0.9958 top1= 60.0000
[E28B80 |  64800/50000 (130%) ] Loss: 0.9648 top1= 63.8750
[E28B90 |  72800/50000 (146%) ] Loss: 0.9806 top1= 65.5000
[E28B100|  80800/50000 (162%) ] Loss: 1.0794 top1= 62.5000
[E28B110|  88800/50000 (178%) ] Loss: 1.0173 top1= 65.8750

=> Eval Loss=0.9837 top1= 65.4447

Train epoch 29
[E29B0  |    800/50000 (  2%) ] Loss: 1.0317 top1= 61.6250
[E29B10 |   8800/50000 ( 18%) ] Loss: 1.0247 top1= 60.8750
[E29B20 |  16800/50000 ( 34%) ] Loss: 0.9466 top1= 64.2500
[E29B30 |  24800/50000 ( 50%) ] Loss: 1.0708 top1= 58.8750
[E29B40 |  32800/50000 ( 66%) ] Loss: 0.9454 top1= 66.8750
[E29B50 |  40800/50000 ( 82%) ] Loss: 1.0354 top1= 62.0000
[E29B60 |  48800/50000 ( 98%) ] Loss: 0.9858 top1= 67.5000
[E29B70 |  56800/50000 (114%) ] Loss: 0.9657 top1= 63.3750
[E29B80 |  64800/50000 (130%) ] Loss: 0.9939 top1= 65.1250
[E29B90 |  72800/50000 (146%) ] Loss: 0.9923 top1= 65.6250
[E29B100|  80800/50000 (162%) ] Loss: 1.0899 top1= 61.1250
[E29B110|  88800/50000 (178%) ] Loss: 0.9236 top1= 69.1250

=> Eval Loss=0.9684 top1= 65.4147

Train epoch 30
[E30B0  |    800/50000 (  2%) ] Loss: 1.0347 top1= 63.1250
[E30B10 |   8800/50000 ( 18%) ] Loss: 0.9962 top1= 64.5000
[E30B20 |  16800/50000 ( 34%) ] Loss: 1.0773 top1= 59.6250
[E30B30 |  24800/50000 ( 50%) ] Loss: 1.0224 top1= 64.7500
[E30B40 |  32800/50000 ( 66%) ] Loss: 1.0531 top1= 64.2500
[E30B50 |  40800/50000 ( 82%) ] Loss: 0.9763 top1= 64.2500
[E30B60 |  48800/50000 ( 98%) ] Loss: 0.9865 top1= 62.8750
[E30B70 |  56800/50000 (114%) ] Loss: 0.8857 top1= 69.3750
[E30B80 |  64800/50000 (130%) ] Loss: 0.9742 top1= 65.1250
[E30B90 |  72800/50000 (146%) ] Loss: 0.9778 top1= 65.7500
[E30B100|  80800/50000 (162%) ] Loss: 0.9127 top1= 66.3750
[E30B110|  88800/50000 (178%) ] Loss: 0.9468 top1= 68.0000

=> Eval Loss=1.0024 top1= 64.8838

Train epoch 31
[E31B0  |    800/50000 (  2%) ] Loss: 1.0301 top1= 63.6250
[E31B10 |   8800/50000 ( 18%) ] Loss: 0.9264 top1= 66.6250
[E31B20 |  16800/50000 ( 34%) ] Loss: 0.9960 top1= 61.7500
[E31B30 |  24800/50000 ( 50%) ] Loss: 0.9930 top1= 65.2500
[E31B40 |  32800/50000 ( 66%) ] Loss: 0.9091 top1= 66.7500
[E31B50 |  40800/50000 ( 82%) ] Loss: 1.0614 top1= 65.1250
[E31B60 |  48800/50000 ( 98%) ] Loss: 1.0265 top1= 66.1250
[E31B70 |  56800/50000 (114%) ] Loss: 1.0372 top1= 62.5000
[E31B80 |  64800/50000 (130%) ] Loss: 0.9227 top1= 63.8750
[E31B90 |  72800/50000 (146%) ] Loss: 0.9901 top1= 65.7500
[E31B100|  80800/50000 (162%) ] Loss: 0.9970 top1= 64.2500
[E31B110|  88800/50000 (178%) ] Loss: 1.1252 top1= 57.6250

=> Eval Loss=0.9874 top1= 65.3746

Train epoch 32
[E32B0  |    800/50000 (  2%) ] Loss: 0.9269 top1= 68.3750
[E32B10 |   8800/50000 ( 18%) ] Loss: 0.9634 top1= 64.8750
[E32B20 |  16800/50000 ( 34%) ] Loss: 1.0310 top1= 65.7500
[E32B30 |  24800/50000 ( 50%) ] Loss: 1.0150 top1= 61.8750
[E32B40 |  32800/50000 ( 66%) ] Loss: 1.0703 top1= 63.0000
[E32B50 |  40800/50000 ( 82%) ] Loss: 1.0446 top1= 60.3750
[E32B60 |  48800/50000 ( 98%) ] Loss: 0.9524 top1= 64.1250
[E32B70 |  56800/50000 (114%) ] Loss: 0.9675 top1= 66.3750
[E32B80 |  64800/50000 (130%) ] Loss: 0.9516 top1= 64.2500
[E32B90 |  72800/50000 (146%) ] Loss: 1.0041 top1= 66.0000
[E32B100|  80800/50000 (162%) ] Loss: 0.9824 top1= 64.7500
[E32B110|  88800/50000 (178%) ] Loss: 0.9884 top1= 63.6250

=> Eval Loss=0.9694 top1= 66.2360

Train epoch 33
[E33B0  |    800/50000 (  2%) ] Loss: 1.0176 top1= 65.1250
[E33B10 |   8800/50000 ( 18%) ] Loss: 0.9505 top1= 64.0000
[E33B20 |  16800/50000 ( 34%) ] Loss: 1.0243 top1= 63.6250
[E33B30 |  24800/50000 ( 50%) ] Loss: 0.9406 top1= 63.8750
[E33B40 |  32800/50000 ( 66%) ] Loss: 1.0365 top1= 65.3750
[E33B50 |  40800/50000 ( 82%) ] Loss: 0.8887 top1= 69.7500
