ParallelTrainer(aggregator=RFA(T=3,nu=0.1), max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.4202 top1= 10.8750
[E 1B10 |   8800/50000 ( 18%) ] Loss: 2.5331 top1=  8.5000
[E 1B20 |  16800/50000 ( 34%) ] Loss: 2.6553 top1=  8.1250
[E 1B30 |  24800/50000 ( 50%) ] Loss: 2.6577 top1= 10.3750
[E 1B40 |  32800/50000 ( 66%) ] Loss: 2.7066 top1=  9.7500
[E 1B50 |  40800/50000 ( 82%) ] Loss: 2.6876 top1= 10.2500
[E 1B60 |  48800/50000 ( 98%) ] Loss: 2.6935 top1= 11.0000
[E 1B70 |  56800/50000 (114%) ] Loss: 2.6500 top1= 10.8750
[E 1B80 |  64800/50000 (130%) ] Loss: 2.7019 top1=  9.0000
[E 1B90 |  72800/50000 (146%) ] Loss: 2.6881 top1= 10.7500
[E 1B100|  80800/50000 (162%) ] Loss: 2.6399 top1=  8.6250
[E 1B110|  88800/50000 (178%) ] Loss: 2.7089 top1=  8.2500

=> Eval Loss=2.6745 top1=  9.9860

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 2.6800 top1=  9.0000
[E 2B10 |   8800/50000 ( 18%) ] Loss: 2.7429 top1=  8.2500
[E 2B20 |  16800/50000 ( 34%) ] Loss: 2.6975 top1=  8.5000
[E 2B30 |  24800/50000 ( 50%) ] Loss: 2.7054 top1= 10.1250
[E 2B40 |  32800/50000 ( 66%) ] Loss: 2.6668 top1= 11.5000
[E 2B50 |  40800/50000 ( 82%) ] Loss: 2.7190 top1=  8.1250
[E 2B60 |  48800/50000 ( 98%) ] Loss: 2.6733 top1= 11.8750
[E 2B70 |  56800/50000 (114%) ] Loss: 2.6851 top1=  9.0000
[E 2B80 |  64800/50000 (130%) ] Loss: 2.6970 top1=  9.8750
[E 2B90 |  72800/50000 (146%) ] Loss: 2.6821 top1= 11.1250
[E 2B100|  80800/50000 (162%) ] Loss: 2.7415 top1=  9.2500
[E 2B110|  88800/50000 (178%) ] Loss: 2.6830 top1= 10.3750

=> Eval Loss=2.6988 top1=  9.9860

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 2.7243 top1=  9.5000
[E 3B10 |   8800/50000 ( 18%) ] Loss: 2.7386 top1=  7.5000
[E 3B20 |  16800/50000 ( 34%) ] Loss: 2.6793 top1= 10.6250
[E 3B30 |  24800/50000 ( 50%) ] Loss: 2.7089 top1=  9.5000
[E 3B40 |  32800/50000 ( 66%) ] Loss: 2.6819 top1= 10.6250
[E 3B50 |  40800/50000 ( 82%) ] Loss: 2.7428 top1=  9.5000
[E 3B60 |  48800/50000 ( 98%) ] Loss: 2.7096 top1= 10.3750
[E 3B70 |  56800/50000 (114%) ] Loss: 2.6848 top1=  9.3750
[E 3B80 |  64800/50000 (130%) ] Loss: 2.7456 top1=  7.7500
[E 3B90 |  72800/50000 (146%) ] Loss: 2.6661 top1= 12.7500
[E 3B100|  80800/50000 (162%) ] Loss: 2.7147 top1=  9.3750
[E 3B110|  88800/50000 (178%) ] Loss: 2.7278 top1= 10.8750

=> Eval Loss=2.6673 top1=  9.9860

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 2.6911 top1= 10.8750
[E 4B10 |   8800/50000 ( 18%) ] Loss: 2.6935 top1= 11.0000
[E 4B20 |  16800/50000 ( 34%) ] Loss: 2.6248 top1= 13.5000
[E 4B30 |  24800/50000 ( 50%) ] Loss: 2.6867 top1= 10.8750
[E 4B40 |  32800/50000 ( 66%) ] Loss: 2.7073 top1=  8.6250
[E 4B50 |  40800/50000 ( 82%) ] Loss: 2.6634 top1= 11.1250
[E 4B60 |  48800/50000 ( 98%) ] Loss: 2.6981 top1=  8.8750
[E 4B70 |  56800/50000 (114%) ] Loss: 2.7732 top1=  7.2500
[E 4B80 |  64800/50000 (130%) ] Loss: 2.6413 top1= 11.8750
[E 4B90 |  72800/50000 (146%) ] Loss: 2.7158 top1=  9.2500
[E 4B100|  80800/50000 (162%) ] Loss: 2.7409 top1= 10.0000
[E 4B110|  88800/50000 (178%) ] Loss: 2.7798 top1=  8.7500

=> Eval Loss=2.6813 top1=  9.9860

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 2.6504 top1= 11.2500
[E 5B10 |   8800/50000 ( 18%) ] Loss: 2.7366 top1= 11.3750
[E 5B20 |  16800/50000 ( 34%) ] Loss: 2.6221 top1= 15.1250
[E 5B30 |  24800/50000 ( 50%) ] Loss: 2.7595 top1=  9.8750
[E 5B40 |  32800/50000 ( 66%) ] Loss: 2.6660 top1=  7.5000
[E 5B50 |  40800/50000 ( 82%) ] Loss: 2.7536 top1= 10.7500
[E 5B60 |  48800/50000 ( 98%) ] Loss: 2.6732 top1= 11.0000
[E 5B70 |  56800/50000 (114%) ] Loss: 2.6958 top1=  7.5000
[E 5B80 |  64800/50000 (130%) ] Loss: 2.6688 top1=  9.2500
[E 5B90 |  72800/50000 (146%) ] Loss: 2.7031 top1= 10.0000
[E 5B100|  80800/50000 (162%) ] Loss: 2.7468 top1=  9.2500
[E 5B110|  88800/50000 (178%) ] Loss: 2.6151 top1= 13.1250

=> Eval Loss=2.7161 top1=  9.9860

Train epoch 6
[E 6B0  |    800/50000 (  2%) ] Loss: 2.6972 top1=  9.2500
[E 6B10 |   8800/50000 ( 18%) ] Loss: 2.7505 top1= 10.2500
[E 6B20 |  16800/50000 ( 34%) ] Loss: 2.6428 top1= 10.2500
[E 6B30 |  24800/50000 ( 50%) ] Loss: 2.7997 top1=  8.5000
[E 6B40 |  32800/50000 ( 66%) ] Loss: 2.7236 top1= 12.3750
[E 6B50 |  40800/50000 ( 82%) ] Loss: 2.7307 top1=  7.3750
[E 6B60 |  48800/50000 ( 98%) ] Loss: 2.7108 top1=  9.3750
[E 6B70 |  56800/50000 (114%) ] Loss: 2.6981 top1=  9.3750
[E 6B80 |  64800/50000 (130%) ] Loss: 2.6353 top1= 12.0000
[E 6B90 |  72800/50000 (146%) ] Loss: 2.7855 top1=  6.1250
[E 6B100|  80800/50000 (162%) ] Loss: 2.6970 top1= 10.1250
[E 6B110|  88800/50000 (178%) ] Loss: 2.6920 top1= 10.6250

=> Eval Loss=2.7043 top1=  9.9860

Train epoch 7
[E 7B0  |    800/50000 (  2%) ] Loss: 2.7287 top1= 10.0000
[E 7B10 |   8800/50000 ( 18%) ] Loss: 2.7264 top1= 10.6250
[E 7B20 |  16800/50000 ( 34%) ] Loss: 2.6958 top1=  9.8750
[E 7B30 |  24800/50000 ( 50%) ] Loss: 2.7512 top1=  8.5000
[E 7B40 |  32800/50000 ( 66%) ] Loss: 2.7299 top1=  9.6250
[E 7B50 |  40800/50000 ( 82%) ] Loss: 2.7864 top1=  8.1250
[E 7B60 |  48800/50000 ( 98%) ] Loss: 2.7151 top1=  9.5000
[E 7B70 |  56800/50000 (114%) ] Loss: 2.7310 top1= 10.5000
[E 7B80 |  64800/50000 (130%) ] Loss: 2.7147 top1=  9.8750
[E 7B90 |  72800/50000 (146%) ] Loss: 2.6688 top1= 10.3750
[E 7B100|  80800/50000 (162%) ] Loss: 2.6998 top1= 11.7500
[E 7B110|  88800/50000 (178%) ] Loss: 2.7641 top1= 10.2500

=> Eval Loss=2.6881 top1=  9.9860

Train epoch 8
[E 8B0  |    800/50000 (  2%) ] Loss: 2.6533 top1=  9.2500
[E 8B10 |   8800/50000 ( 18%) ] Loss: 2.7055 top1= 11.7500
[E 8B20 |  16800/50000 ( 34%) ] Loss: 2.6475 top1= 12.0000
[E 8B30 |  24800/50000 ( 50%) ] Loss: 2.6754 top1= 11.2500
[E 8B40 |  32800/50000 ( 66%) ] Loss: 2.7419 top1= 11.6250
[E 8B50 |  40800/50000 ( 82%) ] Loss: 2.6793 top1= 10.7500
[E 8B60 |  48800/50000 ( 98%) ] Loss: 2.7307 top1=  9.1250
[E 8B70 |  56800/50000 (114%) ] Loss: 2.6997 top1= 10.1250
[E 8B80 |  64800/50000 (130%) ] Loss: 2.6952 top1= 10.0000
[E 8B90 |  72800/50000 (146%) ] Loss: 2.7281 top1= 10.1250
[E 8B100|  80800/50000 (162%) ] Loss: 2.7222 top1=  9.3750
[E 8B110|  88800/50000 (178%) ] Loss: 2.7113 top1= 10.2500

=> Eval Loss=2.6877 top1=  9.9860

Train epoch 9
[E 9B0  |    800/50000 (  2%) ] Loss: 2.7768 top1=  8.0000
[E 9B10 |   8800/50000 ( 18%) ] Loss: 2.6836 top1= 12.7500
[E 9B20 |  16800/50000 ( 34%) ] Loss: 2.7811 top1=  7.5000
[E 9B30 |  24800/50000 ( 50%) ] Loss: 2.6909 top1= 10.6250
[E 9B40 |  32800/50000 ( 66%) ] Loss: 2.6826 top1= 10.8750
[E 9B50 |  40800/50000 ( 82%) ] Loss: 2.7047 top1=  9.1250
[E 9B60 |  48800/50000 ( 98%) ] Loss: 2.6988 top1= 10.2500
[E 9B70 |  56800/50000 (114%) ] Loss: 2.6675 top1= 10.3750
[E 9B80 |  64800/50000 (130%) ] Loss: 2.7078 top1= 10.3750
[E 9B90 |  72800/50000 (146%) ] Loss: 2.6808 top1= 10.5000
[E 9B100|  80800/50000 (162%) ] Loss: 2.7463 top1=  9.3750
[E 9B110|  88800/50000 (178%) ] Loss: 2.6646 top1= 12.1250

=> Eval Loss=2.7150 top1=  9.9860

Train epoch 10
[E10B0  |    800/50000 (  2%) ] Loss: 2.6645 top1= 11.2500
[E10B10 |   8800/50000 ( 18%) ] Loss: 2.6666 top1= 10.2500
[E10B20 |  16800/50000 ( 34%) ] Loss: 2.7231 top1=  8.7500
[E10B30 |  24800/50000 ( 50%) ] Loss: 2.6948 top1=  9.3750
[E10B40 |  32800/50000 ( 66%) ] Loss: 2.7450 top1=  9.3750
[E10B50 |  40800/50000 ( 82%) ] Loss: 2.7230 top1=  9.2500
[E10B60 |  48800/50000 ( 98%) ] Loss: 2.7414 top1=  9.2500
[E10B70 |  56800/50000 (114%) ] Loss: 2.7354 top1=  9.6250
[E10B80 |  64800/50000 (130%) ] Loss: 2.7229 top1=  9.6250
[E10B90 |  72800/50000 (146%) ] Loss: 2.7019 top1= 10.0000
[E10B100|  80800/50000 (162%) ] Loss: 2.7176 top1= 13.2500
[E10B110|  88800/50000 (178%) ] Loss: 2.6253 top1= 12.2500

=> Eval Loss=2.7087 top1=  9.9860

Train epoch 11
[E11B0  |    800/50000 (  2%) ] Loss: 2.7899 top1=  9.6250
[E11B10 |   8800/50000 ( 18%) ] Loss: 2.6952 top1= 11.3750
[E11B20 |  16800/50000 ( 34%) ] Loss: 2.7187 top1= 10.0000
[E11B30 |  24800/50000 ( 50%) ] Loss: 2.6957 top1=  9.6250
[E11B40 |  32800/50000 ( 66%) ] Loss: 2.7249 top1=  8.8750
[E11B50 |  40800/50000 ( 82%) ] Loss: 2.7345 top1=  9.0000
[E11B60 |  48800/50000 ( 98%) ] Loss: 2.7384 top1=  9.3750
[E11B70 |  56800/50000 (114%) ] Loss: 2.6309 top1= 11.6250
[E11B80 |  64800/50000 (130%) ] Loss: 2.7156 top1=  9.6250
[E11B90 |  72800/50000 (146%) ] Loss: 2.7716 top1=  9.0000
[E11B100|  80800/50000 (162%) ] Loss: 2.7412 top1=  9.5000
[E11B110|  88800/50000 (178%) ] Loss: 2.7245 top1= 11.0000

=> Eval Loss=2.7233 top1=  9.9860

Train epoch 12
[E12B0  |    800/50000 (  2%) ] Loss: 2.7663 top1= 10.1250
[E12B10 |   8800/50000 ( 18%) ] Loss: 2.6715 top1= 11.8750
[E12B20 |  16800/50000 ( 34%) ] Loss: 2.6174 top1= 14.0000
[E12B30 |  24800/50000 ( 50%) ] Loss: 2.6345 top1= 11.2500
[E12B40 |  32800/50000 ( 66%) ] Loss: 2.6519 top1= 11.2500
[E12B50 |  40800/50000 ( 82%) ] Loss: 2.7415 top1=  8.7500
[E12B60 |  48800/50000 ( 98%) ] Loss: 2.7296 top1= 10.2500
[E12B70 |  56800/50000 (114%) ] Loss: 2.7627 top1= 11.6250
[E12B80 |  64800/50000 (130%) ] Loss: 2.6990 top1= 11.5000
[E12B90 |  72800/50000 (146%) ] Loss: 2.7708 top1=  9.8750
[E12B100|  80800/50000 (162%) ] Loss: 2.7489 top1=  8.1250
[E12B110|  88800/50000 (178%) ] Loss: 2.7642 top1=  9.5000

=> Eval Loss=2.6947 top1=  9.9860

Train epoch 13
[E13B0  |    800/50000 (  2%) ] Loss: 2.7703 top1=  8.6250
[E13B10 |   8800/50000 ( 18%) ] Loss: 2.6928 top1= 10.3750
[E13B20 |  16800/50000 ( 34%) ] Loss: 2.7597 top1= 11.7500
[E13B30 |  24800/50000 ( 50%) ] Loss: 2.7684 top1= 10.3750
[E13B40 |  32800/50000 ( 66%) ] Loss: 2.7031 top1=  8.2500
[E13B50 |  40800/50000 ( 82%) ] Loss: 2.6997 top1= 10.6250
[E13B60 |  48800/50000 ( 98%) ] Loss: 2.8165 top1=  7.7500
[E13B70 |  56800/50000 (114%) ] Loss: 2.7413 top1= 10.1250
[E13B80 |  64800/50000 (130%) ] Loss: 2.7743 top1= 10.6250
[E13B90 |  72800/50000 (146%) ] Loss: 2.7277 top1=  9.5000
[E13B100|  80800/50000 (162%) ] Loss: 2.7390 top1= 10.2500
[E13B110|  88800/50000 (178%) ] Loss: 2.6792 top1= 11.5000

=> Eval Loss=2.7268 top1=  9.9860

Train epoch 14
[E14B0  |    800/50000 (  2%) ] Loss: 2.6887 top1= 10.2500
[E14B10 |   8800/50000 ( 18%) ] Loss: 2.6586 top1= 11.7500
[E14B20 |  16800/50000 ( 34%) ] Loss: 2.6868 top1= 11.3750
[E14B30 |  24800/50000 ( 50%) ] Loss: 2.6305 top1= 11.8750
[E14B40 |  32800/50000 ( 66%) ] Loss: 2.7160 top1=  9.5000
[E14B50 |  40800/50000 ( 82%) ] Loss: 2.7142 top1=  7.1250
[E14B60 |  48800/50000 ( 98%) ] Loss: 2.7500 top1=  8.6250
[E14B70 |  56800/50000 (114%) ] Loss: 2.7134 top1=  9.3750
[E14B80 |  64800/50000 (130%) ] Loss: 2.7455 top1= 10.2500
[E14B90 |  72800/50000 (146%) ] Loss: 2.6728 top1= 12.2500
[E14B100|  80800/50000 (162%) ] Loss: 2.7380 top1= 12.1250
[E14B110|  88800/50000 (178%) ] Loss: 2.7022 top1= 11.6250

=> Eval Loss=2.7526 top1=  9.9860

Train epoch 15
[E15B0  |    800/50000 (  2%) ] Loss: 2.7437 top1=  8.5000
[E15B10 |   8800/50000 ( 18%) ] Loss: 2.7592 top1=  9.2500
[E15B20 |  16800/50000 ( 34%) ] Loss: 2.7357 top1=  9.3750
[E15B30 |  24800/50000 ( 50%) ] Loss: 2.7525 top1=  8.0000
[E15B40 |  32800/50000 ( 66%) ] Loss: 2.7077 top1= 10.2500
[E15B50 |  40800/50000 ( 82%) ] Loss: 2.7654 top1= 10.6250
[E15B60 |  48800/50000 ( 98%) ] Loss: 2.6723 top1= 10.8750
[E15B70 |  56800/50000 (114%) ] Loss: 2.6978 top1= 13.1250
[E15B80 |  64800/50000 (130%) ] Loss: 2.7431 top1=  9.7500
[E15B90 |  72800/50000 (146%) ] Loss: 2.6830 top1= 12.3750
[E15B100|  80800/50000 (162%) ] Loss: 2.7453 top1=  8.8750
[E15B110|  88800/50000 (178%) ] Loss: 2.7085 top1= 13.0000

=> Eval Loss=2.6882 top1=  9.9860

Train epoch 16
[E16B0  |    800/50000 (  2%) ] Loss: 2.6863 top1= 10.1250
[E16B10 |   8800/50000 ( 18%) ] Loss: 2.7698 top1=  8.6250
[E16B20 |  16800/50000 ( 34%) ] Loss: 2.7116 top1= 10.1250
[E16B30 |  24800/50000 ( 50%) ] Loss: 2.7481 top1= 10.5000
[E16B40 |  32800/50000 ( 66%) ] Loss: 2.7224 top1= 11.1250
[E16B50 |  40800/50000 ( 82%) ] Loss: 2.7088 top1=  9.7500
[E16B60 |  48800/50000 ( 98%) ] Loss: 2.7345 top1=  9.1250
[E16B70 |  56800/50000 (114%) ] Loss: 2.7358 top1=  9.5000
[E16B80 |  64800/50000 (130%) ] Loss: 2.8123 top1=  8.3750
[E16B90 |  72800/50000 (146%) ] Loss: 2.7952 top1=  8.0000
[E16B100|  80800/50000 (162%) ] Loss: 2.7445 top1= 11.1250
[E16B110|  88800/50000 (178%) ] Loss: 2.7041 top1= 10.5000

=> Eval Loss=2.7272 top1=  9.9860

Train epoch 17
[E17B0  |    800/50000 (  2%) ] Loss: 2.6437 top1= 12.1250
[E17B10 |   8800/50000 ( 18%) ] Loss: 2.8035 top1=  8.3750
[E17B20 |  16800/50000 ( 34%) ] Loss: 2.7212 top1=  9.0000
[E17B30 |  24800/50000 ( 50%) ] Loss: 2.7332 top1=  9.7500
[E17B40 |  32800/50000 ( 66%) ] Loss: 2.7781 top1=  9.0000
[E17B50 |  40800/50000 ( 82%) ] Loss: 2.7289 top1= 10.5000
[E17B60 |  48800/50000 ( 98%) ] Loss: 2.8534 top1=  8.0000
[E17B70 |  56800/50000 (114%) ] Loss: 2.7589 top1= 11.2500
[E17B80 |  64800/50000 (130%) ] Loss: 2.7881 top1=  6.8750
[E17B90 |  72800/50000 (146%) ] Loss: 2.7293 top1= 10.3750
[E17B100|  80800/50000 (162%) ] Loss: 2.7637 top1=  8.2500
[E17B110|  88800/50000 (178%) ] Loss: 2.6696 top1= 10.3750

=> Eval Loss=2.7554 top1=  9.9860

Train epoch 18
[E18B0  |    800/50000 (  2%) ] Loss: 2.6795 top1= 13.1250
[E18B10 |   8800/50000 ( 18%) ] Loss: 2.7197 top1=  9.8750
[E18B20 |  16800/50000 ( 34%) ] Loss: 2.7790 top1=  8.8750
[E18B30 |  24800/50000 ( 50%) ] Loss: 2.8285 top1=  9.5000
[E18B40 |  32800/50000 ( 66%) ] Loss: 2.7341 top1= 10.5000
[E18B50 |  40800/50000 ( 82%) ] Loss: 2.7629 top1=  9.1250
[E18B60 |  48800/50000 ( 98%) ] Loss: 2.7389 top1=  9.8750
[E18B70 |  56800/50000 (114%) ] Loss: 2.8465 top1=  8.2500
[E18B80 |  64800/50000 (130%) ] Loss: 2.7556 top1=  9.1250
[E18B90 |  72800/50000 (146%) ] Loss: 2.7265 top1=  9.6250
[E18B100|  80800/50000 (162%) ] Loss: 2.8124 top1=  7.8750
[E18B110|  88800/50000 (178%) ] Loss: 2.7248 top1= 11.2500

=> Eval Loss=2.7567 top1=  9.9860

Train epoch 19
[E19B0  |    800/50000 (  2%) ] Loss: 2.7418 top1= 11.5000
[E19B10 |   8800/50000 ( 18%) ] Loss: 2.7537 top1= 11.5000
[E19B20 |  16800/50000 ( 34%) ] Loss: 2.7772 top1=  9.8750
[E19B30 |  24800/50000 ( 50%) ] Loss: 2.8278 top1=  8.5000
[E19B40 |  32800/50000 ( 66%) ] Loss: 2.9228 top1=  6.1250
[E19B50 |  40800/50000 ( 82%) ] Loss: 2.7547 top1= 12.6250
[E19B60 |  48800/50000 ( 98%) ] Loss: 2.7669 top1= 10.7500
[E19B70 |  56800/50000 (114%) ] Loss: 2.6914 top1= 10.2500
[E19B80 |  64800/50000 (130%) ] Loss: 2.7384 top1= 10.2500
[E19B90 |  72800/50000 (146%) ] Loss: 2.8348 top1=  9.8750
[E19B100|  80800/50000 (162%) ] Loss: 2.8704 top1=  9.2500
[E19B110|  88800/50000 (178%) ] Loss: 2.7566 top1= 10.1250

=> Eval Loss=2.7972 top1=  9.9860

Train epoch 20
[E20B0  |    800/50000 (  2%) ] Loss: 2.7051 top1= 10.2500
[E20B10 |   8800/50000 ( 18%) ] Loss: 2.7584 top1= 10.5000
[E20B20 |  16800/50000 ( 34%) ] Loss: 2.7596 top1=  9.5000
[E20B30 |  24800/50000 ( 50%) ] Loss: 2.7977 top1=  9.1250
[E20B40 |  32800/50000 ( 66%) ] Loss: 2.6721 top1= 12.7500
[E20B50 |  40800/50000 ( 82%) ] Loss: 2.8008 top1=  8.0000
[E20B60 |  48800/50000 ( 98%) ] Loss: 2.7969 top1=  8.8750
[E20B70 |  56800/50000 (114%) ] Loss: 2.7363 top1= 12.2500
[E20B80 |  64800/50000 (130%) ] Loss: 2.7517 top1= 11.6250
[E20B90 |  72800/50000 (146%) ] Loss: 2.7431 top1= 11.3750
[E20B100|  80800/50000 (162%) ] Loss: 2.7421 top1=  8.7500
[E20B110|  88800/50000 (178%) ] Loss: 2.7576 top1= 10.3750

=> Eval Loss=2.7976 top1=  9.9860

Train epoch 21
[E21B0  |    800/50000 (  2%) ] Loss: 2.7599 top1= 10.1250
[E21B10 |   8800/50000 ( 18%) ] Loss: 2.7920 top1= 10.3750
[E21B20 |  16800/50000 ( 34%) ] Loss: 2.8154 top1=  9.1250
[E21B30 |  24800/50000 ( 50%) ] Loss: 2.8334 top1=  8.5000
[E21B40 |  32800/50000 ( 66%) ] Loss: 2.7698 top1=  9.6250
[E21B50 |  40800/50000 ( 82%) ] Loss: 2.8329 top1=  9.3750
[E21B60 |  48800/50000 ( 98%) ] Loss: 2.7217 top1= 12.3750
[E21B70 |  56800/50000 (114%) ] Loss: 2.7483 top1= 10.5000
[E21B80 |  64800/50000 (130%) ] Loss: 2.8499 top1=  9.3750
[E21B90 |  72800/50000 (146%) ] Loss: 2.7210 top1= 11.8750
[E21B100|  80800/50000 (162%) ] Loss: 2.7277 top1= 11.7500
[E21B110|  88800/50000 (178%) ] Loss: 2.7902 top1=  9.2500

=> Eval Loss=2.7672 top1=  9.9860

Train epoch 22
[E22B0  |    800/50000 (  2%) ] Loss: 2.7446 top1= 10.5000
[E22B10 |   8800/50000 ( 18%) ] Loss: 2.7101 top1= 11.8750
[E22B20 |  16800/50000 ( 34%) ] Loss: 2.7694 top1= 10.1250
[E22B30 |  24800/50000 ( 50%) ] Loss: 2.8070 top1= 10.3750
[E22B40 |  32800/50000 ( 66%) ] Loss: 2.6424 top1= 11.5000
[E22B50 |  40800/50000 ( 82%) ] Loss: 2.8945 top1=  8.1250
[E22B60 |  48800/50000 ( 98%) ] Loss: 2.6823 top1= 12.2500
[E22B70 |  56800/50000 (114%) ] Loss: 2.8117 top1= 10.1250
[E22B80 |  64800/50000 (130%) ] Loss: 2.8246 top1= 11.6250
[E22B90 |  72800/50000 (146%) ] Loss: 2.7449 top1= 10.3750
[E22B100|  80800/50000 (162%) ] Loss: 2.7183 top1=  8.3750
[E22B110|  88800/50000 (178%) ] Loss: 2.8108 top1=  9.8750

=> Eval Loss=2.8718 top1=  9.9860

Train epoch 23
[E23B0  |    800/50000 (  2%) ] Loss: 2.7344 top1= 14.2500
[E23B10 |   8800/50000 ( 18%) ] Loss: 2.7809 top1= 11.5000
[E23B20 |  16800/50000 ( 34%) ] Loss: 2.7550 top1= 11.1250
[E23B30 |  24800/50000 ( 50%) ] Loss: 2.9041 top1=  8.3750
[E23B40 |  32800/50000 ( 66%) ] Loss: 2.8741 top1=  8.3750
[E23B50 |  40800/50000 ( 82%) ] Loss: 2.8346 top1=  8.3750
[E23B60 |  48800/50000 ( 98%) ] Loss: 2.7931 top1= 11.5000
[E23B70 |  56800/50000 (114%) ] Loss: 2.8136 top1= 11.2500
[E23B80 |  64800/50000 (130%) ] Loss: 2.8521 top1= 10.1250
[E23B90 |  72800/50000 (146%) ] Loss: 2.8775 top1=  7.7500
[E23B100|  80800/50000 (162%) ] Loss: 2.8135 top1= 11.5000
[E23B110|  88800/50000 (178%) ] Loss: 2.7573 top1= 10.1250

=> Eval Loss=2.8723 top1=  9.9860

Train epoch 24
[E24B0  |    800/50000 (  2%) ] Loss: 2.7862 top1=  9.8750
[E24B10 |   8800/50000 ( 18%) ] Loss: 2.9184 top1=  9.0000
[E24B20 |  16800/50000 ( 34%) ] Loss: 2.8735 top1=  9.3750
[E24B30 |  24800/50000 ( 50%) ] Loss: 2.9425 top1= 11.8750
[E24B40 |  32800/50000 ( 66%) ] Loss: 2.9178 top1=  9.7500
[E24B50 |  40800/50000 ( 82%) ] Loss: 2.8203 top1= 10.8750
[E24B60 |  48800/50000 ( 98%) ] Loss: 2.7464 top1= 10.1250
[E24B70 |  56800/50000 (114%) ] Loss: 2.6896 top1= 13.8750
[E24B80 |  64800/50000 (130%) ] Loss: 2.8132 top1= 10.5000
[E24B90 |  72800/50000 (146%) ] Loss: 2.7156 top1= 12.7500
[E24B100|  80800/50000 (162%) ] Loss: 2.7632 top1= 11.6250
[E24B110|  88800/50000 (178%) ] Loss: 2.8052 top1=  9.7500

=> Eval Loss=2.8575 top1=  9.9860

Train epoch 25
[E25B0  |    800/50000 (  2%) ] Loss: 2.7638 top1= 10.8750
[E25B10 |   8800/50000 ( 18%) ] Loss: 2.7795 top1= 10.7500
[E25B20 |  16800/50000 ( 34%) ] Loss: 2.8895 top1=  8.2500
[E25B30 |  24800/50000 ( 50%) ] Loss: 2.9270 top1=  8.5000
[E25B40 |  32800/50000 ( 66%) ] Loss: 2.8463 top1= 11.1250
[E25B50 |  40800/50000 ( 82%) ] Loss: 2.8751 top1=  8.6250
[E25B60 |  48800/50000 ( 98%) ] Loss: 2.8303 top1= 13.6250
[E25B70 |  56800/50000 (114%) ] Loss: 2.7432 top1= 10.7500
[E25B80 |  64800/50000 (130%) ] Loss: 2.8387 top1=  8.8750
[E25B90 |  72800/50000 (146%) ] Loss: 2.7477 top1= 13.0000
[E25B100|  80800/50000 (162%) ] Loss: 2.8491 top1=  9.7500
[E25B110|  88800/50000 (178%) ] Loss: 2.9230 top1=  9.8750

=> Eval Loss=3.0208 top1=  9.9860

Train epoch 26
[E26B0  |    800/50000 (  2%) ] Loss: 2.7852 top1= 11.2500
[E26B10 |   8800/50000 ( 18%) ] Loss: 2.9531 top1=  9.3750
[E26B20 |  16800/50000 ( 34%) ] Loss: 2.8863 top1= 10.7500
[E26B30 |  24800/50000 ( 50%) ] Loss: 2.8394 top1= 10.2500
[E26B40 |  32800/50000 ( 66%) ] Loss: 2.9430 top1= 11.2500
[E26B50 |  40800/50000 ( 82%) ] Loss: 2.7870 top1= 11.0000
[E26B60 |  48800/50000 ( 98%) ] Loss: 2.9616 top1=  8.3750
[E26B70 |  56800/50000 (114%) ] Loss: 2.8532 top1= 10.2500
[E26B80 |  64800/50000 (130%) ] Loss: 2.7955 top1=  8.2500
[E26B90 |  72800/50000 (146%) ] Loss: 2.8794 top1=  9.1250
[E26B100|  80800/50000 (162%) ] Loss: 2.7796 top1= 12.2500
[E26B110|  88800/50000 (178%) ] Loss: 2.9626 top1=  7.7500

=> Eval Loss=2.9153 top1=  9.9760

Train epoch 27
[E27B0  |    800/50000 (  2%) ] Loss: 2.8184 top1= 10.0000
[E27B10 |   8800/50000 ( 18%) ] Loss: 2.8905 top1= 10.6250
[E27B20 |  16800/50000 ( 34%) ] Loss: 2.8059 top1= 10.7500
[E27B30 |  24800/50000 ( 50%) ] Loss: 2.8306 top1=  9.6250
[E27B40 |  32800/50000 ( 66%) ] Loss: 2.9460 top1=  8.0000
[E27B50 |  40800/50000 ( 82%) ] Loss: 2.7906 top1= 12.0000
[E27B60 |  48800/50000 ( 98%) ] Loss: 3.0080 top1= 10.7500
[E27B70 |  56800/50000 (114%) ] Loss: 2.8817 top1=  8.3750
[E27B80 |  64800/50000 (130%) ] Loss: 2.9204 top1=  9.3750
[E27B90 |  72800/50000 (146%) ] Loss: 3.0106 top1= 11.1250
[E27B100|  80800/50000 (162%) ] Loss: 2.9427 top1= 11.2500
[E27B110|  88800/50000 (178%) ] Loss: 2.8764 top1=  9.5000

=> Eval Loss=3.0993 top1=  9.9860

Train epoch 28
[E28B0  |    800/50000 (  2%) ] Loss: 2.8470 top1=  9.3750
[E28B10 |   8800/50000 ( 18%) ] Loss: 3.0631 top1= 11.5000
[E28B20 |  16800/50000 ( 34%) ] Loss: 3.0625 top1=  8.8750
[E28B30 |  24800/50000 ( 50%) ] Loss: 2.8228 top1=  9.5000
[E28B40 |  32800/50000 ( 66%) ] Loss: 2.9887 top1= 10.1250
[E28B50 |  40800/50000 ( 82%) ] Loss: 2.8428 top1=  9.1250
[E28B60 |  48800/50000 ( 98%) ] Loss: 3.0563 top1= 10.1250
[E28B70 |  56800/50000 (114%) ] Loss: 2.9868 top1=  9.7500
[E28B80 |  64800/50000 (130%) ] Loss: 2.9520 top1= 10.8750
[E28B90 |  72800/50000 (146%) ] Loss: 3.0640 top1=  7.7500
[E28B100|  80800/50000 (162%) ] Loss: 3.0984 top1=  9.2500
[E28B110|  88800/50000 (178%) ] Loss: 3.0826 top1= 11.6250

=> Eval Loss=3.1743 top1=  9.9960

Train epoch 29
[E29B0  |    800/50000 (  2%) ] Loss: 3.0622 top1=  9.0000
[E29B10 |   8800/50000 ( 18%) ] Loss: 2.9681 top1= 12.1250
[E29B20 |  16800/50000 ( 34%) ] Loss: 2.9490 top1= 11.7500
[E29B30 |  24800/50000 ( 50%) ] Loss: 2.9699 top1= 12.2500
[E29B40 |  32800/50000 ( 66%) ] Loss: 3.0271 top1=  7.8750
[E29B50 |  40800/50000 ( 82%) ] Loss: 3.0301 top1= 12.7500
[E29B60 |  48800/50000 ( 98%) ] Loss: 3.0361 top1=  9.5000
[E29B70 |  56800/50000 (114%) ] Loss: 3.0752 top1= 11.3750
[E29B80 |  64800/50000 (130%) ] Loss: 2.9801 top1=  9.6250
[E29B90 |  72800/50000 (146%) ] Loss: 3.2489 top1=  9.1250
[E29B100|  80800/50000 (162%) ] Loss: 2.9545 top1= 10.3750
[E29B110|  88800/50000 (178%) ] Loss: 3.1082 top1=  8.7500

=> Eval Loss=3.2069 top1=  9.9760

Train epoch 30
[E30B0  |    800/50000 (  2%) ] Loss: 3.1263 top1= 10.5000
[E30B10 |   8800/50000 ( 18%) ] Loss: 2.9745 top1= 12.1250
[E30B20 |  16800/50000 ( 34%) ] Loss: 3.1999 top1=  7.7500
[E30B30 |  24800/50000 ( 50%) ] Loss: 3.2470 top1=  9.6250
[E30B40 |  32800/50000 ( 66%) ] Loss: 3.3446 top1=  9.6250
[E30B50 |  40800/50000 ( 82%) ] Loss: 3.4427 top1=  6.8750
[E30B60 |  48800/50000 ( 98%) ] Loss: 3.3450 top1=  8.8750
[E30B70 |  56800/50000 (114%) ] Loss: 3.4139 top1= 10.5000
[E30B80 |  64800/50000 (130%) ] Loss: 3.5276 top1= 12.5000
[E30B90 |  72800/50000 (146%) ] Loss: 3.8303 top1= 10.6250
[E30B100|  80800/50000 (162%) ] Loss: 3.5102 top1=  9.5000
[E30B110|  88800/50000 (178%) ] Loss: 3.7570 top1=  9.5000

=> Eval Loss=4.1282 top1=  9.9860

Train epoch 31
[E31B0  |    800/50000 (  2%) ] Loss: 3.6905 top1= 10.8750
[E31B10 |   8800/50000 ( 18%) ] Loss: 3.7788 top1= 10.0000
[E31B20 |  16800/50000 ( 34%) ] Loss: 3.9233 top1=  8.6250
[E31B30 |  24800/50000 ( 50%) ] Loss: 3.8101 top1= 12.6250
[E31B40 |  32800/50000 ( 66%) ] Loss: 4.0915 top1=  9.1250
[E31B50 |  40800/50000 ( 82%) ] Loss: 4.0098 top1= 11.6250
[E31B60 |  48800/50000 ( 98%) ] Loss: 4.1237 top1=  8.8750
[E31B70 |  56800/50000 (114%) ] Loss: 4.1290 top1= 10.5000
[E31B80 |  64800/50000 (130%) ] Loss: 4.2333 top1=  9.7500
[E31B90 |  72800/50000 (146%) ] Loss: 4.2460 top1= 11.2500
[E31B100|  80800/50000 (162%) ] Loss: 4.6253 top1=  8.6250
[E31B110|  88800/50000 (178%) ] Loss: 4.7141 top1=  7.7500

=> Eval Loss=4.8037 top1=  9.9860

Train epoch 32
[E32B0  |    800/50000 (  2%) ] Loss: 4.3924 top1=  9.1250
[E32B10 |   8800/50000 ( 18%) ] Loss: 4.3329 top1= 13.2500
[E32B20 |  16800/50000 ( 34%) ] Loss: 4.5405 top1=  8.3750
[E32B30 |  24800/50000 ( 50%) ] Loss: 4.5809 top1= 11.6250
[E32B40 |  32800/50000 ( 66%) ] Loss: 4.8412 top1= 11.1250
[E32B50 |  40800/50000 ( 82%) ] Loss: 5.3885 top1=  7.5000
[E32B60 |  48800/50000 ( 98%) ] Loss: 5.6037 top1= 11.0000
[E32B70 |  56800/50000 (114%) ] Loss: 5.6223 top1= 11.6250
[E32B80 |  64800/50000 (130%) ] Loss: 6.2169 top1= 12.5000
[E32B90 |  72800/50000 (146%) ] Loss: 6.7776 top1= 10.1250
[E32B100|  80800/50000 (162%) ] Loss: 7.3873 top1=  9.0000
[E32B110|  88800/50000 (178%) ] Loss: 8.7960 top1=  9.3750

=> Eval Loss=8.8348 top1=  9.9860

Train epoch 33
[E33B0  |    800/50000 (  2%) ] Loss: 8.9267 top1= 12.1250
[E33B10 |   8800/50000 ( 18%) ] Loss: 10.2092 top1= 10.6250
[E33B20 |  16800/50000 ( 34%) ] Loss: 12.6822 top1=  7.5000
[E33B30 |  24800/50000 ( 50%) ] Loss: 14.6701 top1= 10.3750
[E33B40 |  32800/50000 ( 66%) ] Loss: 16.9640 top1=  9.3750
[E33B50 |  40800/50000 ( 82%) ] Loss: 20.5104 top1=  9.0000
[E33B60 |  48800/50000 ( 98%) ] Loss: 23.5605 top1= 12.6250
[E33B70 |  56800/50000 (114%) ] Loss: 28.8770 top1=  9.2500
[E33B80 |  64800/50000 (130%) ] Loss: 35.0580 top1= 12.7500
[E33B90 |  72800/50000 (146%) ] Loss: 42.0590 top1=  8.8750
[E33B100|  80800/50000 (162%) ] Loss: 48.1714 top1= 10.1250
[E33B110|  88800/50000 (178%) ] Loss: 55.6939 top1=  9.0000

=> Eval Loss=66.0184 top1=  9.9860

Train epoch 34
[E34B0  |    800/50000 (  2%) ] Loss: 53.6310 top1= 10.5000
[E34B10 |   8800/50000 ( 18%) ] Loss: 65.0926 top1=  9.5000
[E34B20 |  16800/50000 ( 34%) ] Loss: 68.1763 top1= 10.1250
[E34B30 |  24800/50000 ( 50%) ] Loss: 74.2801 top1=  9.8750
[E34B40 |  32800/50000 ( 66%) ] Loss: 83.3930 top1=  7.8750
[E34B50 |  40800/50000 ( 82%) ] Loss: 52.6159 top1= 11.0000
[E34B60 |  48800/50000 ( 98%) ] Loss: 59.6322 top1=  9.3750
[E34B70 |  56800/50000 (114%) ] Loss: 51.0499 top1=  9.8750
[E34B80 |  64800/50000 (130%) ] Loss: 34.9860 top1= 12.1250
[E34B90 |  72800/50000 (146%) ] Loss: 33.3039 top1=  8.0000
[E34B100|  80800/50000 (162%) ] Loss: 28.4381 top1=  9.5000
[E34B110|  88800/50000 (178%) ] Loss: 31.8230 top1= 11.5000

=> Eval Loss=18.6887 top1=  9.9860

Train epoch 35
[E35B0  |    800/50000 (  2%) ] Loss: 31.2404 top1=  9.6250
[E35B10 |   8800/50000 ( 18%) ] Loss: 34.9997 top1=  9.5000
[E35B20 |  16800/50000 ( 34%) ] Loss: 43.2755 top1= 11.0000
[E35B30 |  24800/50000 ( 50%) ] Loss: 39.1978 top1=  9.3750
[E35B40 |  32800/50000 ( 66%) ] Loss: 39.3435 top1= 10.8750
[E35B50 |  40800/50000 ( 82%) ] Loss: 43.8742 top1=  9.2500
[E35B60 |  48800/50000 ( 98%) ] Loss: 57.8290 top1= 10.5000
[E35B70 |  56800/50000 (114%) ] Loss: 38.9779 top1= 12.1250
[E35B80 |  64800/50000 (130%) ] Loss: 35.0410 top1= 13.5000
[E35B90 |  72800/50000 (146%) ] Loss: 36.0794 top1=  7.6250
[E35B100|  80800/50000 (162%) ] Loss: 47.4399 top1= 10.8750
[E35B110|  88800/50000 (178%) ] Loss: 32.8930 top1= 10.6250

=> Eval Loss=31.6603 top1=  9.9860

Train epoch 36
[E36B0  |    800/50000 (  2%) ] Loss: 34.0327 top1= 10.0000
[E36B10 |   8800/50000 ( 18%) ] Loss: 31.9333 top1=  8.5000
[E36B20 |  16800/50000 ( 34%) ] Loss: 27.7474 top1= 10.5000
[E36B30 |  24800/50000 ( 50%) ] Loss: 30.4568 top1=  7.8750
[E36B40 |  32800/50000 ( 66%) ] Loss: 45.5396 top1=  7.6250
[E36B50 |  40800/50000 ( 82%) ] Loss: 57.1347 top1= 11.6250
[E36B60 |  48800/50000 ( 98%) ] Loss: 66.8419 top1= 11.7500
[E36B70 |  56800/50000 (114%) ] Loss: 77.4280 top1= 10.5000
[E36B80 |  64800/50000 (130%) ] Loss: 81.1902 top1= 11.8750
[E36B90 |  72800/50000 (146%) ] Loss: 94.8234 top1=  9.3750
[E36B100|  80800/50000 (162%) ] Loss: 105.7757 top1=  7.8750
[E36B110|  88800/50000 (178%) ] Loss: 80.6143 top1=  9.2500

=> Eval Loss=145.6020 top1=  9.9860

Train epoch 37
[E37B0  |    800/50000 (  2%) ] Loss: 86.4013 top1=  8.8750
[E37B10 |   8800/50000 ( 18%) ] Loss: 102.2859 top1= 10.1250
[E37B20 |  16800/50000 ( 34%) ] Loss: 121.7298 top1=  6.1250
[E37B30 |  24800/50000 ( 50%) ] Loss: 126.7209 top1= 10.1250
[E37B40 |  32800/50000 ( 66%) ] Loss: 143.9182 top1= 10.1250
[E37B50 |  40800/50000 ( 82%) ] Loss: 153.6769 top1=  8.8750
[E37B60 |  48800/50000 ( 98%) ] Loss: 164.1137 top1=  9.2500
[E37B70 |  56800/50000 (114%) ] Loss: 180.4018 top1= 10.5000
[E37B80 |  64800/50000 (130%) ] Loss: 193.9043 top1= 10.8750
[E37B90 |  72800/50000 (146%) ] Loss: 215.8940 top1=  7.7500
[E37B100|  80800/50000 (162%) ] Loss: 238.4814 top1=  9.1250
[E37B110|  88800/50000 (178%) ] Loss: 246.4751 top1= 11.1250

=> Eval Loss=267.2638 top1=  9.9860

Train epoch 38
[E38B0  |    800/50000 (  2%) ] Loss: 246.7127 top1= 11.8750
[E38B10 |   8800/50000 ( 18%) ] Loss: 259.6377 top1= 10.7500
[E38B20 |  16800/50000 ( 34%) ] Loss: 281.3135 top1=  9.8750
[E38B30 |  24800/50000 ( 50%) ] Loss: 305.6908 top1= 10.8750
[E38B40 |  32800/50000 ( 66%) ] Loss: 340.0205 top1=  9.5000
[E38B50 |  40800/50000 ( 82%) ] Loss: 358.6799 top1=  9.8750
[E38B60 |  48800/50000 ( 98%) ] Loss: 404.0566 top1=  7.1250
[E38B70 |  56800/50000 (114%) ] Loss: 425.7997 top1=  9.2500
[E38B80 |  64800/50000 (130%) ] Loss: 440.4888 top1= 11.1250
[E38B90 |  72800/50000 (146%) ] Loss: 482.9875 top1= 11.8750
[E38B100|  80800/50000 (162%) ] Loss: 557.6141 top1=  9.3750
[E38B110|  88800/50000 (178%) ] Loss: 603.8637 top1= 10.7500

=> Eval Loss=622.8071 top1=  9.9860

Train epoch 39
[E39B0  |    800/50000 (  2%) ] Loss: 629.1236 top1=  8.6250
[E39B10 |   8800/50000 ( 18%) ] Loss: 679.1137 top1= 10.0000
[E39B20 |  16800/50000 ( 34%) ] Loss: 765.6723 top1=  9.0000
[E39B30 |  24800/50000 ( 50%) ] Loss: 835.6892 top1= 10.1250
[E39B40 |  32800/50000 ( 66%) ] Loss: 958.5383 top1=  9.0000
[E39B50 |  40800/50000 ( 82%) ] Loss: 1032.5765 top1= 12.8750
[E39B60 |  48800/50000 ( 98%) ] Loss: 873.7594 top1=  9.7500
[E39B70 |  56800/50000 (114%) ] Loss: 780.9658 top1=  7.2500
[E39B80 |  64800/50000 (130%) ] Loss: 710.5402 top1= 11.2500
[E39B90 |  72800/50000 (146%) ] Loss: 632.9398 top1=  8.7500
[E39B100|  80800/50000 (162%) ] Loss: 587.3327 top1=  8.3750
[E39B110|  88800/50000 (178%) ] Loss: 488.9751 top1= 11.6250

=> Eval Loss=644.6731 top1=  9.9860

Train epoch 40
[E40B0  |    800/50000 (  2%) ] Loss: 512.7753 top1=  9.7500
[E40B10 |   8800/50000 ( 18%) ] Loss: 573.3574 top1=  9.3750
[E40B20 |  16800/50000 ( 34%) ] Loss: 461.7707 top1= 11.3750
[E40B30 |  24800/50000 ( 50%) ] Loss: 566.3511 top1=  9.1250
[E40B40 |  32800/50000 ( 66%) ] Loss: 497.6340 top1= 12.0000
[E40B50 |  40800/50000 ( 82%) ] Loss: 415.9905 top1= 11.0000
[E40B60 |  48800/50000 ( 98%) ] Loss: 555.5380 top1= 11.5000
[E40B70 |  56800/50000 (114%) ] Loss: 506.0794 top1= 11.5000
[E40B80 |  64800/50000 (130%) ] Loss: 402.3914 top1= 10.2500
[E40B90 |  72800/50000 (146%) ] Loss: 411.3987 top1= 10.6250
[E40B100|  80800/50000 (162%) ] Loss: 594.2974 top1= 11.3750
[E40B110|  88800/50000 (178%) ] Loss: 612.7882 top1= 11.6250

=> Eval Loss=782.8823 top1=  9.9860

Train epoch 41
[E41B0  |    800/50000 (  2%) ] Loss: 604.1770 top1=  8.0000
[E41B10 |   8800/50000 ( 18%) ] Loss: 369.3860 top1=  7.5000
[E41B20 |  16800/50000 ( 34%) ] Loss: 309.0158 top1=  9.1250
[E41B30 |  24800/50000 ( 50%) ] Loss: 240.2683 top1=  8.8750
[E41B40 |  32800/50000 ( 66%) ] Loss: 212.2597 top1=  7.5000
[E41B50 |  40800/50000 ( 82%) ] Loss: 178.8424 top1=  8.1250
[E41B60 |  48800/50000 ( 98%) ] Loss: 160.1623 top1= 12.3750
[E41B70 |  56800/50000 (114%) ] Loss: 182.2077 top1= 10.6250
[E41B80 |  64800/50000 (130%) ] Loss: 161.9552 top1=  7.8750
[E41B90 |  72800/50000 (146%) ] Loss: 142.5797 top1= 11.0000
[E41B100|  80800/50000 (162%) ] Loss: 132.4243 top1= 11.7500
[E41B110|  88800/50000 (178%) ] Loss: 145.2597 top1= 11.1250

=> Eval Loss=427.4930 top1=  9.9860

Train epoch 42
[E42B0  |    800/50000 (  2%) ] Loss: 148.0346 top1=  9.8750
[E42B10 |   8800/50000 ( 18%) ] Loss: 127.7517 top1= 11.7500
[E42B20 |  16800/50000 ( 34%) ] Loss: 132.4395 top1=  6.7500
[E42B30 |  24800/50000 ( 50%) ] Loss: 124.0023 top1=  7.1250
[E42B40 |  32800/50000 ( 66%) ] Loss: 109.4476 top1=  9.0000
[E42B50 |  40800/50000 ( 82%) ] Loss: 119.1293 top1= 10.8750
[E42B60 |  48800/50000 ( 98%) ] Loss: 110.0386 top1=  8.5000
[E42B70 |  56800/50000 (114%) ] Loss: 104.6736 top1= 10.2500
[E42B80 |  64800/50000 (130%) ] Loss: 114.7242 top1=  7.5000
[E42B90 |  72800/50000 (146%) ] Loss: 110.6403 top1= 10.7500
[E42B100|  80800/50000 (162%) ] Loss: 112.0354 top1= 11.0000
[E42B110|  88800/50000 (178%) ] Loss: 114.0150 top1= 10.5000

=> Eval Loss=121.1956 top1=  9.9860

Train epoch 43
[E43B0  |    800/50000 (  2%) ] Loss: 102.6190 top1= 11.7500
[E43B10 |   8800/50000 ( 18%) ] Loss: 111.9446 top1= 10.1250
[E43B20 |  16800/50000 ( 34%) ] Loss: 105.5014 top1=  9.8750
[E43B30 |  24800/50000 ( 50%) ] Loss: 110.3466 top1=  7.7500
[E43B40 |  32800/50000 ( 66%) ] Loss: 95.0217 top1=  8.7500
[E43B50 |  40800/50000 ( 82%) ] Loss: 95.5049 top1= 10.2500
[E43B60 |  48800/50000 ( 98%) ] Loss: 95.4871 top1= 11.5000
[E43B70 |  56800/50000 (114%) ] Loss: 88.7916 top1= 13.1250
[E43B80 |  64800/50000 (130%) ] Loss: 98.3008 top1= 12.1250
[E43B90 |  72800/50000 (146%) ] Loss: 105.4404 top1= 11.0000
[E43B100|  80800/50000 (162%) ] Loss: 141.9557 top1= 10.0000
[E43B110|  88800/50000 (178%) ] Loss: 102.5090 top1=  9.7500

=> Eval Loss=90.6094 top1=  9.9860

Train epoch 44
[E44B0  |    800/50000 (  2%) ] Loss: 113.4667 top1=  9.3750
[E44B10 |   8800/50000 ( 18%) ] Loss: 97.9291 top1=  9.1250
[E44B20 |  16800/50000 ( 34%) ] Loss: 106.4632 top1=  7.0000
[E44B30 |  24800/50000 ( 50%) ] Loss: 105.2159 top1=  7.8750
[E44B40 |  32800/50000 ( 66%) ] Loss: 78.4611 top1= 11.8750
[E44B50 |  40800/50000 ( 82%) ] Loss: 77.5557 top1= 10.0000
[E44B60 |  48800/50000 ( 98%) ] Loss: 101.7332 top1=  9.7500
[E44B70 |  56800/50000 (114%) ] Loss: 163.5911 top1=  7.6250
[E44B80 |  64800/50000 (130%) ] Loss: 123.7079 top1= 10.6250
[E44B90 |  72800/50000 (146%) ] Loss: 87.5392 top1=  8.7500
[E44B100|  80800/50000 (162%) ] Loss: 87.2856 top1= 10.5000
[E44B110|  88800/50000 (178%) ] Loss: 86.8676 top1= 10.8750

=> Eval Loss=89.1380 top1=  9.9860

Train epoch 45
[E45B0  |    800/50000 (  2%) ] Loss: 94.0924 top1=  8.3750
[E45B10 |   8800/50000 ( 18%) ] Loss: 90.8260 top1= 10.2500
[E45B20 |  16800/50000 ( 34%) ] Loss: 91.6102 top1=  9.1250
[E45B30 |  24800/50000 ( 50%) ] Loss: 92.4436 top1=  6.5000
[E45B40 |  32800/50000 ( 66%) ] Loss: 80.2894 top1=  9.3750
[E45B50 |  40800/50000 ( 82%) ] Loss: 83.2763 top1= 11.2500
[E45B60 |  48800/50000 ( 98%) ] Loss: 154.1671 top1=  9.7500
[E45B70 |  56800/50000 (114%) ] Loss: 64.0902 top1= 10.3750
[E45B80 |  64800/50000 (130%) ] Loss: 66.2997 top1= 10.0000
[E45B90 |  72800/50000 (146%) ] Loss: 142.6122 top1= 10.2500
[E45B100|  80800/50000 (162%) ] Loss: 156.2106 top1=  7.7500
[E45B110|  88800/50000 (178%) ] Loss: 150.1129 top1= 10.8750

=> Eval Loss=155.6715 top1=  9.9860

Train epoch 46
[E46B0  |    800/50000 (  2%) ] Loss: 153.6289 top1= 11.0000
[E46B10 |   8800/50000 ( 18%) ] Loss: 148.0944 top1=  8.7500
[E46B20 |  16800/50000 ( 34%) ] Loss: 149.0002 top1=  9.3750
[E46B30 |  24800/50000 ( 50%) ] Loss: 144.1639 top1= 10.3750
[E46B40 |  32800/50000 ( 66%) ] Loss: 138.5187 top1=  8.0000
[E46B50 |  40800/50000 ( 82%) ] Loss: 131.4744 top1= 11.0000
[E46B60 |  48800/50000 ( 98%) ] Loss: 128.9277 top1= 12.7500
[E46B70 |  56800/50000 (114%) ] Loss: 125.5000 top1= 10.7500
[E46B80 |  64800/50000 (130%) ] Loss: 137.2046 top1=  8.2500
[E46B90 |  72800/50000 (146%) ] Loss: 140.2492 top1=  8.6250
[E46B100|  80800/50000 (162%) ] Loss: 136.4954 top1= 11.1250
[E46B110|  88800/50000 (178%) ] Loss: 138.2785 top1= 11.5000

=> Eval Loss=139.0160 top1=  9.9860

Train epoch 47
[E47B0  |    800/50000 (  2%) ] Loss: 141.4024 top1=  9.3750
[E47B10 |   8800/50000 ( 18%) ] Loss: 136.8108 top1= 10.0000
[E47B20 |  16800/50000 ( 34%) ] Loss: 136.8756 top1=  9.7500
[E47B30 |  24800/50000 ( 50%) ] Loss: 120.4043 top1= 12.8750
[E47B40 |  32800/50000 ( 66%) ] Loss: 117.0057 top1= 11.2500
[E47B50 |  40800/50000 ( 82%) ] Loss: 123.6878 top1= 11.2500
[E47B60 |  48800/50000 ( 98%) ] Loss: 136.1272 top1= 14.5000
[E47B70 |  56800/50000 (114%) ] Loss: 119.5480 top1= 10.8750
[E47B80 |  64800/50000 (130%) ] Loss: 116.7179 top1=  9.7500
[E47B90 |  72800/50000 (146%) ] Loss: 117.8319 top1= 11.5000
[E47B100|  80800/50000 (162%) ] Loss: 112.7332 top1= 10.6250
[E47B110|  88800/50000 (178%) ] Loss: 114.7640 top1=  9.8750

=> Eval Loss=113.2995 top1=  9.9860

Train epoch 48
[E48B0  |    800/50000 (  2%) ] Loss: 111.5928 top1= 12.5000
[E48B10 |   8800/50000 ( 18%) ] Loss: 110.3306 top1= 10.5000
[E48B20 |  16800/50000 ( 34%) ] Loss: 111.2913 top1=  9.0000
[E48B30 |  24800/50000 ( 50%) ] Loss: 115.7193 top1= 10.3750
[E48B40 |  32800/50000 ( 66%) ] Loss: 109.2899 top1= 10.0000
[E48B50 |  40800/50000 ( 82%) ] Loss: 109.2913 top1= 10.8750
[E48B60 |  48800/50000 ( 98%) ] Loss: 108.8103 top1= 11.5000
[E48B70 |  56800/50000 (114%) ] Loss: 106.4316 top1= 10.1250
[E48B80 |  64800/50000 (130%) ] Loss: 139.1984 top1=  8.8750
[E48B90 |  72800/50000 (146%) ] Loss: 58.7412 top1=  8.2500
[E48B100|  80800/50000 (162%) ] Loss: 63.1830 top1=  7.7500
[E48B110|  88800/50000 (178%) ] Loss: 67.1921 top1=  7.1250

=> Eval Loss=43.4369 top1=  9.9860

Train epoch 49
[E49B0  |    800/50000 (  2%) ] Loss: 56.1245 top1=  7.8750
[E49B10 |   8800/50000 ( 18%) ] Loss: 62.7576 top1=  7.7500
[E49B20 |  16800/50000 ( 34%) ] Loss: 57.9528 top1= 11.3750
[E49B30 |  24800/50000 ( 50%) ] Loss: 169.5643 top1=  8.5000
[E49B40 |  32800/50000 ( 66%) ] Loss: 133.4443 top1= 10.3750
[E49B50 |  40800/50000 ( 82%) ] Loss: 123.5312 top1= 11.5000
[E49B60 |  48800/50000 ( 98%) ] Loss: 127.2465 top1=  9.3750
[E49B70 |  56800/50000 (114%) ] Loss: 122.2621 top1=  9.6250
[E49B80 |  64800/50000 (130%) ] Loss: 145.5336 top1=  9.1250
[E49B90 |  72800/50000 (146%) ] Loss: 151.7156 top1=  8.0000
[E49B100|  80800/50000 (162%) ] Loss: 144.0404 top1=  8.1250
[E49B110|  88800/50000 (178%) ] Loss: 137.2070 top1=  9.3750

=> Eval Loss=135.7416 top1=  9.9860

Train epoch 50
[E50B0  |    800/50000 (  2%) ] Loss: 140.3415 top1= 10.1250
[E50B10 |   8800/50000 ( 18%) ] Loss: 139.6175 top1=  8.6250
[E50B20 |  16800/50000 ( 34%) ] Loss: 149.1438 top1=  9.8750
[E50B30 |  24800/50000 ( 50%) ] Loss: 222.6740 top1=  8.0000
[E50B40 |  32800/50000 ( 66%) ] Loss: 214.8831 top1= 12.1250
[E50B50 |  40800/50000 ( 82%) ] Loss: 211.1908 top1=  9.7500
[E50B60 |  48800/50000 ( 98%) ] Loss: 199.8582 top1= 10.0000
[E50B70 |  56800/50000 (114%) ] Loss: 208.3426 top1= 11.5000
[E50B80 |  64800/50000 (130%) ] Loss: 222.2927 top1= 10.5000
[E50B90 |  72800/50000 (146%) ] Loss: 231.9068 top1=  8.5000
[E50B100|  80800/50000 (162%) ] Loss: 218.2073 top1=  9.5000
[E50B110|  88800/50000 (178%) ] Loss: 213.4921 top1= 11.0000

=> Eval Loss=216.3403 top1=  9.9860

Train epoch 51
[E51B0  |    800/50000 (  2%) ] Loss: 215.7960 top1= 11.5000
[E51B10 |   8800/50000 ( 18%) ] Loss: 212.9586 top1=  9.2500
[E51B20 |  16800/50000 ( 34%) ] Loss: 208.1238 top1=  7.5000
[E51B30 |  24800/50000 ( 50%) ] Loss: 207.7028 top1= 12.0000
[E51B40 |  32800/50000 ( 66%) ] Loss: 210.3565 top1= 13.3750
[E51B50 |  40800/50000 ( 82%) ] Loss: 237.4304 top1= 10.6250
[E51B60 |  48800/50000 ( 98%) ] Loss: 213.0848 top1= 11.2500
[E51B70 |  56800/50000 (114%) ] Loss: 240.7011 top1= 10.6250
[E51B80 |  64800/50000 (130%) ] Loss: 252.5633 top1=  9.8750
[E51B90 |  72800/50000 (146%) ] Loss: 260.8908 top1= 11.0000
[E51B100|  80800/50000 (162%) ] Loss: 254.7292 top1= 10.6250
[E51B110|  88800/50000 (178%) ] Loss: 230.2247 top1= 10.8750

=> Eval Loss=242.7011 top1=  9.9860

Train epoch 52
[E52B0  |    800/50000 (  2%) ] Loss: 227.8753 top1= 10.8750
[E52B10 |   8800/50000 ( 18%) ] Loss: 213.7555 top1= 12.6250
[E52B20 |  16800/50000 ( 34%) ] Loss: 244.0701 top1= 10.8750
[E52B30 |  24800/50000 ( 50%) ] Loss: 279.8884 top1=  9.8750
[E52B40 |  32800/50000 ( 66%) ] Loss: 80.2960 top1= 10.5000
[E52B50 |  40800/50000 ( 82%) ] Loss: 63.8075 top1=  8.1250
[E52B60 |  48800/50000 ( 98%) ] Loss: 51.5803 top1= 10.0000
[E52B70 |  56800/50000 (114%) ] Loss: 36.6970 top1= 10.6250
[E52B80 |  64800/50000 (130%) ] Loss: 31.7720 top1= 12.0000
[E52B90 |  72800/50000 (146%) ] Loss: 29.7965 top1= 11.3750
[E52B100|  80800/50000 (162%) ] Loss: 25.4229 top1= 10.0000
[E52B110|  88800/50000 (178%) ] Loss: 18.2210 top1= 10.1250

=> Eval Loss=22.4041 top1=  9.9860

Train epoch 53
[E53B0  |    800/50000 (  2%) ] Loss: 30.0331 top1= 10.5000
[E53B10 |   8800/50000 ( 18%) ] Loss: 14.7377 top1=  9.7500
[E53B20 |  16800/50000 ( 34%) ] Loss: 24.1651 top1= 12.1250
[E53B30 |  24800/50000 ( 50%) ] Loss: 28.0159 top1= 10.5000
[E53B40 |  32800/50000 ( 66%) ] Loss: 26.6558 top1=  9.1250
[E53B50 |  40800/50000 ( 82%) ] Loss: 24.5449 top1=  8.8750
[E53B60 |  48800/50000 ( 98%) ] Loss: 21.5023 top1=  9.2500
[E53B70 |  56800/50000 (114%) ] Loss: 47.4065 top1= 12.3750
[E53B80 |  64800/50000 (130%) ] Loss: 38.1779 top1=  9.3750
[E53B90 |  72800/50000 (146%) ] Loss: 55.0696 top1=  9.8750
[E53B100|  80800/50000 (162%) ] Loss: 54.7183 top1=  7.2500
[E53B110|  88800/50000 (178%) ] Loss: 83.5110 top1=  9.3750

=> Eval Loss=83.5141 top1=  9.9860

Train epoch 54
[E54B0  |    800/50000 (  2%) ] Loss: 75.1857 top1= 10.2500
[E54B10 |   8800/50000 ( 18%) ] Loss: 64.7868 top1=  9.3750
[E54B20 |  16800/50000 ( 34%) ] Loss: 67.5899 top1=  9.8750
[E54B30 |  24800/50000 ( 50%) ] Loss: 85.5721 top1=  8.7500
[E54B40 |  32800/50000 ( 66%) ] Loss: 96.3053 top1=  7.6250
[E54B50 |  40800/50000 ( 82%) ] Loss: 76.6686 top1= 13.7500
[E54B60 |  48800/50000 ( 98%) ] Loss: 91.1811 top1=  8.3750
[E54B70 |  56800/50000 (114%) ] Loss: 60.5411 top1=  9.8750
[E54B80 |  64800/50000 (130%) ] Loss: 79.3365 top1= 11.2500
[E54B90 |  72800/50000 (146%) ] Loss: 90.1442 top1=  9.6250
[E54B100|  80800/50000 (162%) ] Loss: 91.0175 top1= 11.6250
[E54B110|  88800/50000 (178%) ] Loss: 62.9502 top1= 10.2500

=> Eval Loss=66.6222 top1=  9.9860

Train epoch 55
[E55B0  |    800/50000 (  2%) ] Loss: 58.8836 top1= 10.5000
