ParallelTrainer(aggregator=Krum (m=1), max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.4307 top1= 11.5000
[E 1B10 |   8800/50000 ( 18%) ] Loss: 3.3097 top1=  8.5000
[E 1B20 |  16800/50000 ( 34%) ] Loss: 3.3008 top1=  9.6250
[E 1B30 |  24800/50000 ( 50%) ] Loss: 3.1569 top1=  7.7500
[E 1B40 |  32800/50000 ( 66%) ] Loss: 3.0202 top1=  8.5000
[E 1B50 |  40800/50000 ( 82%) ] Loss: 2.8218 top1= 11.7500
[E 1B60 |  48800/50000 ( 98%) ] Loss: 2.7846 top1=  6.7500
[E 1B70 |  56800/50000 (114%) ] Loss: 2.6600 top1=  9.5000
[E 1B80 |  64800/50000 (130%) ] Loss: 3.8088 top1= 11.1250
[E 1B90 |  72800/50000 (146%) ] Loss: 3.2980 top1= 10.1250
[E 1B100|  80800/50000 (162%) ] Loss: 3.7122 top1=  8.6250
[E 1B110|  88800/50000 (178%) ] Loss: 3.4432 top1=  9.2500

=> Eval Loss=2.3765 top1= 10.8073

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 2.4084 top1= 12.7500
[E 2B10 |   8800/50000 ( 18%) ] Loss: 2.7494 top1=  8.7500
[E 2B20 |  16800/50000 ( 34%) ] Loss: 2.6524 top1=  8.1250
[E 2B30 |  24800/50000 ( 50%) ] Loss: 2.5562 top1= 12.3750
[E 2B40 |  32800/50000 ( 66%) ] Loss: 2.7779 top1=  7.8750
[E 2B50 |  40800/50000 ( 82%) ] Loss: 3.4125 top1= 12.3750
[E 2B60 |  48800/50000 ( 98%) ] Loss: 3.2869 top1= 10.3750
[E 2B70 |  56800/50000 (114%) ] Loss: 4.6029 top1= 13.2500
[E 2B80 |  64800/50000 (130%) ] Loss: 8.5454 top1=  9.0000
[E 2B90 |  72800/50000 (146%) ] Loss: 3.3990 top1= 10.8750
[E 2B100|  80800/50000 (162%) ] Loss: 4.7388 top1= 16.2500
[E 2B110|  88800/50000 (178%) ] Loss: 8.0384 top1=  9.7500

=> Eval Loss=8.2971 top1=  9.9860

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 8.6774 top1=  9.6250
[E 3B10 |   8800/50000 ( 18%) ] Loss: 15.1992 top1=  9.3750
[E 3B20 |  16800/50000 ( 34%) ] Loss: 25.3297 top1= 12.8750
[E 3B30 |  24800/50000 ( 50%) ] Loss: 42.1199 top1= 10.2500
[E 3B40 |  32800/50000 ( 66%) ] Loss: 62.7891 top1= 10.8750
[E 3B50 |  40800/50000 ( 82%) ] Loss: 92.7993 top1=  9.8750
[E 3B60 |  48800/50000 ( 98%) ] Loss: 128.6086 top1=  8.2500
[E 3B70 |  56800/50000 (114%) ] Loss: 181.7683 top1=  8.7500
[E 3B80 |  64800/50000 (130%) ] Loss: 245.2087 top1=  9.7500
[E 3B90 |  72800/50000 (146%) ] Loss: 328.4102 top1= 10.1250
[E 3B100|  80800/50000 (162%) ] Loss: 113.6500 top1= 12.0000
[E 3B110|  88800/50000 (178%) ] Loss: 192.6803 top1= 10.8750

=> Eval Loss=100913.9256 top1=  9.9860

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 112.5840 top1= 12.3750
[E 4B10 |   8800/50000 ( 18%) ] Loss: 83.1161 top1= 11.0000
[E 4B20 |  16800/50000 ( 34%) ] Loss: 116.7448 top1=  9.8750
[E 4B30 |  24800/50000 ( 50%) ] Loss: 72.0905 top1= 10.0000
[E 4B40 |  32800/50000 ( 66%) ] Loss: 102.4446 top1=  9.1250
[E 4B50 |  40800/50000 ( 82%) ] Loss: 134.0260 top1=  9.8750
[E 4B60 |  48800/50000 ( 98%) ] Loss: 59.0185 top1= 13.5000
[E 4B70 |  56800/50000 (114%) ] Loss: 66.2024 top1= 10.0000
[E 4B80 |  64800/50000 (130%) ] Loss: 82.0264 top1= 10.0000
[E 4B90 |  72800/50000 (146%) ] Loss: 101.2192 top1=  9.7500
[E 4B100|  80800/50000 (162%) ] Loss: 138.9489 top1=  8.7500
[E 4B110|  88800/50000 (178%) ] Loss: 47.0432 top1= 10.0000

=> Eval Loss=101.3246 top1=  9.9860

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 50.4061 top1=  9.3750
[E 5B10 |   8800/50000 ( 18%) ] Loss: 51.5128 top1= 10.3750
[E 5B20 |  16800/50000 ( 34%) ] Loss: 49.9779 top1= 10.7500
[E 5B30 |  24800/50000 ( 50%) ] Loss: 70.9948 top1=  7.5000
[E 5B40 |  32800/50000 ( 66%) ] Loss: 78.9053 top1= 13.5000
[E 5B50 |  40800/50000 ( 82%) ] Loss: 116.5254 top1=  8.8750
[E 5B60 |  48800/50000 ( 98%) ] Loss: 156.0021 top1= 10.1250
[E 5B70 |  56800/50000 (114%) ] Loss: 53.3619 top1= 13.2500
[E 5B80 |  64800/50000 (130%) ] Loss: 32.5371 top1= 11.5000
[E 5B90 |  72800/50000 (146%) ] Loss: 34.5941 top1=  8.6250
[E 5B100|  80800/50000 (162%) ] Loss: 43.8439 top1= 10.5000
[E 5B110|  88800/50000 (178%) ] Loss: 49.4222 top1= 10.2500

=> Eval Loss=79.7316 top1=  9.9860

Train epoch 6
[E 6B0  |    800/50000 (  2%) ] Loss: 55.7774 top1=  9.3750
[E 6B10 |   8800/50000 ( 18%) ] Loss: 71.7430 top1=  7.5000
[E 6B20 |  16800/50000 ( 34%) ] Loss: 83.0259 top1=  8.5000
[E 6B30 |  24800/50000 ( 50%) ] Loss: 112.6544 top1=  7.8750
[E 6B40 |  32800/50000 ( 66%) ] Loss: 100.8481 top1=  7.6250
[E 6B50 |  40800/50000 ( 82%) ] Loss: 53.7286 top1=  6.7500
[E 6B60 |  48800/50000 ( 98%) ] Loss: 65.9337 top1=  8.0000
[E 6B70 |  56800/50000 (114%) ] Loss: 75.9291 top1= 10.2500
[E 6B80 |  64800/50000 (130%) ] Loss: 94.8910 top1= 10.6250
[E 6B90 |  72800/50000 (146%) ] Loss: 123.5164 top1=  7.2500
[E 6B100|  80800/50000 (162%) ] Loss: 178.7539 top1=  7.6250
[E 6B110|  88800/50000 (178%) ] Loss: 262.2711 top1=  9.6250

=> Eval Loss=346.5168 top1=  9.9860

Train epoch 7
[E 7B0  |    800/50000 (  2%) ] Loss: 281.9150 top1=  9.0000
[E 7B10 |   8800/50000 ( 18%) ] Loss: 420.5417 top1=  6.8750
[E 7B20 |  16800/50000 ( 34%) ] Loss: 173.4907 top1= 10.6250
[E 7B30 |  24800/50000 ( 50%) ] Loss: 247.0047 top1=  9.8750
[E 7B40 |  32800/50000 ( 66%) ] Loss: 371.4417 top1=  9.6250
[E 7B50 |  40800/50000 ( 82%) ] Loss: 123.9388 top1=  9.8750
[E 7B60 |  48800/50000 ( 98%) ] Loss: 123.3507 top1=  9.7500
[E 7B70 |  56800/50000 (114%) ] Loss: 94.0836 top1=  8.2500
[E 7B80 |  64800/50000 (130%) ] Loss: 68.1445 top1=  6.6250
[E 7B90 |  72800/50000 (146%) ] Loss: 82.9195 top1= 10.5000
[E 7B100|  80800/50000 (162%) ] Loss: 109.9394 top1=  6.6250
[E 7B110|  88800/50000 (178%) ] Loss: 141.5068 top1=  7.2500

=> Eval Loss=175.9354 top1=  9.9860

Train epoch 8
[E 8B0  |    800/50000 (  2%) ] Loss: 135.1332 top1= 12.0000
[E 8B10 |   8800/50000 ( 18%) ] Loss: 74.6792 top1= 10.5000
[E 8B20 |  16800/50000 ( 34%) ] Loss: 98.2075 top1= 10.8750
[E 8B30 |  24800/50000 ( 50%) ] Loss: 128.3865 top1=  8.6250
[E 8B40 |  32800/50000 ( 66%) ] Loss: 148.8201 top1= 12.3750
[E 8B50 |  40800/50000 ( 82%) ] Loss: 195.1874 top1=  9.7500
[E 8B60 |  48800/50000 ( 98%) ] Loss: 269.1989 top1=  9.5000
[E 8B70 |  56800/50000 (114%) ] Loss: 73.0564 top1=  9.8750
[E 8B80 |  64800/50000 (130%) ] Loss: 98.3254 top1=  8.6250
[E 8B90 |  72800/50000 (146%) ] Loss: 119.6755 top1= 10.5000
[E 8B100|  80800/50000 (162%) ] Loss: 143.1227 top1= 11.1250
[E 8B110|  88800/50000 (178%) ] Loss: 205.4611 top1=  9.1250

=> Eval Loss=193.1639 top1=  9.9860

Train epoch 9
[E 9B0  |    800/50000 (  2%) ] Loss: 205.5445 top1=  9.7500
[E 9B10 |   8800/50000 ( 18%) ] Loss: 272.4184 top1=  9.7500
[E 9B20 |  16800/50000 ( 34%) ] Loss: 259.0390 top1= 10.1250
[E 9B30 |  24800/50000 ( 50%) ] Loss: 94.7897 top1=  8.8750
[E 9B40 |  32800/50000 ( 66%) ] Loss: 76.4452 top1=  9.0000
[E 9B50 |  40800/50000 ( 82%) ] Loss: 91.3814 top1= 10.2500
[E 9B60 |  48800/50000 ( 98%) ] Loss: 114.3433 top1=  9.1250
[E 9B70 |  56800/50000 (114%) ] Loss: 148.5296 top1= 12.3750
[E 9B80 |  64800/50000 (130%) ] Loss: 197.8713 top1=  6.3750
[E 9B90 |  72800/50000 (146%) ] Loss: 243.0722 top1=  8.8750
[E 9B100|  80800/50000 (162%) ] Loss: 166.3040 top1=  7.3750
[E 9B110|  88800/50000 (178%) ] Loss: 161.7401 top1=  8.6250

=> Eval Loss=198.5389 top1=  9.9860

Train epoch 10
[E10B0  |    800/50000 (  2%) ] Loss: 166.8094 top1=  8.2500
[E10B10 |   8800/50000 ( 18%) ] Loss: 208.8205 top1= 11.6250
[E10B20 |  16800/50000 ( 34%) ] Loss: 285.4471 top1= 10.5000
[E10B30 |  24800/50000 ( 50%) ] Loss: 70.7528 top1=  8.8750
[E10B40 |  32800/50000 ( 66%) ] Loss: 88.7480 top1=  9.0000
[E10B50 |  40800/50000 ( 82%) ] Loss: 112.5019 top1=  9.6250
[E10B60 |  48800/50000 ( 98%) ] Loss: 144.8010 top1=  7.8750
[E10B70 |  56800/50000 (114%) ] Loss: 184.5177 top1=  8.0000
[E10B80 |  64800/50000 (130%) ] Loss: 231.7409 top1= 11.6250
[E10B90 |  72800/50000 (146%) ] Loss: 320.6222 top1=  9.6250
[E10B100|  80800/50000 (162%) ] Loss: 447.6618 top1=  9.6250
[E10B110|  88800/50000 (178%) ] Loss: 272.0450 top1=  9.0000

=> Eval Loss=242.1358 top1=  9.9860

Train epoch 11
[E11B0  |    800/50000 (  2%) ] Loss: 275.3127 top1=  9.0000
[E11B10 |   8800/50000 ( 18%) ] Loss: 270.4663 top1=  8.7500
[E11B20 |  16800/50000 ( 34%) ] Loss: 250.3828 top1=  7.8750
[E11B30 |  24800/50000 ( 50%) ] Loss: 328.8591 top1=  9.2500
[E11B40 |  32800/50000 ( 66%) ] Loss: 112.2764 top1= 11.3750
[E11B50 |  40800/50000 ( 82%) ] Loss: 150.9265 top1=  8.1250
[E11B60 |  48800/50000 ( 98%) ] Loss: 196.9177 top1=  9.1250
[E11B70 |  56800/50000 (114%) ] Loss: 254.4996 top1= 10.7500
[E11B80 |  64800/50000 (130%) ] Loss: 359.1148 top1= 10.5000
[E11B90 |  72800/50000 (146%) ] Loss: 497.2362 top1= 10.3750
[E11B100|  80800/50000 (162%) ] Loss: 54.5547 top1=  9.3750
[E11B110|  88800/50000 (178%) ] Loss: 76.0819 top1=  9.5000

=> Eval Loss=69.4982 top1=  9.9860

Train epoch 12
[E12B0  |    800/50000 (  2%) ] Loss: 78.9217 top1= 12.5000
[E12B10 |   8800/50000 ( 18%) ] Loss: 104.4839 top1= 10.3750
[E12B20 |  16800/50000 ( 34%) ] Loss: 134.2142 top1= 10.3750
[E12B30 |  24800/50000 ( 50%) ] Loss: 177.5739 top1=  9.2500
[E12B40 |  32800/50000 ( 66%) ] Loss: 232.0302 top1=  9.5000
[E12B50 |  40800/50000 ( 82%) ] Loss: 199.5742 top1=  9.7500
[E12B60 |  48800/50000 ( 98%) ] Loss: 277.4069 top1=  8.5000
[E12B70 |  56800/50000 (114%) ] Loss: 46.3018 top1= 11.3750
[E12B80 |  64800/50000 (130%) ] Loss: 50.0390 top1=  8.5000
[E12B90 |  72800/50000 (146%) ] Loss: 21.4214 top1= 10.2500
[E12B100|  80800/50000 (162%) ] Loss: 19.2483 top1=  9.5000
[E12B110|  88800/50000 (178%) ] Loss: 19.4625 top1=  9.8750

=> Eval Loss=15.4348 top1=  9.9860

Train epoch 13
[E13B0  |    800/50000 (  2%) ] Loss: 19.5201 top1=  7.7500
[E13B10 |   8800/50000 ( 18%) ] Loss: 17.4251 top1= 10.7500
[E13B20 |  16800/50000 ( 34%) ] Loss: 20.4884 top1=  8.7500
[E13B30 |  24800/50000 ( 50%) ] Loss: 19.1200 top1= 13.3750
[E13B40 |  32800/50000 ( 66%) ] Loss: 23.9443 top1= 13.5000
[E13B50 |  40800/50000 ( 82%) ] Loss: 28.1004 top1= 10.0000
[E13B60 |  48800/50000 ( 98%) ] Loss: 34.3219 top1= 11.1250
[E13B70 |  56800/50000 (114%) ] Loss: 37.6125 top1=  9.5000
[E13B80 |  64800/50000 (130%) ] Loss: 48.1396 top1=  7.8750
[E13B90 |  72800/50000 (146%) ] Loss: 59.0598 top1= 11.1250
[E13B100|  80800/50000 (162%) ] Loss: 62.6689 top1= 11.8750
[E13B110|  88800/50000 (178%) ] Loss: 83.4226 top1= 10.2500

=> Eval Loss=72.0769 top1=  9.9860

Train epoch 14
[E14B0  |    800/50000 (  2%) ] Loss: 87.0661 top1= 11.1250
[E14B10 |   8800/50000 ( 18%) ] Loss: 62.8417 top1=  9.8750
[E14B20 |  16800/50000 ( 34%) ] Loss: 21.8037 top1= 11.2500
[E14B30 |  24800/50000 ( 50%) ] Loss: 31.3802 top1=  8.2500
[E14B40 |  32800/50000 ( 66%) ] Loss: 29.8922 top1= 10.5000
[E14B50 |  40800/50000 ( 82%) ] Loss: 37.2299 top1=  9.8750
[E14B60 |  48800/50000 ( 98%) ] Loss: 39.6926 top1= 11.7500
[E14B70 |  56800/50000 (114%) ] Loss: 53.2438 top1=  9.2500
[E14B80 |  64800/50000 (130%) ] Loss: 59.7673 top1= 10.8750
[E14B90 |  72800/50000 (146%) ] Loss: 76.7169 top1=  7.1250
[E14B100|  80800/50000 (162%) ] Loss: 93.4193 top1=  9.2500
[E14B110|  88800/50000 (178%) ] Loss: 35.8766 top1= 10.0000

=> Eval Loss=18.0798 top1=  9.9860

Train epoch 15
[E15B0  |    800/50000 (  2%) ] Loss: 29.3156 top1= 12.6250
[E15B10 |   8800/50000 ( 18%) ] Loss: 36.4538 top1=  8.1250
[E15B20 |  16800/50000 ( 34%) ] Loss: 42.8295 top1=  9.3750
[E15B30 |  24800/50000 ( 50%) ] Loss: 51.0236 top1= 11.7500
[E15B40 |  32800/50000 ( 66%) ] Loss: 66.6160 top1= 11.5000
[E15B50 |  40800/50000 ( 82%) ] Loss: 78.0806 top1=  8.8750
[E15B60 |  48800/50000 ( 98%) ] Loss: 90.2861 top1=  9.0000
[E15B70 |  56800/50000 (114%) ] Loss: 119.8503 top1=  8.3750
[E15B80 |  64800/50000 (130%) ] Loss: 150.0592 top1=  9.0000
[E15B90 |  72800/50000 (146%) ] Loss: 203.9323 top1=  9.8750
[E15B100|  80800/50000 (162%) ] Loss: 125.9752 top1=  9.8750
[E15B110|  88800/50000 (178%) ] Loss: 27.4540 top1=  8.5000

=> Eval Loss=20.3904 top1=  9.9860

Train epoch 16
[E16B0  |    800/50000 (  2%) ] Loss: 26.6349 top1= 11.6250
[E16B10 |   8800/50000 ( 18%) ] Loss: 25.7133 top1= 12.2500
[E16B20 |  16800/50000 ( 34%) ] Loss: 23.2065 top1= 10.3750
[E16B30 |  24800/50000 ( 50%) ] Loss: 19.8957 top1=  9.2500
[E16B40 |  32800/50000 ( 66%) ] Loss: 22.9959 top1=  8.8750
[E16B50 |  40800/50000 ( 82%) ] Loss: 16.4396 top1=  9.6250
[E16B60 |  48800/50000 ( 98%) ] Loss: 10.5072 top1= 11.5000
[E16B70 |  56800/50000 (114%) ] Loss: 12.4431 top1=  7.2500
[E16B80 |  64800/50000 (130%) ] Loss: 13.3173 top1= 10.1250
[E16B90 |  72800/50000 (146%) ] Loss: 17.4845 top1=  9.5000
[E16B100|  80800/50000 (162%) ] Loss: 14.7324 top1= 10.7500
[E16B110|  88800/50000 (178%) ] Loss: 18.3172 top1= 11.7500

=> Eval Loss=19.4625 top1=  9.9860

Train epoch 17
[E17B0  |    800/50000 (  2%) ] Loss: 22.0851 top1=  9.2500
[E17B10 |   8800/50000 ( 18%) ] Loss: 22.6697 top1=  9.5000
[E17B20 |  16800/50000 ( 34%) ] Loss: 24.3330 top1= 10.3750
[E17B30 |  24800/50000 ( 50%) ] Loss: 31.8087 top1=  8.1250
[E17B40 |  32800/50000 ( 66%) ] Loss: 33.3158 top1= 10.8750
[E17B50 |  40800/50000 ( 82%) ] Loss: 38.3375 top1= 10.1250
[E17B60 |  48800/50000 ( 98%) ] Loss: 51.2406 top1=  6.7500
[E17B70 |  56800/50000 (114%) ] Loss: 59.8798 top1=  8.1250
[E17B80 |  64800/50000 (130%) ] Loss: 53.3495 top1= 11.1250
[E17B90 |  72800/50000 (146%) ] Loss: 64.3211 top1=  8.5000
[E17B100|  80800/50000 (162%) ] Loss: 76.7754 top1=  9.8750
[E17B110|  88800/50000 (178%) ] Loss: 98.2091 top1= 10.0000

=> Eval Loss=90.2442 top1=  9.9860

Train epoch 18
[E18B0  |    800/50000 (  2%) ] Loss: 95.8737 top1=  8.3750
[E18B10 |   8800/50000 ( 18%) ] Loss: 35.0452 top1= 13.1250
[E18B20 |  16800/50000 ( 34%) ] Loss: 40.3596 top1=  9.3750
[E18B30 |  24800/50000 ( 50%) ] Loss: 46.7077 top1= 10.2500
[E18B40 |  32800/50000 ( 66%) ] Loss: 57.7711 top1=  9.1250
[E18B50 |  40800/50000 ( 82%) ] Loss: 67.9030 top1=  9.6250
[E18B60 |  48800/50000 ( 98%) ] Loss: 83.8338 top1=  7.8750
[E18B70 |  56800/50000 (114%) ] Loss: 102.5227 top1= 10.2500
[E18B80 |  64800/50000 (130%) ] Loss: 126.5599 top1= 10.5000
[E18B90 |  72800/50000 (146%) ] Loss: 155.0905 top1= 11.6250
[E18B100|  80800/50000 (162%) ] Loss: 48.4930 top1= 12.2500
[E18B110|  88800/50000 (178%) ] Loss: 53.9886 top1=  8.1250

=> Eval Loss=10.7727 top1=  9.9860

Train epoch 19
[E19B0  |    800/50000 (  2%) ] Loss: 38.6972 top1=  9.5000
[E19B10 |   8800/50000 ( 18%) ] Loss: 29.6434 top1= 10.7500
[E19B20 |  16800/50000 ( 34%) ] Loss: 27.1319 top1=  8.2500
[E19B30 |  24800/50000 ( 50%) ] Loss: 29.7756 top1= 11.7500
[E19B40 |  32800/50000 ( 66%) ] Loss: 22.0984 top1=  8.3750
[E19B50 |  40800/50000 ( 82%) ] Loss: 28.1569 top1=  9.2500
[E19B60 |  48800/50000 ( 98%) ] Loss: 22.6596 top1= 11.1250
[E19B70 |  56800/50000 (114%) ] Loss: 23.3380 top1=  9.0000
[E19B80 |  64800/50000 (130%) ] Loss: 28.1268 top1=  8.5000
[E19B90 |  72800/50000 (146%) ] Loss: 22.6400 top1= 13.0000
[E19B100|  80800/50000 (162%) ] Loss: 27.7044 top1=  9.0000
[E19B110|  88800/50000 (178%) ] Loss: 26.3933 top1=  7.5000

=> Eval Loss=18.5694 top1=  9.9860

Train epoch 20
[E20B0  |    800/50000 (  2%) ] Loss: 28.3094 top1=  8.3750
[E20B10 |   8800/50000 ( 18%) ] Loss: 24.2961 top1=  9.3750
[E20B20 |  16800/50000 ( 34%) ] Loss: 24.4314 top1= 12.0000
[E20B30 |  24800/50000 ( 50%) ] Loss: 27.5185 top1= 11.5000
[E20B40 |  32800/50000 ( 66%) ] Loss: 27.2033 top1=  9.3750
[E20B50 |  40800/50000 ( 82%) ] Loss: 27.6738 top1= 11.0000
[E20B60 |  48800/50000 ( 98%) ] Loss: 32.4961 top1=  8.3750
[E20B70 |  56800/50000 (114%) ] Loss: 31.1573 top1= 12.0000
[E20B80 |  64800/50000 (130%) ] Loss: 24.0327 top1=  8.3750
[E20B90 |  72800/50000 (146%) ] Loss: 17.0744 top1=  9.5000
[E20B100|  80800/50000 (162%) ] Loss: 25.0708 top1= 11.6250
[E20B110|  88800/50000 (178%) ] Loss: 25.4421 top1=  7.2500

=> Eval Loss=7.8631 top1=  9.9860

Train epoch 21
[E21B0  |    800/50000 (  2%) ] Loss: 24.8456 top1=  9.5000
[E21B10 |   8800/50000 ( 18%) ] Loss: 25.0978 top1=  8.5000
[E21B20 |  16800/50000 ( 34%) ] Loss: 27.7894 top1= 10.1250
[E21B30 |  24800/50000 ( 50%) ] Loss: 29.5963 top1=  8.6250
[E21B40 |  32800/50000 ( 66%) ] Loss: 32.0718 top1=  9.7500
[E21B50 |  40800/50000 ( 82%) ] Loss: 33.7607 top1= 10.0000
[E21B60 |  48800/50000 ( 98%) ] Loss: 42.3409 top1= 11.2500
[E21B70 |  56800/50000 (114%) ] Loss: 55.2789 top1= 10.0000
[E21B80 |  64800/50000 (130%) ] Loss: 62.8375 top1=  7.8750
[E21B90 |  72800/50000 (146%) ] Loss: 76.7937 top1= 12.0000
[E21B100|  80800/50000 (162%) ] Loss: 97.3575 top1=  9.8750
[E21B110|  88800/50000 (178%) ] Loss: 117.2278 top1=  8.7500

=> Eval Loss=112.6756 top1=  9.9860

Train epoch 22
[E22B0  |    800/50000 (  2%) ] Loss: 123.9447 top1= 11.0000
[E22B10 |   8800/50000 ( 18%) ] Loss: 150.9583 top1=  9.2500
[E22B20 |  16800/50000 ( 34%) ] Loss: 203.5428 top1= 13.1250
[E22B30 |  24800/50000 ( 50%) ] Loss: 40.0272 top1=  8.2500
[E22B40 |  32800/50000 ( 66%) ] Loss: 43.1379 top1= 11.1250
[E22B50 |  40800/50000 ( 82%) ] Loss: 16.6641 top1= 10.6250
[E22B60 |  48800/50000 ( 98%) ] Loss: 20.8128 top1=  8.3750
[E22B70 |  56800/50000 (114%) ] Loss: 19.9959 top1= 11.8750
[E22B80 |  64800/50000 (130%) ] Loss: 19.2763 top1=  9.1250
[E22B90 |  72800/50000 (146%) ] Loss: 17.0349 top1= 10.8750
[E22B100|  80800/50000 (162%) ] Loss: 22.3058 top1= 10.7500
[E22B110|  88800/50000 (178%) ] Loss: 21.5339 top1= 10.7500

=> Eval Loss=26.1148 top1=  9.9860

Train epoch 23
[E23B0  |    800/50000 (  2%) ] Loss: 22.9914 top1= 10.0000
[E23B10 |   8800/50000 ( 18%) ] Loss: 34.7626 top1=  9.3750
[E23B20 |  16800/50000 ( 34%) ] Loss: 41.7143 top1= 10.8750
[E23B30 |  24800/50000 ( 50%) ] Loss: 54.0088 top1=  7.6250
[E23B40 |  32800/50000 ( 66%) ] Loss: 60.7729 top1= 11.1250
[E23B50 |  40800/50000 ( 82%) ] Loss: 79.5869 top1=  9.8750
[E23B60 |  48800/50000 ( 98%) ] Loss: 97.2010 top1=  9.3750
[E23B70 |  56800/50000 (114%) ] Loss: 125.3265 top1=  7.1250
[E23B80 |  64800/50000 (130%) ] Loss: 168.0479 top1=  8.5000
[E23B90 |  72800/50000 (146%) ] Loss: 214.7728 top1= 12.0000
[E23B100|  80800/50000 (162%) ] Loss: 323.2893 top1=  7.1250
[E23B110|  88800/50000 (178%) ] Loss: 278.0899 top1=  6.1250

=> Eval Loss=274.9841 top1=  9.9860

Train epoch 24
[E24B0  |    800/50000 (  2%) ] Loss: 272.0677 top1= 10.1250
[E24B10 |   8800/50000 ( 18%) ] Loss: 252.7183 top1=  9.3750
[E24B20 |  16800/50000 ( 34%) ] Loss: 221.5503 top1= 13.0000
[E24B30 |  24800/50000 ( 50%) ] Loss: 224.1107 top1=  8.5000
[E24B40 |  32800/50000 ( 66%) ] Loss: 211.1238 top1=  9.1250
[E24B50 |  40800/50000 ( 82%) ] Loss: 106.5849 top1= 12.6250
[E24B60 |  48800/50000 ( 98%) ] Loss: 153.5646 top1= 10.5000
[E24B70 |  56800/50000 (114%) ] Loss: 207.2838 top1=  8.0000
[E24B80 |  64800/50000 (130%) ] Loss: 269.6092 top1= 10.7500
[E24B90 |  72800/50000 (146%) ] Loss: 362.8922 top1= 10.1250
[E24B100|  80800/50000 (162%) ] Loss: 505.8710 top1=  7.6250
[E24B110|  88800/50000 (178%) ] Loss: 188.0491 top1=  9.2500

=> Eval Loss=197.8420 top1=  9.9860

Train epoch 25
[E25B0  |    800/50000 (  2%) ] Loss: 209.1314 top1=  7.5000
[E25B10 |   8800/50000 ( 18%) ] Loss: 187.5557 top1=  8.2500
[E25B20 |  16800/50000 ( 34%) ] Loss: 257.3769 top1=  9.3750
[E25B30 |  24800/50000 ( 50%) ] Loss: 75.4866 top1= 10.1250
[E25B40 |  32800/50000 ( 66%) ] Loss: 84.9409 top1=  9.2500
[E25B50 |  40800/50000 ( 82%) ] Loss: 111.7110 top1=  8.7500
[E25B60 |  48800/50000 ( 98%) ] Loss: 153.7023 top1=  6.5000
[E25B70 |  56800/50000 (114%) ] Loss: 193.2242 top1= 12.2500
[E25B80 |  64800/50000 (130%) ] Loss: 252.6076 top1= 12.3750
[E25B90 |  72800/50000 (146%) ] Loss: 354.7743 top1= 10.5000
[E25B100|  80800/50000 (162%) ] Loss: 323.9660 top1=  8.7500
[E25B110|  88800/50000 (178%) ] Loss: 457.7205 top1=  9.2500

=> Eval Loss=324.5107 top1=  9.9860

Train epoch 26
[E26B0  |    800/50000 (  2%) ] Loss: 471.4175 top1= 10.1250
[E26B10 |   8800/50000 ( 18%) ] Loss: 637.6252 top1= 13.3750
[E26B20 |  16800/50000 ( 34%) ] Loss: 337.4808 top1= 11.7500
[E26B30 |  24800/50000 ( 50%) ] Loss: 159.6012 top1= 10.7500
[E26B40 |  32800/50000 ( 66%) ] Loss: 223.6025 top1=  9.7500
[E26B50 |  40800/50000 ( 82%) ] Loss: 213.8897 top1=  9.2500
[E26B60 |  48800/50000 ( 98%) ] Loss: 194.1740 top1=  9.8750
[E26B70 |  56800/50000 (114%) ] Loss: 197.4463 top1=  8.0000
[E26B80 |  64800/50000 (130%) ] Loss: 130.9018 top1= 14.8750
[E26B90 |  72800/50000 (146%) ] Loss: 72.3137 top1= 10.3750
[E26B100|  80800/50000 (162%) ] Loss: 90.8689 top1=  8.0000
[E26B110|  88800/50000 (178%) ] Loss: 89.1411 top1= 11.0000

=> Eval Loss=110.8034 top1=  9.9860

Train epoch 27
[E27B0  |    800/50000 (  2%) ] Loss: 90.3499 top1=  9.2500
[E27B10 |   8800/50000 ( 18%) ] Loss: 81.9140 top1= 11.2500
[E27B20 |  16800/50000 ( 34%) ] Loss: 84.0162 top1=  9.6250
[E27B30 |  24800/50000 ( 50%) ] Loss: 77.1466 top1=  9.0000
[E27B40 |  32800/50000 ( 66%) ] Loss: 99.5253 top1= 10.7500
[E27B50 |  40800/50000 ( 82%) ] Loss: 95.9283 top1=  7.8750
[E27B60 |  48800/50000 ( 98%) ] Loss: 93.4341 top1=  6.6250
[E27B70 |  56800/50000 (114%) ] Loss: 67.3946 top1=  9.8750
[E27B80 |  64800/50000 (130%) ] Loss: 77.8671 top1= 10.2500
[E27B90 |  72800/50000 (146%) ] Loss: 95.8139 top1=  9.6250
[E27B100|  80800/50000 (162%) ] Loss: 127.4718 top1=  8.6250
[E27B110|  88800/50000 (178%) ] Loss: 171.9402 top1=  8.6250

=> Eval Loss=192.5708 top1=  9.9860

Train epoch 28
[E28B0  |    800/50000 (  2%) ] Loss: 177.3663 top1=  9.2500
[E28B10 |   8800/50000 ( 18%) ] Loss: 225.6089 top1= 11.8750
[E28B20 |  16800/50000 ( 34%) ] Loss: 308.3478 top1=  9.1250
[E28B30 |  24800/50000 ( 50%) ] Loss: 104.6179 top1= 10.8750
[E28B40 |  32800/50000 ( 66%) ] Loss: 95.0721 top1=  9.5000
[E28B50 |  40800/50000 ( 82%) ] Loss: 95.5261 top1= 11.5000
[E28B60 |  48800/50000 ( 98%) ] Loss: 67.9204 top1=  9.2500
[E28B70 |  56800/50000 (114%) ] Loss: 68.7040 top1= 10.8750
[E28B80 |  64800/50000 (130%) ] Loss: 87.0411 top1=  8.2500
[E28B90 |  72800/50000 (146%) ] Loss: 80.2989 top1= 10.3750
[E28B100|  80800/50000 (162%) ] Loss: 83.2862 top1=  7.8750
[E28B110|  88800/50000 (178%) ] Loss: 57.6240 top1= 10.3750

=> Eval Loss=76.7277 top1=  9.9860

Train epoch 29
[E29B0  |    800/50000 (  2%) ] Loss: 60.1758 top1= 10.0000
[E29B10 |   8800/50000 ( 18%) ] Loss: 72.8907 top1=  8.7500
[E29B20 |  16800/50000 ( 34%) ] Loss: 97.0974 top1=  9.2500
[E29B30 |  24800/50000 ( 50%) ] Loss: 120.3877 top1= 12.2500
[E29B40 |  32800/50000 ( 66%) ] Loss: 65.3459 top1= 11.3750
[E29B50 |  40800/50000 ( 82%) ] Loss: 62.0292 top1=  9.7500
[E29B60 |  48800/50000 ( 98%) ] Loss: 47.0994 top1= 11.2500
[E29B70 |  56800/50000 (114%) ] Loss: 61.3755 top1=  9.6250
[E29B80 |  64800/50000 (130%) ] Loss: 76.6378 top1=  9.6250
[E29B90 |  72800/50000 (146%) ] Loss: 45.6138 top1=  8.7500
[E29B100|  80800/50000 (162%) ] Loss: 45.4965 top1=  8.0000
[E29B110|  88800/50000 (178%) ] Loss: 54.3119 top1= 10.3750

=> Eval Loss=43.5047 top1=  9.9860

Train epoch 30
[E30B0  |    800/50000 (  2%) ] Loss: 41.8878 top1=  9.6250
[E30B10 |   8800/50000 ( 18%) ] Loss: 52.3362 top1=  9.5000
[E30B20 |  16800/50000 ( 34%) ] Loss: 55.7676 top1=  9.1250
[E30B30 |  24800/50000 ( 50%) ] Loss: 62.6621 top1= 10.1250
[E30B40 |  32800/50000 ( 66%) ] Loss: 74.6812 top1= 12.1250
[E30B50 |  40800/50000 ( 82%) ] Loss: 50.4136 top1= 10.2500
[E30B60 |  48800/50000 ( 98%) ] Loss: 37.0580 top1=  6.0000
[E30B70 |  56800/50000 (114%) ] Loss: 36.0889 top1=  9.1250
[E30B80 |  64800/50000 (130%) ] Loss: 44.3421 top1=  7.3750
[E30B90 |  72800/50000 (146%) ] Loss: 51.1135 top1= 10.3750
[E30B100|  80800/50000 (162%) ] Loss: 51.7559 top1= 10.8750
[E30B110|  88800/50000 (178%) ] Loss: 42.5573 top1=  9.2500

=> Eval Loss=52.0695 top1=  9.9860

Train epoch 31
[E31B0  |    800/50000 (  2%) ] Loss: 41.5611 top1=  8.2500
[E31B10 |   8800/50000 ( 18%) ] Loss: 41.9081 top1=  7.1250
[E31B20 |  16800/50000 ( 34%) ] Loss: 53.6896 top1= 10.2500
[E31B30 |  24800/50000 ( 50%) ] Loss: 49.1377 top1= 10.3750
[E31B40 |  32800/50000 ( 66%) ] Loss: 62.3614 top1= 11.1250
[E31B50 |  40800/50000 ( 82%) ] Loss: 41.2098 top1= 10.3750
[E31B60 |  48800/50000 ( 98%) ] Loss: 44.2472 top1= 11.7500
[E31B70 |  56800/50000 (114%) ] Loss: 45.8813 top1= 10.2500
[E31B80 |  64800/50000 (130%) ] Loss: 43.5428 top1= 11.2500
[E31B90 |  72800/50000 (146%) ] Loss: 41.2312 top1=  9.0000
[E31B100|  80800/50000 (162%) ] Loss: 33.4745 top1=  8.3750
[E31B110|  88800/50000 (178%) ] Loss: 39.5122 top1= 11.8750

=> Eval Loss=43.6176 top1=  9.9860

Train epoch 32
[E32B0  |    800/50000 (  2%) ] Loss: 38.2836 top1= 10.0000
[E32B10 |   8800/50000 ( 18%) ] Loss: 37.4162 top1=  9.3750
[E32B20 |  16800/50000 ( 34%) ] Loss: 45.0281 top1= 10.6250
[E32B30 |  24800/50000 ( 50%) ] Loss: 24.6857 top1= 13.3750
[E32B40 |  32800/50000 ( 66%) ] Loss: 23.8551 top1=  9.5000
[E32B50 |  40800/50000 ( 82%) ] Loss: 31.8497 top1= 12.0000
[E32B60 |  48800/50000 ( 98%) ] Loss: 38.7968 top1= 10.1250
[E32B70 |  56800/50000 (114%) ] Loss: 41.5413 top1= 13.3750
[E32B80 |  64800/50000 (130%) ] Loss: 58.2574 top1=  9.7500
[E32B90 |  72800/50000 (146%) ] Loss: 58.1520 top1= 10.8750
[E32B100|  80800/50000 (162%) ] Loss: 60.9527 top1= 12.2500
[E32B110|  88800/50000 (178%) ] Loss: 74.3109 top1=  9.5000

=> Eval Loss=89.9416 top1= 10.9175

Train epoch 33
[E33B0  |    800/50000 (  2%) ] Loss: 80.6199 top1=  8.3750
[E33B10 |   8800/50000 ( 18%) ] Loss: 71.0933 top1= 10.7500
[E33B20 |  16800/50000 ( 34%) ] Loss: 92.7087 top1= 11.0000
[E33B30 |  24800/50000 ( 50%) ] Loss: 90.4611 top1= 12.0000
[E33B40 |  32800/50000 ( 66%) ] Loss: 90.4231 top1=  9.5000
[E33B50 |  40800/50000 ( 82%) ] Loss: 77.7015 top1= 12.1250
[E33B60 |  48800/50000 ( 98%) ] Loss: 74.0732 top1= 10.3750
[E33B70 |  56800/50000 (114%) ] Loss: 72.8587 top1=  9.6250
[E33B80 |  64800/50000 (130%) ] Loss: 73.2609 top1=  8.0000
[E33B90 |  72800/50000 (146%) ] Loss: 60.8901 top1= 12.6250
[E33B100|  80800/50000 (162%) ] Loss: 79.0983 top1= 10.8750
[E33B110|  88800/50000 (178%) ] Loss: 62.6473 top1= 12.2500

=> Eval Loss=49.1005 top1= 11.4683

Train epoch 34
[E34B0  |    800/50000 (  2%) ] Loss: 53.0144 top1= 10.8750
[E34B10 |   8800/50000 ( 18%) ] Loss: 64.2796 top1= 10.7500
[E34B20 |  16800/50000 ( 34%) ] Loss: 74.6837 top1= 10.7500
[E34B30 |  24800/50000 ( 50%) ] Loss: 92.4201 top1=  9.2500
[E34B40 |  32800/50000 ( 66%) ] Loss: 80.5488 top1= 11.1250
[E34B50 |  40800/50000 ( 82%) ] Loss: 107.1626 top1= 10.0000
[E34B60 |  48800/50000 ( 98%) ] Loss: 79.7433 top1= 10.1250
[E34B70 |  56800/50000 (114%) ] Loss: 77.1648 top1=  9.5000
[E34B80 |  64800/50000 (130%) ] Loss: 85.0863 top1= 11.5000
[E34B90 |  72800/50000 (146%) ] Loss: 113.8771 top1= 10.5000
[E34B100|  80800/50000 (162%) ] Loss: 88.0572 top1= 13.0000
[E34B110|  88800/50000 (178%) ] Loss: 82.8672 top1=  9.0000

=> Eval Loss=79.5817 top1= 11.3181

Train epoch 35
[E35B0  |    800/50000 (  2%) ] Loss: 74.0071 top1= 12.2500
[E35B10 |   8800/50000 ( 18%) ] Loss: 78.5897 top1= 10.2500
[E35B20 |  16800/50000 ( 34%) ] Loss: 88.4154 top1= 11.6250
[E35B30 |  24800/50000 ( 50%) ] Loss: 119.3490 top1= 10.5000
[E35B40 |  32800/50000 ( 66%) ] Loss: 90.2119 top1= 12.2500
[E35B50 |  40800/50000 ( 82%) ] Loss: 85.8404 top1= 11.1250
[E35B60 |  48800/50000 ( 98%) ] Loss: 105.1684 top1= 12.1250
[E35B70 |  56800/50000 (114%) ] Loss: 94.8368 top1= 12.1250
[E35B80 |  64800/50000 (130%) ] Loss: 100.0505 top1=  8.2500
[E35B90 |  72800/50000 (146%) ] Loss: 109.4763 top1= 11.6250
[E35B100|  80800/50000 (162%) ] Loss: 85.1138 top1= 11.2500
[E35B110|  88800/50000 (178%) ] Loss: 79.2554 top1= 12.2500

=> Eval Loss=96.9075 top1= 11.4483

Train epoch 36
[E36B0  |    800/50000 (  2%) ] Loss: 87.0110 top1= 11.2500
[E36B10 |   8800/50000 ( 18%) ] Loss: 81.1603 top1= 12.8750
[E36B20 |  16800/50000 ( 34%) ] Loss: 75.7769 top1= 12.3750
[E36B30 |  24800/50000 ( 50%) ] Loss: 79.1361 top1= 13.1250
[E36B40 |  32800/50000 ( 66%) ] Loss: 98.0281 top1=  9.6250
[E36B50 |  40800/50000 ( 82%) ] Loss: 86.9065 top1= 11.2500
[E36B60 |  48800/50000 ( 98%) ] Loss: 89.0721 top1= 11.7500
[E36B70 |  56800/50000 (114%) ] Loss: 65.1548 top1= 10.5000
[E36B80 |  64800/50000 (130%) ] Loss: 80.7146 top1= 10.0000
[E36B90 |  72800/50000 (146%) ] Loss: 99.5487 top1= 12.2500
[E36B100|  80800/50000 (162%) ] Loss: 84.4687 top1= 11.6250
[E36B110|  88800/50000 (178%) ] Loss: 101.7623 top1= 10.7500

=> Eval Loss=120.9357 top1= 11.1478

Train epoch 37
[E37B0  |    800/50000 (  2%) ] Loss: 108.1953 top1= 12.3750
[E37B10 |   8800/50000 ( 18%) ] Loss: 103.4834 top1= 11.5000
[E37B20 |  16800/50000 ( 34%) ] Loss: 104.0190 top1=  9.5000
[E37B30 |  24800/50000 ( 50%) ] Loss: 129.5198 top1=  9.3750
[E37B40 |  32800/50000 ( 66%) ] Loss: 91.6026 top1= 11.1250
[E37B50 |  40800/50000 ( 82%) ] Loss: 86.7496 top1= 12.3750
[E37B60 |  48800/50000 ( 98%) ] Loss: 69.8801 top1= 12.8750
[E37B70 |  56800/50000 (114%) ] Loss: 72.8859 top1= 11.7500
[E37B80 |  64800/50000 (130%) ] Loss: 84.2896 top1=  9.8750
[E37B90 |  72800/50000 (146%) ] Loss: 75.5119 top1= 11.8750
[E37B100|  80800/50000 (162%) ] Loss: 86.3762 top1= 13.8750
[E37B110|  88800/50000 (178%) ] Loss: 116.3217 top1=  9.8750

=> Eval Loss=127.5315 top1= 10.9375

Train epoch 38
[E38B0  |    800/50000 (  2%) ] Loss: 127.1704 top1= 11.8750
[E38B10 |   8800/50000 ( 18%) ] Loss: 112.5231 top1= 11.2500
[E38B20 |  16800/50000 ( 34%) ] Loss: 135.4645 top1= 10.0000
[E38B30 |  24800/50000 ( 50%) ] Loss: 134.0197 top1= 10.8750
[E38B40 |  32800/50000 ( 66%) ] Loss: 171.7648 top1= 11.2500
[E38B50 |  40800/50000 ( 82%) ] Loss: 128.6295 top1=  9.1250
[E38B60 |  48800/50000 ( 98%) ] Loss: 158.5561 top1= 11.0000
[E38B70 |  56800/50000 (114%) ] Loss: 152.7877 top1= 10.1250
[E38B80 |  64800/50000 (130%) ] Loss: 135.3101 top1=  9.0000
[E38B90 |  72800/50000 (146%) ] Loss: 176.1520 top1= 12.1250
[E38B100|  80800/50000 (162%) ] Loss: 220.5810 top1=  9.0000
[E38B110|  88800/50000 (178%) ] Loss: 307.4383 top1= 10.3750

=> Eval Loss=321.5890 top1=  9.8658

Train epoch 39
[E39B0  |    800/50000 (  2%) ] Loss: 309.0100 top1= 10.5000
[E39B10 |   8800/50000 ( 18%) ] Loss: 198.1431 top1=  8.7500
[E39B20 |  16800/50000 ( 34%) ] Loss: 216.1563 top1=  9.3750
[E39B30 |  24800/50000 ( 50%) ] Loss: 282.0333 top1=  9.0000
[E39B40 |  32800/50000 ( 66%) ] Loss: 380.5735 top1=  9.1250
[E39B50 |  40800/50000 ( 82%) ] Loss: 500.0287 top1= 13.0000
[E39B60 |  48800/50000 ( 98%) ] Loss: 720.0789 top1=  7.3750
[E39B70 |  56800/50000 (114%) ] Loss: 632.9347 top1=  8.7500
[E39B80 |  64800/50000 (130%) ] Loss: 156.0841 top1=  9.8750
[E39B90 |  72800/50000 (146%) ] Loss: 187.9896 top1= 11.2500
[E39B100|  80800/50000 (162%) ] Loss: 88.7262 top1=  5.1250
[E39B110|  88800/50000 (178%) ] Loss: 52.0859 top1=  6.2500

=> Eval Loss=78.0139 top1=  7.1915

Train epoch 40
[E40B0  |    800/50000 (  2%) ] Loss: 52.4378 top1=  9.5000
[E40B10 |   8800/50000 ( 18%) ] Loss: 48.6864 top1=  9.6250
[E40B20 |  16800/50000 ( 34%) ] Loss: 60.9972 top1=  6.3750
[E40B30 |  24800/50000 ( 50%) ] Loss: 72.1167 top1=  8.7500
[E40B40 |  32800/50000 ( 66%) ] Loss: 87.9268 top1=  5.3750
[E40B50 |  40800/50000 ( 82%) ] Loss: 106.1214 top1=  6.1250
[E40B60 |  48800/50000 ( 98%) ] Loss: 45.9605 top1=  7.3750
[E40B70 |  56800/50000 (114%) ] Loss: 48.8634 top1=  6.8750
[E40B80 |  64800/50000 (130%) ] Loss: 64.4935 top1=  7.3750
[E40B90 |  72800/50000 (146%) ] Loss: 39.5110 top1=  6.0000
[E40B100|  80800/50000 (162%) ] Loss: 40.5249 top1=  6.5000
[E40B110|  88800/50000 (178%) ] Loss: 47.7563 top1=  6.6250

=> Eval Loss=74.0928 top1=  7.5120

Train epoch 41
[E41B0  |    800/50000 (  2%) ] Loss: 53.1722 top1=  6.1250
[E41B10 |   8800/50000 ( 18%) ] Loss: 59.7480 top1=  9.1250
[E41B20 |  16800/50000 ( 34%) ] Loss: 72.1190 top1=  9.6250
[E41B30 |  24800/50000 ( 50%) ] Loss: 76.9296 top1=  6.6250
[E41B40 |  32800/50000 ( 66%) ] Loss: 100.1572 top1= 10.2500
[E41B50 |  40800/50000 ( 82%) ] Loss: 124.4247 top1= 10.1250
[E41B60 |  48800/50000 ( 98%) ] Loss: 157.1732 top1=  9.7500
[E41B70 |  56800/50000 (114%) ] Loss: 204.7358 top1=  9.2500
[E41B80 |  64800/50000 (130%) ] Loss: 48.5162 top1=  8.7500
[E41B90 |  72800/50000 (146%) ] Loss: 33.4005 top1=  9.3750
[E41B100|  80800/50000 (162%) ] Loss: 45.7673 top1=  6.0000
[E41B110|  88800/50000 (178%) ] Loss: 62.0721 top1=  8.5000

=> Eval Loss=42.6437 top1=  8.4235

Train epoch 42
[E42B0  |    800/50000 (  2%) ] Loss: 55.1360 top1=  9.8750
[E42B10 |   8800/50000 ( 18%) ] Loss: 77.6223 top1=  8.8750
[E42B20 |  16800/50000 ( 34%) ] Loss: 99.7542 top1= 10.3750
[E42B30 |  24800/50000 ( 50%) ] Loss: 141.9907 top1= 10.2500
[E42B40 |  32800/50000 ( 66%) ] Loss: 191.3737 top1=  7.1250
[E42B50 |  40800/50000 ( 82%) ] Loss: 240.0073 top1=  9.7500
[E42B60 |  48800/50000 ( 98%) ] Loss: 174.6714 top1=  8.2500
[E42B70 |  56800/50000 (114%) ] Loss: 164.2333 top1=  8.0000
[E42B80 |  64800/50000 (130%) ] Loss: 195.2794 top1= 11.8750
[E42B90 |  72800/50000 (146%) ] Loss: 129.3294 top1= 11.2500
[E42B100|  80800/50000 (162%) ] Loss: 129.5625 top1=  9.7500
[E42B110|  88800/50000 (178%) ] Loss: 165.1308 top1=  8.1250

=> Eval Loss=156.5723 top1= 10.0160

Train epoch 43
[E43B0  |    800/50000 (  2%) ] Loss: 126.4361 top1= 10.6250
[E43B10 |   8800/50000 ( 18%) ] Loss: 170.1482 top1=  9.7500
[E43B20 |  16800/50000 ( 34%) ] Loss: 232.3337 top1=  8.6250
[E43B30 |  24800/50000 ( 50%) ] Loss: 144.7245 top1= 12.8750
[E43B40 |  32800/50000 ( 66%) ] Loss: 148.3052 top1= 11.6250
[E43B50 |  40800/50000 ( 82%) ] Loss: 185.8796 top1=  9.5000
[E43B60 |  48800/50000 ( 98%) ] Loss: 103.4927 top1=  8.8750
[E43B70 |  56800/50000 (114%) ] Loss: 126.4593 top1=  9.6250
[E43B80 |  64800/50000 (130%) ] Loss: 93.1265 top1= 10.2500
[E43B90 |  72800/50000 (146%) ] Loss: 116.6131 top1=  9.6250
[E43B100|  80800/50000 (162%) ] Loss: 82.9166 top1=  9.2500
[E43B110|  88800/50000 (178%) ] Loss: 80.1251 top1=  8.6250

=> Eval Loss=102.7729 top1= 10.3365

Train epoch 44
[E44B0  |    800/50000 (  2%) ] Loss: 80.2855 top1= 11.1250
[E44B10 |   8800/50000 ( 18%) ] Loss: 100.7918 top1=  9.6250
[E44B20 |  16800/50000 ( 34%) ] Loss: 129.8916 top1= 10.2500
[E44B30 |  24800/50000 ( 50%) ] Loss: 123.0277 top1=  9.6250
[E44B40 |  32800/50000 ( 66%) ] Loss: 117.2788 top1=  6.6250
[E44B50 |  40800/50000 ( 82%) ] Loss: 108.9924 top1= 10.3750
[E44B60 |  48800/50000 ( 98%) ] Loss: 104.0651 top1=  8.1250
[E44B70 |  56800/50000 (114%) ] Loss: 129.5534 top1= 10.5000
[E44B80 |  64800/50000 (130%) ] Loss: 120.0210 top1= 12.0000
[E44B90 |  72800/50000 (146%) ] Loss: 114.9509 top1= 11.2500
[E44B100|  80800/50000 (162%) ] Loss: 152.3196 top1= 11.7500
[E44B110|  88800/50000 (178%) ] Loss: 103.1380 top1=  9.7500

=> Eval Loss=134.1705 top1= 10.1162

Train epoch 45
[E45B0  |    800/50000 (  2%) ] Loss: 100.5793 top1= 11.1250
[E45B10 |   8800/50000 ( 18%) ] Loss: 81.4645 top1=  9.5000
[E45B20 |  16800/50000 ( 34%) ] Loss: 55.3069 top1= 10.3750
[E45B30 |  24800/50000 ( 50%) ] Loss: 61.8180 top1= 13.3750
[E45B40 |  32800/50000 ( 66%) ] Loss: 55.6085 top1= 10.6250
[E45B50 |  40800/50000 ( 82%) ] Loss: 35.5833 top1= 12.8750
[E45B60 |  48800/50000 ( 98%) ] Loss: 49.8872 top1= 11.6250
[E45B70 |  56800/50000 (114%) ] Loss: 58.2799 top1= 11.3750
[E45B80 |  64800/50000 (130%) ] Loss: 69.5345 top1= 11.8750
[E45B90 |  72800/50000 (146%) ] Loss: 87.2342 top1= 11.7500
[E45B100|  80800/50000 (162%) ] Loss: 85.2232 top1= 11.6250
[E45B110|  88800/50000 (178%) ] Loss: 78.1937 top1= 11.0000

=> Eval Loss=96.3885 top1= 11.0677

Train epoch 46
[E46B0  |    800/50000 (  2%) ] Loss: 83.8972 top1= 10.5000
[E46B10 |   8800/50000 ( 18%) ] Loss: 82.0049 top1= 14.1250
[E46B20 |  16800/50000 ( 34%) ] Loss: 59.3567 top1=  9.5000
[E46B30 |  24800/50000 ( 50%) ] Loss: 45.3576 top1= 11.3750
[E46B40 |  32800/50000 ( 66%) ] Loss: 44.2089 top1= 10.8750
[E46B50 |  40800/50000 ( 82%) ] Loss: 54.3623 top1= 12.5000
[E46B60 |  48800/50000 ( 98%) ] Loss: 70.2858 top1= 10.3750
[E46B70 |  56800/50000 (114%) ] Loss: 60.1119 top1= 10.6250
