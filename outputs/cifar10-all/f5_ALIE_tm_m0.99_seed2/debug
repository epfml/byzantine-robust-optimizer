ParallelTrainer(aggregator=Trimmed Mean (b=5), max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.3983 top1= 12.1250
[E 1B10 |   8800/50000 ( 18%) ] Loss: 2.2232 top1= 18.7500
[E 1B20 |  16800/50000 ( 34%) ] Loss: 2.0654 top1= 16.1250
[E 1B30 |  24800/50000 ( 50%) ] Loss: 1.9372 top1= 27.8750
[E 1B40 |  32800/50000 ( 66%) ] Loss: 1.9046 top1= 29.2500
[E 1B50 |  40800/50000 ( 82%) ] Loss: 1.9211 top1= 24.7500
[E 1B60 |  48800/50000 ( 98%) ] Loss: 1.8120 top1= 32.1250
[E 1B70 |  56800/50000 (114%) ] Loss: 1.8555 top1= 29.8750

=> Eval Loss=1.8860 top1= 29.1066

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 1.8633 top1= 28.5000
[E 2B10 |   8800/50000 ( 18%) ] Loss: 1.8195 top1= 29.1250
[E 2B20 |  16800/50000 ( 34%) ] Loss: 1.7399 top1= 32.1250
[E 2B30 |  24800/50000 ( 50%) ] Loss: 1.7987 top1= 33.1250
[E 2B40 |  32800/50000 ( 66%) ] Loss: 1.8028 top1= 32.7500
[E 2B50 |  40800/50000 ( 82%) ] Loss: 1.7119 top1= 33.7500
[E 2B60 |  48800/50000 ( 98%) ] Loss: 1.7284 top1= 32.7500
[E 2B70 |  56800/50000 (114%) ] Loss: 1.6782 top1= 37.5000

=> Eval Loss=1.6469 top1= 37.8706

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 1.7235 top1= 36.7500
[E 3B10 |   8800/50000 ( 18%) ] Loss: 1.6348 top1= 37.0000
[E 3B20 |  16800/50000 ( 34%) ] Loss: 1.5918 top1= 40.1250
[E 3B30 |  24800/50000 ( 50%) ] Loss: 1.5655 top1= 37.8750
[E 3B40 |  32800/50000 ( 66%) ] Loss: 1.5612 top1= 42.5000
[E 3B50 |  40800/50000 ( 82%) ] Loss: 1.5885 top1= 43.1250
[E 3B60 |  48800/50000 ( 98%) ] Loss: 1.4407 top1= 45.7500
[E 3B70 |  56800/50000 (114%) ] Loss: 1.5369 top1= 40.0000

=> Eval Loss=1.4819 top1= 45.1422

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 1.4732 top1= 46.0000
[E 4B10 |   8800/50000 ( 18%) ] Loss: 1.5046 top1= 44.2500
[E 4B20 |  16800/50000 ( 34%) ] Loss: 1.4572 top1= 49.2500
[E 4B30 |  24800/50000 ( 50%) ] Loss: 1.4595 top1= 47.8750
[E 4B40 |  32800/50000 ( 66%) ] Loss: 1.4414 top1= 46.2500
[E 4B50 |  40800/50000 ( 82%) ] Loss: 1.5004 top1= 42.5000
[E 4B60 |  48800/50000 ( 98%) ] Loss: 1.3645 top1= 46.0000
[E 4B70 |  56800/50000 (114%) ] Loss: 1.3589 top1= 49.6250

=> Eval Loss=1.3713 top1= 49.1286

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 1.4378 top1= 49.1250
[E 5B10 |   8800/50000 ( 18%) ] Loss: 1.3318 top1= 52.5000
[E 5B20 |  16800/50000 ( 34%) ] Loss: 1.3336 top1= 49.5000
[E 5B30 |  24800/50000 ( 50%) ] Loss: 1.3909 top1= 46.7500
[E 5B40 |  32800/50000 ( 66%) ] Loss: 1.4096 top1= 47.3750
[E 5B50 |  40800/50000 ( 82%) ] Loss: 1.3334 top1= 50.8750
[E 5B60 |  48800/50000 ( 98%) ] Loss: 1.3167 top1= 50.5000
[E 5B70 |  56800/50000 (114%) ] Loss: 1.3375 top1= 53.0000

=> Eval Loss=1.2435 top1= 54.1667

Train epoch 6
[E 6B0  |    800/50000 (  2%) ] Loss: 1.3691 top1= 48.8750
[E 6B10 |   8800/50000 ( 18%) ] Loss: 1.2803 top1= 52.3750
[E 6B20 |  16800/50000 ( 34%) ] Loss: 1.3522 top1= 51.3750
[E 6B30 |  24800/50000 ( 50%) ] Loss: 1.3220 top1= 52.7500
[E 6B40 |  32800/50000 ( 66%) ] Loss: 1.2313 top1= 54.2500
[E 6B50 |  40800/50000 ( 82%) ] Loss: 1.1936 top1= 57.7500
[E 6B60 |  48800/50000 ( 98%) ] Loss: 1.2289 top1= 57.2500
[E 6B70 |  56800/50000 (114%) ] Loss: 1.2060 top1= 57.0000

=> Eval Loss=1.1346 top1= 58.5437

Train epoch 7
[E 7B0  |    800/50000 (  2%) ] Loss: 1.1360 top1= 57.5000
[E 7B10 |   8800/50000 ( 18%) ] Loss: 1.1477 top1= 57.5000
[E 7B20 |  16800/50000 ( 34%) ] Loss: 1.0235 top1= 63.2500
[E 7B30 |  24800/50000 ( 50%) ] Loss: 1.2256 top1= 56.8750
[E 7B40 |  32800/50000 ( 66%) ] Loss: 1.1621 top1= 59.7500
[E 7B50 |  40800/50000 ( 82%) ] Loss: 1.1642 top1= 57.7500
[E 7B60 |  48800/50000 ( 98%) ] Loss: 1.1237 top1= 58.3750
[E 7B70 |  56800/50000 (114%) ] Loss: 1.0794 top1= 62.3750

=> Eval Loss=1.0605 top1= 61.4283

Train epoch 8
[E 8B0  |    800/50000 (  2%) ] Loss: 1.1828 top1= 53.6250
[E 8B10 |   8800/50000 ( 18%) ] Loss: 1.1263 top1= 59.1250
[E 8B20 |  16800/50000 ( 34%) ] Loss: 1.0845 top1= 62.7500
[E 8B30 |  24800/50000 ( 50%) ] Loss: 1.0688 top1= 59.8750
[E 8B40 |  32800/50000 ( 66%) ] Loss: 1.1304 top1= 59.5000
[E 8B50 |  40800/50000 ( 82%) ] Loss: 1.0806 top1= 62.2500
[E 8B60 |  48800/50000 ( 98%) ] Loss: 1.0677 top1= 64.5000
[E 8B70 |  56800/50000 (114%) ] Loss: 1.0239 top1= 65.5000

=> Eval Loss=1.0026 top1= 64.2829

Train epoch 9
[E 9B0  |    800/50000 (  2%) ] Loss: 1.0431 top1= 61.7500
[E 9B10 |   8800/50000 ( 18%) ] Loss: 0.9128 top1= 67.1250
[E 9B20 |  16800/50000 ( 34%) ] Loss: 1.0183 top1= 65.0000
[E 9B30 |  24800/50000 ( 50%) ] Loss: 1.0289 top1= 63.1250
[E 9B40 |  32800/50000 ( 66%) ] Loss: 0.9835 top1= 65.5000
[E 9B50 |  40800/50000 ( 82%) ] Loss: 0.9718 top1= 65.6250
[E 9B60 |  48800/50000 ( 98%) ] Loss: 0.9892 top1= 66.1250
[E 9B70 |  56800/50000 (114%) ] Loss: 0.9519 top1= 66.7500

=> Eval Loss=0.9569 top1= 66.0156

Train epoch 10
[E10B0  |    800/50000 (  2%) ] Loss: 0.9403 top1= 67.6250
[E10B10 |   8800/50000 ( 18%) ] Loss: 0.9617 top1= 65.7500
[E10B20 |  16800/50000 ( 34%) ] Loss: 0.9758 top1= 66.7500
[E10B30 |  24800/50000 ( 50%) ] Loss: 0.9597 top1= 66.3750
[E10B40 |  32800/50000 ( 66%) ] Loss: 0.9018 top1= 67.6250
[E10B50 |  40800/50000 ( 82%) ] Loss: 0.9042 top1= 66.8750
[E10B60 |  48800/50000 ( 98%) ] Loss: 0.8909 top1= 69.0000
[E10B70 |  56800/50000 (114%) ] Loss: 0.9127 top1= 69.2500

=> Eval Loss=0.9134 top1= 68.3694

Train epoch 11
[E11B0  |    800/50000 (  2%) ] Loss: 0.8605 top1= 69.1250
[E11B10 |   8800/50000 ( 18%) ] Loss: 0.9915 top1= 63.6250
[E11B20 |  16800/50000 ( 34%) ] Loss: 0.8394 top1= 70.0000
[E11B30 |  24800/50000 ( 50%) ] Loss: 0.8810 top1= 67.0000
[E11B40 |  32800/50000 ( 66%) ] Loss: 0.8800 top1= 69.3750
[E11B50 |  40800/50000 ( 82%) ] Loss: 0.9960 top1= 63.2500
[E11B60 |  48800/50000 ( 98%) ] Loss: 0.8807 top1= 68.7500
[E11B70 |  56800/50000 (114%) ] Loss: 0.8773 top1= 69.7500

=> Eval Loss=0.8403 top1= 70.7432

Train epoch 12
[E12B0  |    800/50000 (  2%) ] Loss: 0.9007 top1= 69.2500
[E12B10 |   8800/50000 ( 18%) ] Loss: 0.9098 top1= 67.7500
[E12B20 |  16800/50000 ( 34%) ] Loss: 0.8556 top1= 69.7500
[E12B30 |  24800/50000 ( 50%) ] Loss: 0.8864 top1= 66.7500
[E12B40 |  32800/50000 ( 66%) ] Loss: 0.8126 top1= 71.3750
[E12B50 |  40800/50000 ( 82%) ] Loss: 0.8963 top1= 69.0000
[E12B60 |  48800/50000 ( 98%) ] Loss: 0.7943 top1= 72.5000
[E12B70 |  56800/50000 (114%) ] Loss: 0.7884 top1= 72.1250

=> Eval Loss=0.8269 top1= 71.4143

Train epoch 13
[E13B0  |    800/50000 (  2%) ] Loss: 0.7327 top1= 72.5000
[E13B10 |   8800/50000 ( 18%) ] Loss: 0.7811 top1= 71.7500
[E13B20 |  16800/50000 ( 34%) ] Loss: 0.8264 top1= 69.7500
[E13B30 |  24800/50000 ( 50%) ] Loss: 0.7645 top1= 73.3750
[E13B40 |  32800/50000 ( 66%) ] Loss: 0.7553 top1= 69.6250
[E13B50 |  40800/50000 ( 82%) ] Loss: 0.8252 top1= 71.2500
[E13B60 |  48800/50000 ( 98%) ] Loss: 0.7886 top1= 71.6250
[E13B70 |  56800/50000 (114%) ] Loss: 0.8892 top1= 68.3750

=> Eval Loss=0.8046 top1= 71.8750

Train epoch 14
[E14B0  |    800/50000 (  2%) ] Loss: 0.7519 top1= 73.5000
[E14B10 |   8800/50000 ( 18%) ] Loss: 0.8440 top1= 69.6250
[E14B20 |  16800/50000 ( 34%) ] Loss: 0.8361 top1= 71.6250
[E14B30 |  24800/50000 ( 50%) ] Loss: 0.7725 top1= 74.0000
[E14B40 |  32800/50000 ( 66%) ] Loss: 0.6869 top1= 77.0000
[E14B50 |  40800/50000 ( 82%) ] Loss: 0.7733 top1= 73.0000
[E14B60 |  48800/50000 ( 98%) ] Loss: 0.7731 top1= 75.1250
[E14B70 |  56800/50000 (114%) ] Loss: 0.7229 top1= 75.0000

=> Eval Loss=0.7549 top1= 74.0385

Train epoch 15
[E15B0  |    800/50000 (  2%) ] Loss: 0.7922 top1= 72.0000
[E15B10 |   8800/50000 ( 18%) ] Loss: 0.7612 top1= 73.3750
[E15B20 |  16800/50000 ( 34%) ] Loss: 0.6419 top1= 79.2500
[E15B30 |  24800/50000 ( 50%) ] Loss: 0.7444 top1= 73.3750
[E15B40 |  32800/50000 ( 66%) ] Loss: 0.7452 top1= 74.6250
[E15B50 |  40800/50000 ( 82%) ] Loss: 0.6414 top1= 75.7500
[E15B60 |  48800/50000 ( 98%) ] Loss: 0.7455 top1= 75.3750
[E15B70 |  56800/50000 (114%) ] Loss: 0.8425 top1= 68.7500

=> Eval Loss=0.7604 top1= 74.5092

Train epoch 16
[E16B0  |    800/50000 (  2%) ] Loss: 0.7270 top1= 74.8750
[E16B10 |   8800/50000 ( 18%) ] Loss: 0.6845 top1= 76.1250
[E16B20 |  16800/50000 ( 34%) ] Loss: 0.6894 top1= 76.1250
[E16B30 |  24800/50000 ( 50%) ] Loss: 0.7354 top1= 73.6250
[E16B40 |  32800/50000 ( 66%) ] Loss: 0.7559 top1= 72.2500
[E16B50 |  40800/50000 ( 82%) ] Loss: 0.7785 top1= 72.7500
[E16B60 |  48800/50000 ( 98%) ] Loss: 0.6677 top1= 76.2500
[E16B70 |  56800/50000 (114%) ] Loss: 0.7452 top1= 74.1250

=> Eval Loss=0.7500 top1= 74.2989

Train epoch 17
[E17B0  |    800/50000 (  2%) ] Loss: 0.7511 top1= 74.7500
[E17B10 |   8800/50000 ( 18%) ] Loss: 0.6932 top1= 74.5000
[E17B20 |  16800/50000 ( 34%) ] Loss: 0.7403 top1= 72.6250
[E17B30 |  24800/50000 ( 50%) ] Loss: 0.6244 top1= 77.5000
[E17B40 |  32800/50000 ( 66%) ] Loss: 0.7165 top1= 75.2500
[E17B50 |  40800/50000 ( 82%) ] Loss: 0.6921 top1= 74.6250
[E17B60 |  48800/50000 ( 98%) ] Loss: 0.6709 top1= 76.7500
[E17B70 |  56800/50000 (114%) ] Loss: 0.7592 top1= 72.7500

=> Eval Loss=0.7543 top1= 74.2788

Train epoch 18
[E18B0  |    800/50000 (  2%) ] Loss: 0.7435 top1= 74.5000
[E18B10 |   8800/50000 ( 18%) ] Loss: 0.6952 top1= 74.8750
[E18B20 |  16800/50000 ( 34%) ] Loss: 0.6853 top1= 77.8750
[E18B30 |  24800/50000 ( 50%) ] Loss: 0.6887 top1= 76.7500
[E18B40 |  32800/50000 ( 66%) ] Loss: 0.6883 top1= 75.8750
[E18B50 |  40800/50000 ( 82%) ] Loss: 0.7382 top1= 74.1250
[E18B60 |  48800/50000 ( 98%) ] Loss: 0.6813 top1= 75.5000
[E18B70 |  56800/50000 (114%) ] Loss: 0.6086 top1= 79.0000

=> Eval Loss=0.6870 top1= 76.5024

Train epoch 19
[E19B0  |    800/50000 (  2%) ] Loss: 0.6546 top1= 78.6250
[E19B10 |   8800/50000 ( 18%) ] Loss: 0.6231 top1= 78.6250
[E19B20 |  16800/50000 ( 34%) ] Loss: 0.5753 top1= 79.0000
[E19B30 |  24800/50000 ( 50%) ] Loss: 0.6195 top1= 78.7500
[E19B40 |  32800/50000 ( 66%) ] Loss: 0.5833 top1= 80.5000
[E19B50 |  40800/50000 ( 82%) ] Loss: 0.6594 top1= 76.1250
[E19B60 |  48800/50000 ( 98%) ] Loss: 0.6180 top1= 78.1250
[E19B70 |  56800/50000 (114%) ] Loss: 0.6762 top1= 76.6250

=> Eval Loss=0.6553 top1= 77.4038

Train epoch 20
[E20B0  |    800/50000 (  2%) ] Loss: 0.6503 top1= 78.0000
[E20B10 |   8800/50000 ( 18%) ] Loss: 0.6064 top1= 79.1250
[E20B20 |  16800/50000 ( 34%) ] Loss: 0.6815 top1= 76.2500
[E20B30 |  24800/50000 ( 50%) ] Loss: 0.6353 top1= 80.8750
[E20B40 |  32800/50000 ( 66%) ] Loss: 0.5938 top1= 79.6250
[E20B50 |  40800/50000 ( 82%) ] Loss: 0.6219 top1= 78.5000
[E20B60 |  48800/50000 ( 98%) ] Loss: 0.6557 top1= 77.3750
[E20B70 |  56800/50000 (114%) ] Loss: 0.6106 top1= 79.0000

=> Eval Loss=0.6610 top1= 77.1134

Train epoch 21
[E21B0  |    800/50000 (  2%) ] Loss: 0.6114 top1= 78.5000
[E21B10 |   8800/50000 ( 18%) ] Loss: 0.5928 top1= 79.6250
[E21B20 |  16800/50000 ( 34%) ] Loss: 0.5974 top1= 77.7500
[E21B30 |  24800/50000 ( 50%) ] Loss: 0.6114 top1= 79.1250
[E21B40 |  32800/50000 ( 66%) ] Loss: 0.6408 top1= 76.5000
[E21B50 |  40800/50000 ( 82%) ] Loss: 0.6370 top1= 78.6250
[E21B60 |  48800/50000 ( 98%) ] Loss: 0.6066 top1= 79.1250
[E21B70 |  56800/50000 (114%) ] Loss: 0.6275 top1= 79.5000

=> Eval Loss=0.6039 top1= 79.5873

Train epoch 22
[E22B0  |    800/50000 (  2%) ] Loss: 0.5965 top1= 80.3750
[E22B10 |   8800/50000 ( 18%) ] Loss: 0.5669 top1= 79.1250
[E22B20 |  16800/50000 ( 34%) ] Loss: 0.6135 top1= 77.5000
[E22B30 |  24800/50000 ( 50%) ] Loss: 0.5569 top1= 79.0000
[E22B40 |  32800/50000 ( 66%) ] Loss: 0.5084 top1= 82.0000
[E22B50 |  40800/50000 ( 82%) ] Loss: 0.6394 top1= 77.0000
[E22B60 |  48800/50000 ( 98%) ] Loss: 0.5873 top1= 81.6250
[E22B70 |  56800/50000 (114%) ] Loss: 0.6147 top1= 78.0000

=> Eval Loss=0.6139 top1= 79.1366

Train epoch 23
[E23B0  |    800/50000 (  2%) ] Loss: 0.5638 top1= 80.7500
[E23B10 |   8800/50000 ( 18%) ] Loss: 0.5695 top1= 79.8750
[E23B20 |  16800/50000 ( 34%) ] Loss: 0.5243 top1= 83.8750
[E23B30 |  24800/50000 ( 50%) ] Loss: 0.6166 top1= 80.6250
[E23B40 |  32800/50000 ( 66%) ] Loss: 0.5367 top1= 82.3750
[E23B50 |  40800/50000 ( 82%) ] Loss: 0.5414 top1= 82.3750
[E23B60 |  48800/50000 ( 98%) ] Loss: 0.5646 top1= 81.1250
[E23B70 |  56800/50000 (114%) ] Loss: 0.6067 top1= 78.2500

=> Eval Loss=0.6356 top1= 78.5056

Train epoch 24
[E24B0  |    800/50000 (  2%) ] Loss: 0.5438 top1= 81.8750
[E24B10 |   8800/50000 ( 18%) ] Loss: 0.4948 top1= 82.7500
[E24B20 |  16800/50000 ( 34%) ] Loss: 0.5493 top1= 82.3750
[E24B30 |  24800/50000 ( 50%) ] Loss: 0.6179 top1= 80.3750
[E24B40 |  32800/50000 ( 66%) ] Loss: 0.5757 top1= 80.6250
[E24B50 |  40800/50000 ( 82%) ] Loss: 0.5351 top1= 80.7500
[E24B60 |  48800/50000 ( 98%) ] Loss: 0.5956 top1= 78.5000
[E24B70 |  56800/50000 (114%) ] Loss: 0.5517 top1= 81.7500

=> Eval Loss=0.6000 top1= 79.7576

Train epoch 25
[E25B0  |    800/50000 (  2%) ] Loss: 0.5251 top1= 81.6250
[E25B10 |   8800/50000 ( 18%) ] Loss: 0.4661 top1= 81.0000
[E25B20 |  16800/50000 ( 34%) ] Loss: 0.5370 top1= 81.3750
[E25B30 |  24800/50000 ( 50%) ] Loss: 0.5122 top1= 81.2500
[E25B40 |  32800/50000 ( 66%) ] Loss: 0.5477 top1= 82.3750
[E25B50 |  40800/50000 ( 82%) ] Loss: 0.5804 top1= 79.2500
[E25B60 |  48800/50000 ( 98%) ] Loss: 0.5913 top1= 79.5000
[E25B70 |  56800/50000 (114%) ] Loss: 0.6260 top1= 78.3750

=> Eval Loss=0.5807 top1= 80.7893

Train epoch 26
[E26B0  |    800/50000 (  2%) ] Loss: 0.4447 top1= 83.7500
[E26B10 |   8800/50000 ( 18%) ] Loss: 0.5247 top1= 82.5000
[E26B20 |  16800/50000 ( 34%) ] Loss: 0.5398 top1= 80.6250
[E26B30 |  24800/50000 ( 50%) ] Loss: 0.5272 top1= 84.0000
[E26B40 |  32800/50000 ( 66%) ] Loss: 0.5308 top1= 82.3750
[E26B50 |  40800/50000 ( 82%) ] Loss: 0.5315 top1= 82.7500
[E26B60 |  48800/50000 ( 98%) ] Loss: 0.5641 top1= 80.8750
[E26B70 |  56800/50000 (114%) ] Loss: 0.4769 top1= 84.2500

=> Eval Loss=0.5796 top1= 80.3185

Train epoch 27
[E27B0  |    800/50000 (  2%) ] Loss: 0.4379 top1= 85.5000
[E27B10 |   8800/50000 ( 18%) ] Loss: 0.4775 top1= 84.1250
[E27B20 |  16800/50000 ( 34%) ] Loss: 0.4921 top1= 83.6250
[E27B30 |  24800/50000 ( 50%) ] Loss: 0.5562 top1= 80.3750
[E27B40 |  32800/50000 ( 66%) ] Loss: 0.4916 top1= 83.1250
[E27B50 |  40800/50000 ( 82%) ] Loss: 0.5759 top1= 79.2500
[E27B60 |  48800/50000 ( 98%) ] Loss: 0.4750 top1= 82.8750
[E27B70 |  56800/50000 (114%) ] Loss: 0.5080 top1= 82.6250

=> Eval Loss=0.5840 top1= 80.6190

Train epoch 28
[E28B0  |    800/50000 (  2%) ] Loss: 0.4933 top1= 82.2500
[E28B10 |   8800/50000 ( 18%) ] Loss: 0.4952 top1= 81.2500
[E28B20 |  16800/50000 ( 34%) ] Loss: 0.5023 top1= 83.5000
[E28B30 |  24800/50000 ( 50%) ] Loss: 0.5040 top1= 82.0000
[E28B40 |  32800/50000 ( 66%) ] Loss: 0.4577 top1= 84.1250
[E28B50 |  40800/50000 ( 82%) ] Loss: 0.5061 top1= 82.7500
[E28B60 |  48800/50000 ( 98%) ] Loss: 0.4907 top1= 82.1250
[E28B70 |  56800/50000 (114%) ] Loss: 0.5776 top1= 80.0000

=> Eval Loss=0.5625 top1= 80.8994

Train epoch 29
[E29B0  |    800/50000 (  2%) ] Loss: 0.5218 top1= 83.7500
[E29B10 |   8800/50000 ( 18%) ] Loss: 0.5152 top1= 82.6250
[E29B20 |  16800/50000 ( 34%) ] Loss: 0.5299 top1= 80.7500
[E29B30 |  24800/50000 ( 50%) ] Loss: 0.5200 top1= 80.5000
[E29B40 |  32800/50000 ( 66%) ] Loss: 0.5305 top1= 81.8750
[E29B50 |  40800/50000 ( 82%) ] Loss: 0.5149 top1= 80.7500
[E29B60 |  48800/50000 ( 98%) ] Loss: 0.5563 top1= 79.2500
[E29B70 |  56800/50000 (114%) ] Loss: 0.5302 top1= 80.7500

=> Eval Loss=0.5465 top1= 81.4303

Train epoch 30
[E30B0  |    800/50000 (  2%) ] Loss: 0.4912 top1= 83.7500
[E30B10 |   8800/50000 ( 18%) ] Loss: 0.4817 top1= 81.8750
[E30B20 |  16800/50000 ( 34%) ] Loss: 0.5379 top1= 82.5000
[E30B30 |  24800/50000 ( 50%) ] Loss: 0.4233 top1= 85.8750
[E30B40 |  32800/50000 ( 66%) ] Loss: 0.4406 top1= 84.1250
[E30B50 |  40800/50000 ( 82%) ] Loss: 0.4726 top1= 82.7500
[E30B60 |  48800/50000 ( 98%) ] Loss: 0.4761 top1= 83.5000
[E30B70 |  56800/50000 (114%) ] Loss: 0.5122 top1= 80.6250

=> Eval Loss=0.5743 top1= 80.9495

Train epoch 31
[E31B0  |    800/50000 (  2%) ] Loss: 0.5340 top1= 81.0000
[E31B10 |   8800/50000 ( 18%) ] Loss: 0.4398 top1= 85.2500
[E31B20 |  16800/50000 ( 34%) ] Loss: 0.4892 top1= 82.2500
[E31B30 |  24800/50000 ( 50%) ] Loss: 0.4237 top1= 87.0000
[E31B40 |  32800/50000 ( 66%) ] Loss: 0.5290 top1= 80.0000
[E31B50 |  40800/50000 ( 82%) ] Loss: 0.4345 top1= 83.7500
[E31B60 |  48800/50000 ( 98%) ] Loss: 0.4440 top1= 84.1250
[E31B70 |  56800/50000 (114%) ] Loss: 0.4812 top1= 82.1250

=> Eval Loss=0.5476 top1= 82.0012

Train epoch 32
[E32B0  |    800/50000 (  2%) ] Loss: 0.3976 top1= 86.5000
[E32B10 |   8800/50000 ( 18%) ] Loss: 0.4198 top1= 84.7500
[E32B20 |  16800/50000 ( 34%) ] Loss: 0.5632 top1= 80.6250
[E32B30 |  24800/50000 ( 50%) ] Loss: 0.4225 top1= 84.5000
[E32B40 |  32800/50000 ( 66%) ] Loss: 0.4521 top1= 84.0000
[E32B50 |  40800/50000 ( 82%) ] Loss: 0.4490 top1= 83.7500
[E32B60 |  48800/50000 ( 98%) ] Loss: 0.4801 top1= 82.2500
[E32B70 |  56800/50000 (114%) ] Loss: 0.4308 top1= 84.2500

=> Eval Loss=0.5438 top1= 82.1214

Train epoch 33
[E33B0  |    800/50000 (  2%) ] Loss: 0.4760 top1= 82.6250
[E33B10 |   8800/50000 ( 18%) ] Loss: 0.4437 top1= 83.8750
[E33B20 |  16800/50000 ( 34%) ] Loss: 0.5080 top1= 83.0000
[E33B30 |  24800/50000 ( 50%) ] Loss: 0.4516 top1= 86.3750
[E33B40 |  32800/50000 ( 66%) ] Loss: 0.5191 top1= 81.2500
[E33B50 |  40800/50000 ( 82%) ] Loss: 0.4622 top1= 83.0000
[E33B60 |  48800/50000 ( 98%) ] Loss: 0.5087 top1= 81.8750
[E33B70 |  56800/50000 (114%) ] Loss: 0.4819 top1= 82.1250

=> Eval Loss=0.5231 top1= 82.2416

Train epoch 34
[E34B0  |    800/50000 (  2%) ] Loss: 0.4897 top1= 82.5000
[E34B10 |   8800/50000 ( 18%) ] Loss: 0.4465 top1= 83.6250
[E34B20 |  16800/50000 ( 34%) ] Loss: 0.4462 top1= 84.5000
[E34B30 |  24800/50000 ( 50%) ] Loss: 0.4697 top1= 83.0000
[E34B40 |  32800/50000 ( 66%) ] Loss: 0.4861 top1= 81.7500
[E34B50 |  40800/50000 ( 82%) ] Loss: 0.5368 top1= 80.2500
[E34B60 |  48800/50000 ( 98%) ] Loss: 0.4240 top1= 85.8750
[E34B70 |  56800/50000 (114%) ] Loss: 0.4224 top1= 84.3750

=> Eval Loss=0.5188 top1= 82.5120

Train epoch 35
[E35B0  |    800/50000 (  2%) ] Loss: 0.4058 top1= 85.0000
[E35B10 |   8800/50000 ( 18%) ] Loss: 0.4134 top1= 84.2500
[E35B20 |  16800/50000 ( 34%) ] Loss: 0.4398 top1= 83.5000
[E35B30 |  24800/50000 ( 50%) ] Loss: 0.3769 top1= 87.0000
[E35B40 |  32800/50000 ( 66%) ] Loss: 0.5294 top1= 83.1250
[E35B50 |  40800/50000 ( 82%) ] Loss: 0.4747 top1= 84.3750
[E35B60 |  48800/50000 ( 98%) ] Loss: 0.4713 top1= 83.1250
[E35B70 |  56800/50000 (114%) ] Loss: 0.3564 top1= 86.6250

=> Eval Loss=0.5450 top1= 82.0012

Train epoch 36
[E36B0  |    800/50000 (  2%) ] Loss: 0.4128 top1= 85.1250
[E36B10 |   8800/50000 ( 18%) ] Loss: 0.3438 top1= 88.6250
[E36B20 |  16800/50000 ( 34%) ] Loss: 0.3878 top1= 86.5000
[E36B30 |  24800/50000 ( 50%) ] Loss: 0.4482 top1= 84.2500
[E36B40 |  32800/50000 ( 66%) ] Loss: 0.4436 top1= 83.1250
[E36B50 |  40800/50000 ( 82%) ] Loss: 0.4246 top1= 84.6250
[E36B60 |  48800/50000 ( 98%) ] Loss: 0.4394 top1= 84.1250
[E36B70 |  56800/50000 (114%) ] Loss: 0.4097 top1= 85.7500

=> Eval Loss=0.5214 top1= 82.4419

Train epoch 37
[E37B0  |    800/50000 (  2%) ] Loss: 0.3496 top1= 87.8750
[E37B10 |   8800/50000 ( 18%) ] Loss: 0.4347 top1= 84.6250
[E37B20 |  16800/50000 ( 34%) ] Loss: 0.3964 top1= 86.3750
[E37B30 |  24800/50000 ( 50%) ] Loss: 0.4139 top1= 86.3750
[E37B40 |  32800/50000 ( 66%) ] Loss: 0.4462 top1= 84.1250
[E37B50 |  40800/50000 ( 82%) ] Loss: 0.3926 top1= 85.2500
[E37B60 |  48800/50000 ( 98%) ] Loss: 0.3837 top1= 85.0000
[E37B70 |  56800/50000 (114%) ] Loss: 0.4176 top1= 85.8750

=> Eval Loss=0.5075 top1= 83.1230

Train epoch 38
[E38B0  |    800/50000 (  2%) ] Loss: 0.4148 top1= 85.8750
[E38B10 |   8800/50000 ( 18%) ] Loss: 0.4491 top1= 82.8750
[E38B20 |  16800/50000 ( 34%) ] Loss: 0.4111 top1= 84.3750
[E38B30 |  24800/50000 ( 50%) ] Loss: 0.4444 top1= 85.0000
[E38B40 |  32800/50000 ( 66%) ] Loss: 0.4594 top1= 84.2500
[E38B50 |  40800/50000 ( 82%) ] Loss: 0.3859 top1= 86.2500
[E38B60 |  48800/50000 ( 98%) ] Loss: 0.3879 top1= 85.6250
[E38B70 |  56800/50000 (114%) ] Loss: 0.3606 top1= 88.6250

=> Eval Loss=0.5190 top1= 83.0329

Train epoch 39
[E39B0  |    800/50000 (  2%) ] Loss: 0.3818 top1= 87.2500
[E39B10 |   8800/50000 ( 18%) ] Loss: 0.3425 top1= 87.0000
[E39B20 |  16800/50000 ( 34%) ] Loss: 0.4615 top1= 82.6250
[E39B30 |  24800/50000 ( 50%) ] Loss: 0.4248 top1= 84.6250
[E39B40 |  32800/50000 ( 66%) ] Loss: 0.3684 top1= 87.6250
[E39B50 |  40800/50000 ( 82%) ] Loss: 0.4280 top1= 84.0000
[E39B60 |  48800/50000 ( 98%) ] Loss: 0.4896 top1= 84.2500
[E39B70 |  56800/50000 (114%) ] Loss: 0.3731 top1= 86.1250

=> Eval Loss=0.5380 top1= 83.0028

Train epoch 40
[E40B0  |    800/50000 (  2%) ] Loss: 0.3621 top1= 86.8750
[E40B10 |   8800/50000 ( 18%) ] Loss: 0.3779 top1= 87.3750
[E40B20 |  16800/50000 ( 34%) ] Loss: 0.3921 top1= 87.6250
[E40B30 |  24800/50000 ( 50%) ] Loss: 0.3410 top1= 87.8750
[E40B40 |  32800/50000 ( 66%) ] Loss: 0.3793 top1= 86.8750
[E40B50 |  40800/50000 ( 82%) ] Loss: 0.4142 top1= 85.5000
[E40B60 |  48800/50000 ( 98%) ] Loss: 0.3580 top1= 88.7500
[E40B70 |  56800/50000 (114%) ] Loss: 0.4496 top1= 84.1250

=> Eval Loss=0.4936 top1= 83.6538

Train epoch 41
[E41B0  |    800/50000 (  2%) ] Loss: 0.3398 top1= 88.1250
[E41B10 |   8800/50000 ( 18%) ] Loss: 0.4141 top1= 87.1250
[E41B20 |  16800/50000 ( 34%) ] Loss: 0.3733 top1= 86.3750
[E41B30 |  24800/50000 ( 50%) ] Loss: 0.3533 top1= 88.8750
[E41B40 |  32800/50000 ( 66%) ] Loss: 0.3972 top1= 86.1250
[E41B50 |  40800/50000 ( 82%) ] Loss: 0.4141 top1= 85.0000
[E41B60 |  48800/50000 ( 98%) ] Loss: 0.4263 top1= 85.3750
[E41B70 |  56800/50000 (114%) ] Loss: 0.3601 top1= 86.1250

=> Eval Loss=0.4967 top1= 83.8642

Train epoch 42
[E42B0  |    800/50000 (  2%) ] Loss: 0.3802 top1= 88.1250
[E42B10 |   8800/50000 ( 18%) ] Loss: 0.3969 top1= 87.2500
[E42B20 |  16800/50000 ( 34%) ] Loss: 0.3770 top1= 86.1250
[E42B30 |  24800/50000 ( 50%) ] Loss: 0.4270 top1= 85.3750
[E42B40 |  32800/50000 ( 66%) ] Loss: 0.4304 top1= 83.8750
[E42B50 |  40800/50000 ( 82%) ] Loss: 0.3634 top1= 86.5000
[E42B60 |  48800/50000 ( 98%) ] Loss: 0.4076 top1= 85.7500
[E42B70 |  56800/50000 (114%) ] Loss: 0.4024 top1= 86.7500

=> Eval Loss=0.4955 top1= 83.7640

Train epoch 43
[E43B0  |    800/50000 (  2%) ] Loss: 0.3920 top1= 85.3750
[E43B10 |   8800/50000 ( 18%) ] Loss: 0.3663 top1= 87.1250
[E43B20 |  16800/50000 ( 34%) ] Loss: 0.3797 top1= 86.1250
[E43B30 |  24800/50000 ( 50%) ] Loss: 0.4060 top1= 86.6250
[E43B40 |  32800/50000 ( 66%) ] Loss: 0.3998 top1= 86.2500
[E43B50 |  40800/50000 ( 82%) ] Loss: 0.3363 top1= 87.1250
[E43B60 |  48800/50000 ( 98%) ] Loss: 0.4118 top1= 85.8750
[E43B70 |  56800/50000 (114%) ] Loss: 0.3532 top1= 87.6250

=> Eval Loss=0.4892 top1= 84.2047

Train epoch 44
[E44B0  |    800/50000 (  2%) ] Loss: 0.3276 top1= 89.0000
[E44B10 |   8800/50000 ( 18%) ] Loss: 0.3199 top1= 88.2500
[E44B20 |  16800/50000 ( 34%) ] Loss: 0.3514 top1= 87.0000
[E44B30 |  24800/50000 ( 50%) ] Loss: 0.3750 top1= 86.6250
[E44B40 |  32800/50000 ( 66%) ] Loss: 0.3609 top1= 87.7500
[E44B50 |  40800/50000 ( 82%) ] Loss: 0.3531 top1= 88.0000
[E44B60 |  48800/50000 ( 98%) ] Loss: 0.3561 top1= 87.8750
[E44B70 |  56800/50000 (114%) ] Loss: 0.3923 top1= 85.8750

=> Eval Loss=0.4663 top1= 84.6354

Train epoch 45
[E45B0  |    800/50000 (  2%) ] Loss: 0.3639 top1= 89.0000
[E45B10 |   8800/50000 ( 18%) ] Loss: 0.3355 top1= 87.3750
[E45B20 |  16800/50000 ( 34%) ] Loss: 0.4486 top1= 85.3750
[E45B30 |  24800/50000 ( 50%) ] Loss: 0.5029 top1= 85.0000
[E45B40 |  32800/50000 ( 66%) ] Loss: 0.3729 top1= 84.8750
[E45B50 |  40800/50000 ( 82%) ] Loss: 0.3502 top1= 86.1250
[E45B60 |  48800/50000 ( 98%) ] Loss: 0.3154 top1= 88.6250
[E45B70 |  56800/50000 (114%) ] Loss: 0.3237 top1= 88.8750

=> Eval Loss=0.4834 top1= 84.1046

Train epoch 46
[E46B0  |    800/50000 (  2%) ] Loss: 0.3503 top1= 88.2500
[E46B10 |   8800/50000 ( 18%) ] Loss: 0.3989 top1= 86.3750
[E46B20 |  16800/50000 ( 34%) ] Loss: 0.3606 top1= 86.7500
[E46B30 |  24800/50000 ( 50%) ] Loss: 0.3912 top1= 86.0000
[E46B40 |  32800/50000 ( 66%) ] Loss: 0.3461 top1= 87.1250
[E46B50 |  40800/50000 ( 82%) ] Loss: 0.3604 top1= 87.3750
[E46B60 |  48800/50000 ( 98%) ] Loss: 0.3510 top1= 88.8750
[E46B70 |  56800/50000 (114%) ] Loss: 0.2992 top1= 89.2500

=> Eval Loss=0.4988 top1= 84.2147

Train epoch 47
[E47B0  |    800/50000 (  2%) ] Loss: 0.3823 top1= 84.8750
