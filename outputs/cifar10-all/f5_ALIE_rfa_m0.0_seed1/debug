ParallelTrainer(aggregator=RFA(T=3,nu=0.1), max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker ByzantineWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.4310 top1= 12.0000
[E 1B10 |   8800/50000 ( 18%) ] Loss: 2.1856 top1= 17.5000
[E 1B20 |  16800/50000 ( 34%) ] Loss: 2.0451 top1= 19.5000
[E 1B30 |  24800/50000 ( 50%) ] Loss: 1.9857 top1= 24.0000
[E 1B40 |  32800/50000 ( 66%) ] Loss: 1.9124 top1= 26.3750
[E 1B50 |  40800/50000 ( 82%) ] Loss: 1.9517 top1= 24.1250
[E 1B60 |  48800/50000 ( 98%) ] Loss: 1.8763 top1= 27.2500
[E 1B70 |  56800/50000 (114%) ] Loss: 1.9536 top1= 21.8750

=> Eval Loss=1.8766 top1= 28.7660

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 1.8783 top1= 29.2500
[E 2B10 |   8800/50000 ( 18%) ] Loss: 1.8847 top1= 26.2500
[E 2B20 |  16800/50000 ( 34%) ] Loss: 1.8588 top1= 29.2500
[E 2B30 |  24800/50000 ( 50%) ] Loss: 1.9283 top1= 25.8750
[E 2B40 |  32800/50000 ( 66%) ] Loss: 1.9601 top1= 27.0000
[E 2B50 |  40800/50000 ( 82%) ] Loss: 1.8653 top1= 28.0000
[E 2B60 |  48800/50000 ( 98%) ] Loss: 1.9680 top1= 26.0000
[E 2B70 |  56800/50000 (114%) ] Loss: 1.9417 top1= 25.6250

=> Eval Loss=2.0094 top1= 24.2688

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 1.9613 top1= 27.6250
[E 3B10 |   8800/50000 ( 18%) ] Loss: 1.8546 top1= 27.8750
[E 3B20 |  16800/50000 ( 34%) ] Loss: 1.9302 top1= 26.0000
[E 3B30 |  24800/50000 ( 50%) ] Loss: 1.8933 top1= 26.8750
[E 3B40 |  32800/50000 ( 66%) ] Loss: 1.8257 top1= 30.7500
[E 3B50 |  40800/50000 ( 82%) ] Loss: 1.9158 top1= 26.5000
[E 3B60 |  48800/50000 ( 98%) ] Loss: 1.8436 top1= 30.0000
[E 3B70 |  56800/50000 (114%) ] Loss: 1.8683 top1= 24.8750

=> Eval Loss=2.7032 top1= 23.3073

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 1.9047 top1= 28.5000
[E 4B10 |   8800/50000 ( 18%) ] Loss: 1.8858 top1= 29.5000
[E 4B20 |  16800/50000 ( 34%) ] Loss: 1.8104 top1= 32.5000
[E 4B30 |  24800/50000 ( 50%) ] Loss: 1.9028 top1= 25.5000
[E 4B40 |  32800/50000 ( 66%) ] Loss: 1.9432 top1= 24.1250
[E 4B50 |  40800/50000 ( 82%) ] Loss: 1.8180 top1= 29.8750
[E 4B60 |  48800/50000 ( 98%) ] Loss: 1.8063 top1= 30.6250
[E 4B70 |  56800/50000 (114%) ] Loss: 1.8139 top1= 29.1250

=> Eval Loss=2.0215 top1= 23.4175

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 1.9647 top1= 24.2500
[E 5B10 |   8800/50000 ( 18%) ] Loss: 1.8566 top1= 29.1250
[E 5B20 |  16800/50000 ( 34%) ] Loss: 1.9741 top1= 25.2500
[E 5B30 |  24800/50000 ( 50%) ] Loss: 1.8818 top1= 30.2500
[E 5B40 |  32800/50000 ( 66%) ] Loss: 1.8864 top1= 30.1250
