ParallelTrainer(aggregator=Clipping (tau=100, n_iter=1), max_batches_per_epoch=9999999, log_interval=10, metrics=['top1']use_cuda=True, debug=False, )
DistributedEvaluator(use_cuda=True, debug=False, )
=> Add worker BitFlippingWorker
=> Add worker BitFlippingWorker
=> Add worker BitFlippingWorker
=> Add worker BitFlippingWorker
=> Add worker BitFlippingWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
=> Add worker TorchWorker
Train epoch 1
[E 1B0  |    800/50000 (  2%) ] Loss: 2.4310 top1= 12.0000
[E 1B10 |   8800/50000 ( 18%) ] Loss: 2.2292 top1= 17.1250
[E 1B20 |  16800/50000 ( 34%) ] Loss: 2.1234 top1= 17.3750
[E 1B30 |  24800/50000 ( 50%) ] Loss: 2.0293 top1= 23.8750
[E 1B40 |  32800/50000 ( 66%) ] Loss: 1.9790 top1= 24.6250
[E 1B50 |  40800/50000 ( 82%) ] Loss: 1.9504 top1= 24.1250
[E 1B60 |  48800/50000 ( 98%) ] Loss: 1.8731 top1= 31.6250
[E 1B70 |  56800/50000 (114%) ] Loss: 1.8860 top1= 28.5000

=> Eval Loss=1.8301 top1= 31.3101

Train epoch 2
[E 2B0  |    800/50000 (  2%) ] Loss: 1.8404 top1= 30.0000
[E 2B10 |   8800/50000 ( 18%) ] Loss: 1.8381 top1= 30.2500
[E 2B20 |  16800/50000 ( 34%) ] Loss: 1.8044 top1= 33.8750
[E 2B30 |  24800/50000 ( 50%) ] Loss: 1.8455 top1= 28.1250
[E 2B40 |  32800/50000 ( 66%) ] Loss: 1.8384 top1= 31.1250
[E 2B50 |  40800/50000 ( 82%) ] Loss: 1.7570 top1= 30.8750
[E 2B60 |  48800/50000 ( 98%) ] Loss: 1.7729 top1= 33.2500
[E 2B70 |  56800/50000 (114%) ] Loss: 1.7580 top1= 31.6250

=> Eval Loss=1.7927 top1= 32.9828

Train epoch 3
[E 3B0  |    800/50000 (  2%) ] Loss: 1.7617 top1= 36.7500
[E 3B10 |   8800/50000 ( 18%) ] Loss: 1.7534 top1= 27.7500
[E 3B20 |  16800/50000 ( 34%) ] Loss: 1.7299 top1= 33.1250
[E 3B30 |  24800/50000 ( 50%) ] Loss: 1.6819 top1= 33.0000
[E 3B40 |  32800/50000 ( 66%) ] Loss: 1.6354 top1= 37.0000
[E 3B50 |  40800/50000 ( 82%) ] Loss: 1.6619 top1= 39.7500
[E 3B60 |  48800/50000 ( 98%) ] Loss: 1.6600 top1= 36.2500
[E 3B70 |  56800/50000 (114%) ] Loss: 1.6864 top1= 38.8750

=> Eval Loss=1.6912 top1= 36.3582

Train epoch 4
[E 4B0  |    800/50000 (  2%) ] Loss: 1.6331 top1= 37.0000
[E 4B10 |   8800/50000 ( 18%) ] Loss: 1.6052 top1= 41.1250
[E 4B20 |  16800/50000 ( 34%) ] Loss: 1.5922 top1= 37.8750
[E 4B30 |  24800/50000 ( 50%) ] Loss: 1.6753 top1= 37.2500
[E 4B40 |  32800/50000 ( 66%) ] Loss: 1.6283 top1= 38.5000
[E 4B50 |  40800/50000 ( 82%) ] Loss: 1.6428 top1= 36.5000
[E 4B60 |  48800/50000 ( 98%) ] Loss: 1.6104 top1= 39.5000
[E 4B70 |  56800/50000 (114%) ] Loss: 1.5949 top1= 40.8750

=> Eval Loss=1.5517 top1= 41.6066

Train epoch 5
[E 5B0  |    800/50000 (  2%) ] Loss: 1.6410 top1= 37.1250
[E 5B10 |   8800/50000 ( 18%) ] Loss: 1.5550 top1= 41.6250
[E 5B20 |  16800/50000 ( 34%) ] Loss: 1.5538 top1= 39.1250
[E 5B30 |  24800/50000 ( 50%) ] Loss: 1.5484 top1= 42.1250
[E 5B40 |  32800/50000 ( 66%) ] Loss: 1.5973 top1= 39.3750
[E 5B50 |  40800/50000 ( 82%) ] Loss: 1.5851 top1= 39.1250
[E 5B60 |  48800/50000 ( 98%) ] Loss: 1.5390 top1= 41.7500
[E 5B70 |  56800/50000 (114%) ] Loss: 1.5707 top1= 43.3750

=> Eval Loss=1.4745 top1= 44.7316

Train epoch 6
[E 6B0  |    800/50000 (  2%) ] Loss: 1.6094 top1= 41.5000
[E 6B10 |   8800/50000 ( 18%) ] Loss: 1.5249 top1= 43.3750
[E 6B20 |  16800/50000 ( 34%) ] Loss: 1.5123 top1= 43.1250
[E 6B30 |  24800/50000 ( 50%) ] Loss: 1.6094 top1= 40.2500
